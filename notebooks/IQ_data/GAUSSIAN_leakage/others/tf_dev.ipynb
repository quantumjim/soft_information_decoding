{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state = Z0\n",
      "shape: (40, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>notebook_name</th>\n",
       "      <th>backend_name</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>meas_level</th>\n",
       "      <th>shots</th>\n",
       "      <th>num_qubits</th>\n",
       "      <th>job_status</th>\n",
       "      <th>execution_date</th>\n",
       "      <th>code</th>\n",
       "      <th>distance</th>\n",
       "      <th>rounds</th>\n",
       "      <th>logical</th>\n",
       "      <th>descr</th>\n",
       "      <th>resets</th>\n",
       "      <th>xbasis</th>\n",
       "      <th>path_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>2024-03-23 17:44:10.530000+01:00</td>\n",
       "      <td>Sherbrooke_RepCodes_jobs</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cqzgdppczq6g0081hjfg</td>\n",
       "      <td>[Subset 52, 100 rounds, 0 log, xbasis=False]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>2024-03-23 18:05:17.770180+01:00</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>subset RepCodes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'mean_gate_error': 0.008345314216382, 'min_ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>2024-03-23 17:43:48.780000+01:00</td>\n",
       "      <td>Sherbrooke_RepCodes_jobs</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cqzgdh6ktf3g00883tn0</td>\n",
       "      <td>[Subset 52, 100 rounds, 0 log, xbasis=False]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>2024-03-23 18:04:47.231991+01:00</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>subset RepCodes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'mean_gate_error': 0.008345314216382, 'min_ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         creation_date             notebook_name  \\\n",
       "5259  2024-03-23 17:44:10.530000+01:00  Sherbrooke_RepCodes_jobs   \n",
       "5258  2024-03-23 17:43:48.780000+01:00  Sherbrooke_RepCodes_jobs   \n",
       "\n",
       "        backend_name                job_id  \\\n",
       "5259  ibm_sherbrooke  cqzgdppczq6g0081hjfg   \n",
       "5258  ibm_sherbrooke  cqzgdh6ktf3g00883tn0   \n",
       "\n",
       "                                              tags  meas_level  shots  \\\n",
       "5259  [Subset 52, 100 rounds, 0 log, xbasis=False]         1.0  768.0   \n",
       "5258  [Subset 52, 100 rounds, 0 log, xbasis=False]         1.0  768.0   \n",
       "\n",
       "      num_qubits      job_status                    execution_date  \\\n",
       "5259         NaN  JobStatus.DONE  2024-03-23 18:05:17.770180+01:00   \n",
       "5258         NaN  JobStatus.DONE  2024-03-23 18:04:47.231991+01:00   \n",
       "\n",
       "                       code  distance  rounds logical            descr resets  \\\n",
       "5259  RepetitionCodeCircuit        52     100       0  subset RepCodes    NaN   \n",
       "5258  RepetitionCodeCircuit        52     100       0  subset RepCodes    NaN   \n",
       "\n",
       "     xbasis                                          path_info  \n",
       "5259  False  {'mean_gate_error': 0.008345314216382, 'min_ga...  \n",
       "5258  False  {'mean_gate_error': 0.008345314216382, 'min_ga...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Scratch import metadata_loader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"ibm_sherbrooke\"\n",
    "LOGICAL = str(0)\n",
    "XBASIS = False\n",
    "ROUNDS = 100\n",
    "\n",
    "state = \"X\" if XBASIS else \"Z\"\n",
    "state += LOGICAL\n",
    "print(f\"state = {state}\")\n",
    "\n",
    "\n",
    "# Load the metadata\n",
    "md = metadata_loader(True, True)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"code\"] == \"RepetitionCodeCircuit\"]\n",
    "md = md[md[\"descr\"] == 'subset RepCodes']\n",
    "md = md.dropna(subset=[\"rounds\"])\n",
    "md = md[md[\"meas_level\"] == 1]\n",
    "md['rounds'] = md['rounds'].astype(int)\n",
    "md['distance'] = md['distance'].astype(int)\n",
    "\n",
    "md = md[md[\"backend_name\"] == DEVICE]\n",
    "md = md[md[\"logical\"] == LOGICAL]\n",
    "md = md[md[\"xbasis\"] == XBASIS]\n",
    "md = md[md[\"rounds\"] == ROUNDS]\n",
    "\n",
    "md = md[md['notebook_name']=='Sherbrooke_RepCodes_jobs']\n",
    "\n",
    "# md = md[0:1]\n",
    "print(\"shape:\", md.shape)\n",
    "md[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution date: 2024-03-23 18:05:17.770180+01:00\n"
     ]
    }
   ],
   "source": [
    "from result_saver import SaverProvider\n",
    "\n",
    "provider = SaverProvider()\n",
    "md_loc = 0\n",
    "\n",
    "job_id = md.iloc[md_loc][\"job_id\"]\n",
    "job = provider.retrieve_job(job_id) \n",
    "\n",
    "execution_date = job.result().date\n",
    "memory = job.result().get_memory()\n",
    "\n",
    "print(f\"Execution date: {execution_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soft_info import inv_qubit_mapping, get_repcode_IQ_map\n",
    "\n",
    "_RESETS = False\n",
    "SOFT_MUL = 0.5\n",
    "T = md.iloc[md_loc][\"rounds\"]\n",
    "d = md.iloc[md_loc][\"distance\"]\n",
    "\n",
    "shots = md.iloc[md_loc][\"shots\"]\n",
    "# Get the layout of the last job (same as previous)\n",
    "layout_des = job.deserialize_layout(job.initial_layouts()[0]) # only 1 layout\n",
    "link_qubits = list(layout_des['link_qubit'].values())\n",
    "code_qubits = list(layout_des['code_qubit'].values())\n",
    "\n",
    "# Get the pSoft and countMat matrices\n",
    "big_layout = link_qubits + code_qubits\n",
    "inverted_q_map = inv_qubit_mapping(get_repcode_IQ_map(big_layout, synd_rounds=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified job execution date: 2024-03-23 18:05:17.770180+01:00\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2024-03-23 17:06:20.263377+00:00.\n"
     ]
    }
   ],
   "source": [
    "from Scratch import load_calibration_memory\n",
    "\n",
    "all_memories_PS, _, msmt_err_dict = load_calibration_memory(provider, tobecalib_job=job_id, post_process=True, double_msmt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RepCode data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/_3/n7zzdff5239886c9gmhrk6yr0000gn/T/ipykernel_12018/2336361769.py\", line 44, in train_step  *\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n        self._backend_apply_gradients(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n        self._backend_update_step(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n        tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n        distribution.extended.update(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var  **\n        return self.update_step(grad, var, learning_rate)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 133, in update_step\n        m, ops.multiply(ops.subtract(gradient, m), 1 - self.beta_1)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 5429, in subtract\n        return backend.numpy.subtract(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py\", line 493, in sparse_wrapper\n        return func(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 344, in subtract\n        return tf.subtract(x1, x2)\n\n    ValueError: Dimensions must be equal, but are 2 and 3 for '{{node adam_1/Sub_2}} = Sub[T=DT_FLOAT](adam_1/IdentityN, adam_1/Sub_2/ReadVariableOp)' with input shapes: [3,2], [3].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     nll \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: NLL = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnll\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/_3/n7zzdff5239886c9gmhrk6yr0000gn/T/__autograph_generated_file6yay9g5f.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(data, model, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m     nll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mlog_prob, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(nll), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:282\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    281\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:351\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:405\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    396\u001b[0m     ops\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m    397\u001b[0m         is_update_step,\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: _update_step_fn(grads, trainable_variables),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m         ),\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Run udpate step.\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    412\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:119\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backend_update_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads, trainable_variables, learning_rate):\n\u001b[1;32m    115\u001b[0m     trainable_variables \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    116\u001b[0m         v\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, backend\u001b[38;5;241m.\u001b[39mVariable) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m trainable_variables\n\u001b[1;32m    118\u001b[0m     ]\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:135\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:132\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/adam.py:133\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    128\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_variable_index(variable)]\n\u001b[1;32m    130\u001b[0m alpha \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m ops\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta_2_power) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta_1_power)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_add(\n\u001b[0;32m--> 133\u001b[0m     m, ops\u001b[38;5;241m.\u001b[39mmultiply(\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1)\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_add(\n\u001b[1;32m    136\u001b[0m     v,\n\u001b[1;32m    137\u001b[0m     ops\u001b[38;5;241m.\u001b[39mmultiply(\n\u001b[1;32m    138\u001b[0m         ops\u001b[38;5;241m.\u001b[39msubtract(ops\u001b[38;5;241m.\u001b[39msquare(gradient), v), \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2\n\u001b[1;32m    139\u001b[0m     ),\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/ops/numpy.py:5429\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   5427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[1;32m   5428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subtract()\u001b[38;5;241m.\u001b[39msymbolic_call(x1, x2)\n\u001b[0;32m-> 5429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py:493\u001b[0m, in \u001b[0;36melementwise_binary_union.<locals>.wrap_elementwise_binary_union.<locals>.sparse_wrapper\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x2, tf\u001b[38;5;241m.\u001b[39mIndexedSlices):\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# x2 is an IndexedSlices, densify.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x2)\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py:344\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    342\u001b[0m x1 \u001b[38;5;241m=\u001b[39m convert_to_tensor(x1, dtype)\n\u001b[1;32m    343\u001b[0m x2 \u001b[38;5;241m=\u001b[39m convert_to_tensor(x2, dtype)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/_3/n7zzdff5239886c9gmhrk6yr0000gn/T/ipykernel_12018/2336361769.py\", line 44, in train_step  *\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n        self._backend_apply_gradients(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n        self._backend_update_step(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n        tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n        distribution.extended.update(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var  **\n        return self.update_step(grad, var, learning_rate)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 133, in update_step\n        m, ops.multiply(ops.subtract(gradient, m), 1 - self.beta_1)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 5429, in subtract\n        return backend.numpy.subtract(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py\", line 493, in sparse_wrapper\n        return func(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 344, in subtract\n        return tf.subtract(x1, x2)\n\n    ValueError: Dimensions must be equal, but are 2 and 3 for '{{node adam_1/Sub_2}} = Sub[T=DT_FLOAT](adam_1/IdentityN, adam_1/Sub_2/ReadVariableOp)' with input shapes: [3,2], [3].\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Generate synthetic data\n",
    "def generate_data(num_samples):\n",
    "    # Generating data from three different normal distributions\n",
    "    data1 = tf.random.normal((num_samples // 3, 2), mean=[2.0, 3.0], stddev=1.0)\n",
    "    data2 = tf.random.normal((num_samples // 3, 2), mean=[-2.0, -3.0], stddev=1.0)\n",
    "    data3 = tf.random.normal((num_samples // 3, 2), mean=[4.0, -2.0], stddev=1.0)\n",
    "    return tf.concat([data1, data2, data3], axis=0)\n",
    "\n",
    "# Define the GMM model\n",
    "def build_gmm():\n",
    "    n_components = 3\n",
    "    n_dims = 2  # Assuming 2-dimensional data\n",
    "\n",
    "    # Component means\n",
    "    component_means = tf.Variable(tf.random.normal([n_components, n_dims]))\n",
    "\n",
    "    # Component scale diagonals (standard deviations)\n",
    "    scale_diags = tf.Variable(tf.random.uniform([n_components, n_dims], minval=0.5, maxval=1.5))\n",
    "\n",
    "    # Mixture weights\n",
    "    mixture_logits = tf.Variable(tf.zeros([n_components]))\n",
    "\n",
    "    # Define the Gaussian components\n",
    "    components = tfd.MultivariateNormalDiag(loc=component_means, scale_diag=scale_diags)\n",
    "\n",
    "    # Create the mixture model\n",
    "    mixture = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(logits=mixture_logits),\n",
    "        components_distribution=tfd.Independent(components)\n",
    "    )\n",
    "\n",
    "    return mixture\n",
    "\n",
    "@tf.function\n",
    "def train_step(data, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Negative log-likelihood to minimize\n",
    "        nll = -tf.reduce_mean(model.log_prob(data))\n",
    "    gradients = tape.gradient(nll, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return nll\n",
    "\n",
    "data = generate_data(300)  # Generate synthetic data\n",
    "gmm_model = build_gmm()  # Build the GMM\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Training loop\n",
    "for step in range(1000):\n",
    "    nll = train_step(data, gmm_model, optimizer)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}: NLL = {nll.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/_3/n7zzdff5239886c9gmhrk6yr0000gn/T/ipykernel_12018/2502449684.py\", line 37, in train_step  *\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n        self._backend_apply_gradients(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n        self._backend_update_step(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n        tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n        distribution.extended.update(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var  **\n        return self.update_step(grad, var, learning_rate)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 133, in update_step\n        m, ops.multiply(ops.subtract(gradient, m), 1 - self.beta_1)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 5429, in subtract\n        return backend.numpy.subtract(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py\", line 493, in sparse_wrapper\n        return func(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 344, in subtract\n        return tf.subtract(x1, x2)\n\n    ValueError: Dimensions must be equal, but are 2 and 3 for '{{node adam_1/Sub_2}} = Sub[T=DT_FLOAT](adam_1/IdentityN, adam_1/Sub_2/ReadVariableOp)' with input shapes: [3,2], [3].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 49\u001b[0m     nll \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: NLL = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnll\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/_3/n7zzdff5239886c9gmhrk6yr0000gn/T/__autograph_generated_filegly7zu48.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(data, model, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m     nll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mlog_prob, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(nll), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:282\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    281\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:351\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:405\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    396\u001b[0m     ops\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m    397\u001b[0m         is_update_step,\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: _update_step_fn(grads, trainable_variables),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m         ),\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Run udpate step.\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    412\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:119\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backend_update_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads, trainable_variables, learning_rate):\n\u001b[1;32m    115\u001b[0m     trainable_variables \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    116\u001b[0m         v\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, backend\u001b[38;5;241m.\u001b[39mVariable) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m trainable_variables\n\u001b[1;32m    118\u001b[0m     ]\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:135\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:132\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/adam.py:133\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    128\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_variable_index(variable)]\n\u001b[1;32m    130\u001b[0m alpha \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m ops\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta_2_power) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta_1_power)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_add(\n\u001b[0;32m--> 133\u001b[0m     m, ops\u001b[38;5;241m.\u001b[39mmultiply(\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1)\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_add(\n\u001b[1;32m    136\u001b[0m     v,\n\u001b[1;32m    137\u001b[0m     ops\u001b[38;5;241m.\u001b[39mmultiply(\n\u001b[1;32m    138\u001b[0m         ops\u001b[38;5;241m.\u001b[39msubtract(ops\u001b[38;5;241m.\u001b[39msquare(gradient), v), \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2\n\u001b[1;32m    139\u001b[0m     ),\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/ops/numpy.py:5429\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   5427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[1;32m   5428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subtract()\u001b[38;5;241m.\u001b[39msymbolic_call(x1, x2)\n\u001b[0;32m-> 5429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py:493\u001b[0m, in \u001b[0;36melementwise_binary_union.<locals>.wrap_elementwise_binary_union.<locals>.sparse_wrapper\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x2, tf\u001b[38;5;241m.\u001b[39mIndexedSlices):\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# x2 is an IndexedSlices, densify.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x2)\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py:344\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    342\u001b[0m x1 \u001b[38;5;241m=\u001b[39m convert_to_tensor(x1, dtype)\n\u001b[1;32m    343\u001b[0m x2 \u001b[38;5;241m=\u001b[39m convert_to_tensor(x2, dtype)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/_3/n7zzdff5239886c9gmhrk6yr0000gn/T/ipykernel_12018/2502449684.py\", line 37, in train_step  *\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n        self._backend_apply_gradients(grads, trainable_variables)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n        self._backend_update_step(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n        tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n        distribution.extended.update(\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var  **\n        return self.update_step(grad, var, learning_rate)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 133, in update_step\n        m, ops.multiply(ops.subtract(gradient, m), 1 - self.beta_1)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 5429, in subtract\n        return backend.numpy.subtract(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py\", line 493, in sparse_wrapper\n        return func(x1, x2)\n    File \"/Users/mha/.local/share/virtualenvs/Soft-Info-fMUpUe5a/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 344, in subtract\n        return tf.subtract(x1, x2)\n\n    ValueError: Dimensions must be equal, but are 2 and 3 for '{{node adam_1/Sub_2}} = Sub[T=DT_FLOAT](adam_1/IdentityN, adam_1/Sub_2/ReadVariableOp)' with input shapes: [3,2], [3].\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "def build_gmm(data):\n",
    "    n_dims = data.shape[-1]  # Extract the number of dimensions in data\n",
    "\n",
    "    # Component means\n",
    "    component_means = tf.Variable(tf.random.normal([3, n_dims]))\n",
    "\n",
    "    # Unified scale diagonals for each component\n",
    "    scale_diags = tfp.util.TransformedVariable(\n",
    "        initial_value=tf.ones([3, n_dims]),\n",
    "        bijector=tfp.bijectors.Softplus()\n",
    "    )\n",
    "\n",
    "    # Mixture weights\n",
    "    mixture_logits = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "    # Define the Gaussian mixture components\n",
    "    components = tfd.MultivariateNormalDiag(loc=component_means, scale_diag=scale_diags)\n",
    "\n",
    "    # Create the mixture model\n",
    "    mixture = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(logits=mixture_logits),\n",
    "        components_distribution=components\n",
    "    )\n",
    "\n",
    "    return mixture\n",
    "\n",
    "@tf.function\n",
    "def train_step(data, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Calculate the negative log-likelihood\n",
    "        nll = -tf.reduce_mean(model.log_prob(data))\n",
    "    gradients = tape.gradient(nll, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return nll\n",
    "\n",
    "# Generate synthetic data\n",
    "data = tf.random.normal([100, 2])  # 100 samples, each with 2 dimensions\n",
    "\n",
    "# Build and train the Gaussian Mixture Model\n",
    "gmm_model = build_gmm(data)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Training loop\n",
    "for step in range(1000):\n",
    "    nll = train_step(data, gmm_model, optimizer)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}: NLL = {nll.numpy()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
