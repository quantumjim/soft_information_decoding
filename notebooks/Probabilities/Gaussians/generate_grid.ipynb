{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-10-27 08:32:22.841567+00:00.\n"
     ]
    }
   ],
   "source": [
    "from Scratch import load_calibration_memory\n",
    "\n",
    "DEVICE = 'ibm_sherbrooke'\n",
    "OTHER_DATE = '2023-10-30'\n",
    "\n",
    "all_memories = load_calibration_memory(provider, tobecalib_backend=DEVICE, other_date=OTHER_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fit_gmm(IQ_data, scaler):\n",
    "\n",
    "    data = IQ_data.flatten()\n",
    "    combined_data = np.column_stack((data.real, data.imag))\n",
    "    combined_data = scaler.transform(combined_data)\n",
    "\n",
    "    n_components_range = range(1, 4)  \n",
    "\n",
    "    lowest_bic = np.infty\n",
    "    best_gmm = None\n",
    "\n",
    "    for n_components in n_components_range:\n",
    "\n",
    "        weights_init = [1]\n",
    "\n",
    "        # Distribute the remaining weight equally among other components\n",
    "        if n_components > 1:\n",
    "            # Initialize weights\n",
    "            weights_init = np.zeros(n_components)\n",
    "            primary_weight = 0.95  # Weight for the first component\n",
    "            weights_init = np.zeros(n_components)\n",
    "            weights_init[0] = primary_weight\n",
    "            remaining_weight = (1 - primary_weight) / (n_components-1)\n",
    "            for i in range(1, n_components):\n",
    "                weights_init[i] = remaining_weight\n",
    "\n",
    "        if n_components == 2:\n",
    "            means_init = np.array([[-1e8, 0], [1e8, 0]])\n",
    "            # means_init = None\n",
    "        else:\n",
    "            means_init = None\n",
    "\n",
    "        # Fit a Gaussian mixture with EM\n",
    "        gmm = GaussianMixture(n_components=n_components, init_params='random',\n",
    "                            covariance_type='tied', random_state=0, weights_init=weights_init, means_init=means_init)\n",
    "        gmm.fit(combined_data)\n",
    "        \n",
    "        # Calculate BIC\n",
    "        bic = gmm.bic(combined_data)\n",
    "        \n",
    "        # Check if this is the lowest BIC so far\n",
    "        if bic < lowest_bic and np.all([weight < 0.1 or weight > 0.9 for weight in gmm.weights_]):\n",
    "            lowest_bic = bic\n",
    "            best_gmm = gmm\n",
    "    \n",
    "    return best_gmm\n",
    "\n",
    "def draw_ellipse(mean, cov, n_std=1, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given mean and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "\n",
    "    # Eigenvalues and eigenvectors of the covariance matrix\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "\n",
    "    theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "    width, height = 2 * n_std * np.sqrt(vals)\n",
    "    ellipse = Ellipse(xy=mean, width=width, height=height, angle=theta, **kwargs)\n",
    "\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "\n",
    "def plot_gmm(gmm, data_2d, n_std=1):\n",
    "    plt.scatter(data_2d[:, 0], data_2d[:, 1], alpha=0.5)\n",
    "\n",
    "    # Plot each Gaussian component\n",
    "    for mean, covar in zip(gmm.means_, gmm.covariances_):\n",
    "        draw_ellipse(mean, covar, n_std=n_std, alpha=1, edgecolor='red', facecolor='none')\n",
    "\n",
    "    plt.title(\"Data and Fitted Gaussian Components\")\n",
    "    plt.xlabel(\"Real Part\")\n",
    "    plt.ylabel(\"Imaginary Part\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-10-27 08:32:22.841567+00:00.\n"
     ]
    }
   ],
   "source": [
    "from soft_info import get_KDEs\n",
    "\n",
    "kde_dict, scaler_dict = get_KDEs(provider, tobecalib_backend=DEVICE, other_date=OTHER_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_dict = {}\n",
    "for qubit in all_memories.keys():\n",
    "    gmm_dict[qubit] = {}\n",
    "    scaler = scaler_dict[qubit]\n",
    "    for mmr in all_memories[qubit].keys():\n",
    "        data = all_memories[qubit][mmr]\n",
    "        gmm_dict[qubit][mmr] = fit_gmm(data, scaler)\n",
    "\n",
    "# takes 3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cpp_soft_info\n",
    "from Scratch import process_scaler_dict\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "num_std_dev = 2\n",
    "num_points = 300\n",
    "\n",
    "grid_dict = {}\n",
    "\n",
    "grid_range_real = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "grid_range_imag = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "grid_x, grid_y = np.meshgrid(grid_range_real, grid_range_imag)\n",
    "grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "\n",
    "for qubit_idx, gmms in gmm_dict.items():    \n",
    "    grid_density_0 = gmms['mmr_0'].score_samples(grid_points).reshape(grid_x.shape)\n",
    "    grid_density_1 = gmms['mmr_1'].score_samples(grid_points).reshape(grid_x.shape)\n",
    "\n",
    "    grid_dict[qubit_idx] = cpp_soft_info.GridData(grid_x, grid_y, grid_density_0, grid_density_1)\n",
    "\n",
    "\n",
    "# Scaler dict \n",
    "processed_scaler_dict = process_scaler_dict(scaler_dict)\n",
    "\n",
    "# takes 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cpp_soft_info\n",
    "from Scratch import process_scaler_dict\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "grid_dict_no_outliers = {}\n",
    "\n",
    "grid_range_real = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "grid_range_imag = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "grid_x, grid_y = np.meshgrid(grid_range_real, grid_range_imag)\n",
    "grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "\n",
    "for qubit_idx, gmms in gmm_dict.items():    \n",
    "    for i, gmm in enumerate(gmms.values()):\n",
    "        max_weight_index = np.argmax(gmm.weights_)\n",
    "        mvn = multivariate_normal(mean=gmm.means_[max_weight_index], cov=gmm.covariances_)\n",
    "        grid_density = mvn.pdf(grid_points).reshape(grid_x.shape)\n",
    "        if i == 0:\n",
    "            grid_density_0 = grid_density\n",
    "        else:\n",
    "            grid_density_1 = grid_density\n",
    "\n",
    "    grid_dict_no_outliers[qubit_idx] = cpp_soft_info.GridData(grid_x, grid_y, grid_density_0, grid_density_1)\n",
    "\n",
    "\n",
    "# Scaler dict \n",
    "processed_scaler_dict = process_scaler_dict(scaler_dict)\n",
    "\n",
    "# takes 0.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soft_info import RepCodeIQSimulator\n",
    "\n",
    "DISTANCE = 7\n",
    "ROUNDS = 7\n",
    "_RESETS = False\n",
    "LOGICAL = 0 # NOT NEEDED FOR EXTREME IQ BCS HARDCODED 0\n",
    "\n",
    "_is_hex = True\n",
    "if DEVICE == 'ibmq_mumbai':\n",
    "    _is_hex = False\n",
    "\n",
    "# Initialize simulator\n",
    "simulator = RepCodeIQSimulator(provider, DISTANCE, ROUNDS, DEVICE, _is_hex=_is_hex, _resets = _RESETS, other_date=OTHER_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8871/8871 [00:00<00:00, 43797.38it/s]\n",
      "100%|██████████| 8871/8871 [00:03<00:00, 2825.42it/s]\n"
     ]
    }
   ],
   "source": [
    "SHOTS = int(1e4)\n",
    "NOISE_LIST = [3e-2, 0.8e-2, 1e-2, 3e-2] # [two-qubit-fidelity, reset error, measurement error, idle error]\n",
    "# NOISE_LIST = None\n",
    "P_AMBIG = 0.3\n",
    "\n",
    "IQ_data = simulator.generate_IQ(SHOTS, noise_list=NOISE_LIST)\n",
    "IQ_data_extreme = simulator.generate_extreme_IQ(SHOTS, P_AMBIG, noise_list=NOISE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatching\n",
    "import stim\n",
    "\n",
    "model = simulator.stim_circ.detector_error_model(decompose_errors=True)\n",
    "matching = pymatching.Matching.from_detector_error_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOFT INFO DECODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 132 out of 10000 shots for _RESETS = False\n",
      "num_errors EXTREME: 272 out of 10000 shots for _RESETS = False\n"
     ]
    }
   ],
   "source": [
    "import cpp_soft_info\n",
    "\n",
    "_DETAILED = False\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result = cpp_soft_info.decode_IQ_shots(matching._matching_graph, IQ_data,\n",
    "                                           ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, simulator.grid_dict,\n",
    "                                           simulator.processed_scaler_dict, p_data=-1, p_mixed=-1,\n",
    "                                           common_measure=-1, _adv_probs=not _RESETS, _bimodal=_RESETS, merge_strategy = \"replace\", _detailed=_DETAILED,\n",
    "                                            p_offset = 1, p_multiplicator = 1, _ntnn_edges = not _RESETS)\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_extreme = cpp_soft_info.decode_IQ_shots(matching._matching_graph, IQ_data_extreme,\n",
    "                                             ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, simulator.grid_dict,\n",
    "                                             simulator.processed_scaler_dict, p_data=-1, p_mixed=-1,\n",
    "                                             common_measure=-1, _adv_probs=not _RESETS, _bimodal=_RESETS, merge_strategy = \"replace\", _detailed=_DETAILED,\n",
    "                                              p_offset = 1, p_multiplicator = 1, _ntnn_edges = not _RESETS)\n",
    "\n",
    "print(\"num_errors:\", result.num_errors, \"out of\", len(IQ_data), \"shots for _RESETS =\", _RESETS)\n",
    "print(\"num_errors EXTREME:\", result_extreme.num_errors, \"out of\", len(IQ_data_extreme), \"shots for _RESETS =\", _RESETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 144 out of 10000 shots for _RESETS = False\n",
      "num_errors EXTREME: 747 out of 10000 shots for _RESETS = False\n"
     ]
    }
   ],
   "source": [
    "import cpp_soft_info\n",
    "\n",
    "_DETAILED = False\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result = cpp_soft_info.decode_IQ_shots(matching._matching_graph, IQ_data,\n",
    "                                           ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, grid_dict,\n",
    "                                           simulator.processed_scaler_dict, p_data=-1, p_mixed=-1,\n",
    "                                           common_measure=-1, _adv_probs=not _RESETS, _bimodal=_RESETS, merge_strategy = \"replace\", _detailed=_DETAILED,\n",
    "                                            p_offset = 1, p_multiplicator = 1, _ntnn_edges = not _RESETS)\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_extreme = cpp_soft_info.decode_IQ_shots(matching._matching_graph, IQ_data_extreme,\n",
    "                                             ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, grid_dict_no_outliers,\n",
    "                                             simulator.processed_scaler_dict, p_data=-1, p_mixed=-1,\n",
    "                                             common_measure=-1, _adv_probs=not _RESETS, _bimodal=_RESETS, merge_strategy = \"replace\", _detailed=_DETAILED,\n",
    "                                              p_offset = 1, p_multiplicator = 1, _ntnn_edges = not _RESETS)\n",
    "\n",
    "print(\"num_errors:\", result.num_errors, \"out of\", len(IQ_data), \"shots for _RESETS =\", _RESETS)\n",
    "print(\"num_errors EXTREME:\", result_extreme.num_errors, \"out of\", len(IQ_data_extreme), \"shots for _RESETS =\", _RESETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFORMED DECODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 166 out of 10000 shots for _RESETS = False\n",
      "num_errors EXTREME: 2435 out of 10000 shots for _RESETS = False\n"
     ]
    }
   ],
   "source": [
    "p_meas = -1\n",
    "# p_meas = 30e-2 \n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_informed = cpp_soft_info.decode_IQ_shots_flat_informed(matching._matching_graph, IQ_data[:],\n",
    "                                           ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, simulator.grid_dict, simulator.processed_scaler_dict,\n",
    "                                           p_data = -1, p_mixed = -1, p_meas = p_meas, common_measure=-1, _detailed=_DETAILED, _ntnn_edges = True)\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_informed_extreme = cpp_soft_info.decode_IQ_shots_flat_informed(matching._matching_graph, IQ_data_extreme[:],\n",
    "                                             ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, simulator.grid_dict, simulator.processed_scaler_dict,\n",
    "                                             p_data = -1, p_mixed = -1, p_meas = p_meas, common_measure=-1, _detailed=_DETAILED, _ntnn_edges = True)\n",
    "\n",
    "print(\"num_errors:\", result_informed.num_errors, \"out of\", len(IQ_data), \"shots for _RESETS =\", _RESETS)\n",
    "print(\"num_errors EXTREME:\", result_informed_extreme.num_errors, \"out of\", len(IQ_data_extreme), \"shots for _RESETS =\", _RESETS)\n",
    "         \n",
    "# takes 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 162 out of 10000 shots for _RESETS = False\n",
      "num_errors EXTREME: 857 out of 10000 shots for _RESETS = False\n"
     ]
    }
   ],
   "source": [
    "p_meas = -1\n",
    "# p_meas = 30e-2 \n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_informed = cpp_soft_info.decode_IQ_shots_flat_informed(matching._matching_graph, IQ_data[:],\n",
    "                                           ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, grid_dict_no_outliers, simulator.processed_scaler_dict,\n",
    "                                           p_data = -1, p_mixed = -1, p_meas = p_meas, common_measure=-1, _detailed=_DETAILED, _ntnn_edges = True)\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_informed_extreme = cpp_soft_info.decode_IQ_shots_flat_informed(matching._matching_graph, IQ_data_extreme[:],\n",
    "                                             ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, grid_dict_no_outliers, simulator.processed_scaler_dict,\n",
    "                                             p_data = -1, p_mixed = -1, p_meas = p_meas, common_measure=-1, _detailed=_DETAILED, _ntnn_edges = True)\n",
    "\n",
    "print(\"num_errors:\", result_informed.num_errors, \"out of\", len(IQ_data), \"shots for _RESETS =\", _RESETS)\n",
    "print(\"num_errors EXTREME:\", result_informed_extreme.num_errors, \"out of\", len(IQ_data_extreme), \"shots for _RESETS =\", _RESETS)\n",
    "         \n",
    "# takes 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLAT DECODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 196 out of 10000 shots for _RESETS = False\n",
      "num_errors EXTREME: 3740 out of 10000 shots for _RESETS = False\n"
     ]
    }
   ],
   "source": [
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_flat = cpp_soft_info.decode_IQ_shots_flat(matching._matching_graph, IQ_data,\n",
    "                                           ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, simulator.grid_dict,\n",
    "                                           simulator.processed_scaler_dict, _detailed=_DETAILED)\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_flat_extreme = cpp_soft_info.decode_IQ_shots_flat(matching._matching_graph, IQ_data_extreme,\n",
    "                                                         ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, simulator.grid_dict,\n",
    "                                                            simulator.processed_scaler_dict, _detailed=_DETAILED)\n",
    "\n",
    "print(\"num_errors:\", result_flat.num_errors, \"out of\", len(IQ_data), \"shots for _RESETS =\", _RESETS)\n",
    "print(\"num_errors EXTREME:\", result_flat_extreme.num_errors, \"out of\", len(IQ_data_extreme), \"shots for _RESETS =\", _RESETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 198 out of 10000 shots for _RESETS = False\n",
      "num_errors EXTREME: 1549 out of 10000 shots for _RESETS = False\n"
     ]
    }
   ],
   "source": [
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_flat = cpp_soft_info.decode_IQ_shots_flat(matching._matching_graph, IQ_data,\n",
    "                                           ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, grid_dict_no_outliers,\n",
    "                                           simulator.processed_scaler_dict, _detailed=_DETAILED)\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "result_flat_extreme = cpp_soft_info.decode_IQ_shots_flat(matching._matching_graph, IQ_data_extreme,\n",
    "                                                         ROUNDS, int(LOGICAL), _RESETS, simulator.qubit_mapping, grid_dict_no_outliers,\n",
    "                                                            simulator.processed_scaler_dict, _detailed=_DETAILED)\n",
    "\n",
    "print(\"num_errors:\", result_flat.num_errors, \"out of\", len(IQ_data), \"shots for _RESETS =\", _RESETS)\n",
    "print(\"num_errors EXTREME:\", result_flat_extreme.num_errors, \"out of\", len(IQ_data_extreme), \"shots for _RESETS =\", _RESETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
