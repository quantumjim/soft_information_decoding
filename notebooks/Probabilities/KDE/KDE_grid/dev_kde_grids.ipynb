{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'/Users/mha/My Drive/Desktop/Studium/Physik/MSc/Semester 3/IBM/IBM GIT/Soft-Info/build')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cpp_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n"
     ]
    }
   ],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()\n",
    "backend_name = provider.get_backend('ibmq_mumbai') \n",
    "job = provider.retrieve_job(\"cmyhbrqrmwhg008bs4h0\") # Mumbai job\n",
    "# job = provider.retrieve_job(\"cn6g47862r90008810pg\") # Sherbrooke job\n",
    "memory = job.result().get_memory()\n",
    "\n",
    "print(memory.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the qubit mapping...\n"
     ]
    }
   ],
   "source": [
    "from soft_info import get_KDEs, get_repcode_layout, get_repcode_IQ_map\n",
    "\n",
    "## Mumbai\n",
    "layout = [25, 19, 26, 22, 16] # To implement: into scratch job_data\n",
    "kde_dict, processed_scaler_dict = get_KDEs(provider, tobecalib_job=\"cmyhbrqrmwhg008bs4h0\")\n",
    "# kde_dict, scaler_dict = get_KDEs(provider, device='ibmq_mumbai', qubits=list(range(27)), bandwidths=0.2, plot=False)\n",
    "synd_rounds = 3\n",
    "\n",
    "## Sherbrooke\n",
    "# layout = get_repcode_layout(30, provider.get_backend('ibm_sherbrooke') )\n",
    "# kde_dict, scaler_dict = get_KDEs(provider, 'ibm_sdherbrooke', list(range(127)), bandwidths=0.2, plot=False)\n",
    "# synd_rounds = 35\n",
    "\n",
    "print(\"Generating the qubit mapping...\")\n",
    "qubit_mapping = get_repcode_IQ_map(layout, synd_rounds) #Hardcoded for repetition codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_or_load_kde_grid' from 'Scratch' (/Users/mha/My Drive/Desktop/Studium/Physik/MSc/Semester 3/IBM/IBM GIT/Soft-Info/src/Scratch/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/mha/My Drive/Desktop/Studium/Physik/MSc/Semester 3/IBM/IBM GIT/Soft-Info/notebooks/Probabilities/KDE/KDE_grid/dev_kde_grids.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mha/My%20Drive/Desktop/Studium/Physik/MSc/Semester%203/IBM/IBM%20GIT/Soft-Info/notebooks/Probabilities/KDE/KDE_grid/dev_kde_grids.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mScratch\u001b[39;00m \u001b[39mimport\u001b[39;00m create_or_load_kde_grid\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mha/My%20Drive/Desktop/Studium/Physik/MSc/Semester%203/IBM/IBM%20GIT/Soft-Info/notebooks/Probabilities/KDE/KDE_grid/dev_kde_grids.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mha/My%20Drive/Desktop/Studium/Physik/MSc/Semester%203/IBM/IBM%20GIT/Soft-Info/notebooks/Probabilities/KDE/KDE_grid/dev_kde_grids.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, \"cmyhbrqrmwhg008bs4h0\", 10, 3)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mha/My%20Drive/Desktop/Studium/Physik/MSc/Semester%203/IBM/IBM%20GIT/Soft-Info/notebooks/Probabilities/KDE/KDE_grid/dev_kde_grids.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m grid_dict, processed_scaler_dict \u001b[39m=\u001b[39m create_or_load_kde_grid(provider, \u001b[39m\"\u001b[39m\u001b[39mcn6h8rv62r90008814s0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_or_load_kde_grid' from 'Scratch' (/Users/mha/My Drive/Desktop/Studium/Physik/MSc/Semester 3/IBM/IBM GIT/Soft-Info/src/Scratch/__init__.py)"
     ]
    }
   ],
   "source": [
    "from Scratch import create_or_load_kde_grid\n",
    "\n",
    "# Example usage\n",
    "# grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, \"cmyhbrqrmwhg008bs4h0\", 10, 3)\n",
    "grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, \"cn6h8rv62r90008814s0\", 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "from typing import Dict, List, Optional, Union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from Scratch import find_and_create_scratch\n",
    "\n",
    "from cpp import process_scaler_dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def generate_kde_grid(kde_dict, num_points, num_std_dev=3):\n",
    "    grid_dict = {}\n",
    "\n",
    "    # Define the grid range and create grid points\n",
    "    grid_range_real = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "    grid_range_imag = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "    grid_x, grid_y = np.meshgrid(grid_range_real, grid_range_imag)\n",
    "    grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "\n",
    "    for qubit_idx, (kde_0, kde_1) in kde_dict.items():\n",
    "        # Evaluate KDE on the grid for both states\n",
    "        grid_density_0 = (kde_0.score_samples(grid_points)).reshape(grid_x.shape)\n",
    "        grid_density_1 = (kde_1.score_samples(grid_points)).reshape(grid_x.shape)\n",
    "        \n",
    "        # Create an instance of GridData and store in dictionary\n",
    "        # grid_dict[qubit_idx] = cpp_probabilities.GridData(grid_x, grid_y, grid_density_0, grid_density_1)\n",
    "        grid_dict[qubit_idx] = (grid_x, grid_y, grid_density_0, grid_density_1)\n",
    "\n",
    "    return grid_dict\n",
    "\n",
    "\n",
    "\n",
    "def update_grid_metadata(metadata_path, creation_date, backend_name, job_ids, grid_file_path, num_grid_points, num_std_dev):\n",
    "    # Convert creation_date to datetime if it is a string\n",
    "    if isinstance(creation_date, str):\n",
    "        creation_date = datetime.strptime(creation_date, \"%y-%m-%d_%Hhh%M\")\n",
    "\n",
    "    # Check if the metadata file exists\n",
    "    if os.path.exists(metadata_path):\n",
    "        # Read existing metadata\n",
    "        with open(metadata_path, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "    else:\n",
    "        # Initialize metadata if file does not exist\n",
    "        metadata = {}\n",
    "\n",
    "    # Format the creation date\n",
    "    formatted_date = creation_date.strftime(\"%y.%m.%d_%Hh%M\")\n",
    "\n",
    "    # Create a nested entry for the backend, if it doesn't exist\n",
    "    if backend_name not in metadata:\n",
    "        metadata[backend_name] = {}\n",
    "\n",
    "    # Update or create the metadata entry for the specific backend and date\n",
    "    formatted_key = f\"{creation_date.strftime('%y.%m.%d_%Hh%M')}_{num_grid_points}pts_{num_std_dev}std\"\n",
    "    metadata[backend_name][formatted_key] = {\n",
    "        'grid_file_path': grid_file_path,\n",
    "        'job_ids': job_ids,\n",
    "    }\n",
    "\n",
    "    # Write the updated metadata back to the file\n",
    "    with open(metadata_path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "def save_grid(grid_dict, processed_scaler_dict, filename):\n",
    "    \"\"\"\n",
    "    Save a grid dictionary and scaler dictionary as a JSON file.\n",
    "\n",
    "    Args:\n",
    "        grid_dict (dict): Dictionary containing tuples of NumPy arrays.\n",
    "        scaler_dict (dict): Dictionary containing scaler parameters.\n",
    "        filename (str): The name of the file to save the grid and scaler data.\n",
    "    \"\"\"\n",
    "    serializable_grid_dict = {}\n",
    "    for qubit_idx, (grid_x, grid_y, grid_density_0, grid_density_1) in grid_dict.items():\n",
    "        serializable_grid_dict[qubit_idx] = {\n",
    "            'grid_x': grid_x.tolist(), \n",
    "            'grid_y': grid_y.tolist(), \n",
    "            'grid_density_0': grid_density_0.tolist(), \n",
    "            'grid_density_1': grid_density_1.tolist()\n",
    "        }\n",
    "\n",
    "    data_to_save = {\n",
    "        'grid_data': serializable_grid_dict,\n",
    "        'scaler_data': processed_scaler_dict\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data_to_save, file, indent=4)\n",
    "    \n",
    "\n",
    "\n",
    "def load_grid(filename):\n",
    "    \"\"\"\n",
    "    Load a grid dictionary and scaler dictionary from a JSON file and create GridData objects.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file to load the grid and scaler data from.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries, one with GridData objects and the other with scaler data.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        data_loaded = json.load(file)\n",
    "\n",
    "    grid_dict = {}\n",
    "    for qubit_idx, grid_data in data_loaded['grid_data'].items():\n",
    "        grid_x = np.array(grid_data['grid_x'])\n",
    "        grid_y = np.array(grid_data['grid_y'])\n",
    "        grid_density_0 = np.array(grid_data['grid_density_0'])\n",
    "        grid_density_1 = np.array(grid_data['grid_density_1'])\n",
    "\n",
    "        # Create GridData objects\n",
    "        grid_dict[int(qubit_idx)] = cpp_probabilities.GridData(\n",
    "            grid_x, grid_y, grid_density_0, grid_density_1\n",
    "        )\n",
    "\n",
    "    scaler_dict = data_loaded['scaler_data']\n",
    "\n",
    "    return grid_dict, scaler_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# root_dir = find_and_create_scratch()\n",
    "# grid_dict = generate_kde_grid(kde_dict, 5, num_std_dev=3)  # Replace with actual kde_dict\n",
    "# save_grid(grid_dict, root_dir + '/calibration_grids/your_grid_file.json')\n",
    "# grid = load_grid(root_dir + '/calibration_grids/your_grid_file.json')\n",
    "# print(grid[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cpp import process_scaler_dict\n",
    "\n",
    "from Scratch import find_closest_calib_jobs\n",
    "\n",
    "def create_or_load_kde_grid(provider, tobecalib_job: str, num_grid_points: int, num_std_dev: int=3):\n",
    "    root_dir = find_and_create_scratch()\n",
    "    grid_folder = root_dir + '/calibration_grids'\n",
    "    metadata_file = root_dir + '/calibration_grid_metadata.json'\n",
    "\n",
    "    # Check if metadata file exists and load it\n",
    "    if os.path.exists(metadata_file):\n",
    "        with open(metadata_file, 'r') as file:\n",
    "            grid_metadata = json.load(file)\n",
    "    else:\n",
    "        grid_metadata = {}\n",
    "\n",
    "    # Find the closest calibration jobs\n",
    "    closest_job_ids, backend, creation_time = find_closest_calib_jobs(tobecalib_job)\n",
    "\n",
    "    # Format the creation date and construct the key for metadata\n",
    "    formatted_key = f\"{creation_time.strftime('%y.%m.%d_%Hh%M')}_{num_grid_points}pts_{num_std_dev}std\"\n",
    "    grid_entry = grid_metadata.get(backend, {}).get(formatted_key)\n",
    "\n",
    "    \n",
    "\n",
    "    if grid_entry:\n",
    "        # Load the existing grid and scaler\n",
    "        grid_file_path = grid_entry['grid_file_path']\n",
    "        loaded_grid_dict, loaded_scaler_dict = load_grid(grid_file_path)\n",
    "        return loaded_grid_dict, loaded_scaler_dict\n",
    "    else:\n",
    "        # Retrieve KDEs and scaler data\n",
    "        kde_dict, scaler_dict = get_KDEs(provider, tobecalib_job=tobecalib_job)\n",
    "        processed_scaler_dict = process_scaler_dict(scaler_dict)\n",
    "\n",
    "        # Generate a new grid and save it\n",
    "        grid_dict = generate_kde_grid(kde_dict, num_grid_points, num_std_dev)\n",
    "        grid_file_path = os.path.join(grid_folder, f\"{formatted_key}_grid.json\")\n",
    "        save_grid(grid_dict, processed_scaler_dict, grid_file_path)\n",
    "\n",
    "        # Update metadata\n",
    "        update_grid_metadata(metadata_file, creation_date=creation_time, backend_name=backend, job_ids=closest_job_ids, grid_file_path=grid_file_path, num_grid_points=num_grid_points, num_std_dev=num_std_dev)\n",
    "\n",
    "    return grid_dict, processed_scaler_dict\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, \"cmyhbrqrmwhg008bs4h0\", 10, 3)\n",
    "grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, \"cn6h8rv62r90008814s0\", 3, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate grid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_kde_grid(kde_dict, num_points, num_std_dev=10):\n",
    "    grid_dict = {}\n",
    "\n",
    "    # Define the grid range and create grid points\n",
    "    grid_range_real = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "    grid_range_imag = np.linspace(-num_std_dev, num_std_dev, num_points)\n",
    "    grid_x, grid_y = np.meshgrid(grid_range_real, grid_range_imag)\n",
    "    grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "\n",
    "    for qubit_idx, (kde_0, kde_1) in kde_dict.items():\n",
    "        # Evaluate KDE on the grid for both states\n",
    "        grid_density_0 = (kde_0.score_samples(grid_points)).reshape(grid_x.shape)\n",
    "        grid_density_1 = (kde_1.score_samples(grid_points)).reshape(grid_x.shape)\n",
    "        \n",
    "        # Create an instance of GridData and store in dictionary\n",
    "        grid_dict[qubit_idx] = cpp_probabilities.GridData(grid_x, grid_y, grid_density_0, grid_density_1)\n",
    "\n",
    "    return grid_dict\n",
    "\n",
    "grid_dict = generate_kde_grid(kde_dict, 10, num_std_dev=3)\n",
    "print(len(grid_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test grid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000 00 00 00', 866),\n",
       " ('000 01 00 00', 15),\n",
       " ('000 10 10 10', 11),\n",
       " ('000 01 01 01', 10),\n",
       " ('000 00 01 00', 9),\n",
       " ('000 10 00 00', 9),\n",
       " ('100 00 10 00', 8),\n",
       " ('100 10 00 10', 7),\n",
       " ('000 10 10 00', 6),\n",
       " ('001 00 00 00', 5),\n",
       " ('010 11 00 11', 5),\n",
       " ('000 00 10 00', 4),\n",
       " ('001 00 01 00', 4),\n",
       " ('001 01 00 00', 4),\n",
       " ('001 01 00 01', 4),\n",
       " ('100 10 00 00', 4),\n",
       " ('100 00 00 00', 3),\n",
       " ('000 00 10 10', 2),\n",
       " ('000 01 01 00', 2),\n",
       " ('000 10 00 10', 2),\n",
       " ('000 00 00 01', 1),\n",
       " ('000 00 00 10', 1),\n",
       " ('000 01 00 01', 1),\n",
       " ('000 10 11 10', 1),\n",
       " ('000 11 01 01', 1),\n",
       " ('001 01 01 00', 1),\n",
       " ('001 01 01 01', 1),\n",
       " ('001 01 10 00', 1),\n",
       " ('001 10 10 00', 1),\n",
       " ('001 11 10 10', 1),\n",
       " ('010 00 00 00', 1),\n",
       " ('010 00 11 00', 1),\n",
       " ('010 01 00 11', 1),\n",
       " ('010 01 10 01', 1),\n",
       " ('010 10 00 00', 1),\n",
       " ('010 10 01 00', 1),\n",
       " ('010 11 00 00', 1),\n",
       " ('010 11 01 00', 1),\n",
       " ('100 00 10 10', 1),\n",
       " ('100 10 10 00', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cpp import process_scaler_dict\n",
    "\n",
    "\n",
    "processed_scaler_dict = process_scaler_dict(processed_scaler_dict)\n",
    "\n",
    "counts = cpp_probabilities.get_counts(memory, qubit_mapping, grid_dict, processed_scaler_dict, synd_rounds)\n",
    "(sorted(counts.items(), key=lambda x: x[1], reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-Sk8aHGSa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
