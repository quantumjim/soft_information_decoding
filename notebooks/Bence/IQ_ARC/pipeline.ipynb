{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:42<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ArcParams_class import ArcParams\n",
    "import utils\n",
    "\n",
    "from src import cpp_soft_info as csi\n",
    "from soft_info import inv_qubit_mapping\n",
    "\n",
    "\n",
    "def process_pSoft(pSoft, estim0Mat, estim1Mat, threshold):\n",
    "    pSoft_copy = pSoft.copy()\n",
    "    mask = ((estim0Mat < threshold) & (estim1Mat < threshold))\n",
    "    pSoft_copy[mask] = 0.5-1e-8\n",
    "\n",
    "    # calculate the filtered ratio\n",
    "    ratio = np.sum(mask) / (pSoft.shape[0]*pSoft.shape[1])\n",
    "    return pSoft_copy, ratio\n",
    "\n",
    "\n",
    "\n",
    "files = [f for f in os.listdir('data/IQ_data/') if os.path.isfile(os.path.join('data/IQ_data/', f))]\n",
    "\n",
    "for file in tqdm(files):\n",
    "\n",
    "    # Load and correct the data\n",
    "    with open('data/IQ_data/' + file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    with open('data/params/' + file, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "\n",
    "    cor_data = []\n",
    "    for idx, data_list in enumerate(data):\n",
    "        vstack = np.vstack(data_list)\n",
    "        if idx != 4:\n",
    "            vstack = vstack[:,vstack.shape[1]//2:]\n",
    "        cor_data.append(vstack)\n",
    "\n",
    "    # Create all memories\n",
    "    all_memories = {qubit: {} for qubit in range(127)}\n",
    "    all_memories_dbl = {qubit: {} for qubit in range(127)}\n",
    "    for qubit in all_memories.keys():\n",
    "        # all_memories[qubit]['mmr_0'] = np.hstack([cor_data[0][:, qubit], cor_data[2][:, qubit], cor_data[2][:, qubit+127]])\n",
    "        # all_memories[qubit]['mmr_1'] = np.hstack([cor_data[1][:, qubit], cor_data[3][:, qubit], cor_data[3][:, qubit+127]])\n",
    "        all_memories[qubit]['mmr_0'] = np.hstack([cor_data[0][:, qubit], cor_data[2][:, qubit]])\n",
    "        all_memories[qubit]['mmr_1'] = np.hstack([cor_data[1][:, qubit], cor_data[3][:, qubit] ])\n",
    "        all_memories_dbl[qubit]['mmr_0'] = cor_data[2][:, qubit]\n",
    "        all_memories_dbl[qubit]['mmr_1'] = cor_data[3][:, qubit]\n",
    "        all_memories_dbl[qubit]['mmr_0_scnd'] = cor_data[2][:, qubit+127]\n",
    "        all_memories_dbl[qubit]['mmr_1_scnd'] = cor_data[3][:, qubit+127]\n",
    "\n",
    "    # Get the KDEs\n",
    "    bandwidths = [0.6]\n",
    "    num_points = 51\n",
    "\n",
    "    kde_dict = csi.get_KDEs(all_memories, bandwidths, relError=1, absError=-1, num_points=num_points)\n",
    "\n",
    "    # Qubit lists\n",
    "    code_qubits = set()\n",
    "    ancilla_qubits = set()\n",
    "    for link in params.links:\n",
    "        code_qubits.add(link[0])\n",
    "        code_qubits.add(link[2])\n",
    "        ancilla_qubits.add(link[1])\n",
    "    code_qubits = list(code_qubits)\n",
    "    ancilla_qubits = list(ancilla_qubits)\n",
    "\n",
    "    # Get qubit mapping\n",
    "    memory = cor_data[4]\n",
    "    qubit_mapping = {}\n",
    "    for idx in range(memory.shape[1]):\n",
    "        if idx < params.T * len(ancilla_qubits):\n",
    "            qubit_mapping[idx] = ancilla_qubits[idx % len(ancilla_qubits)]\n",
    "        else:\n",
    "            qubit_mapping[idx] = code_qubits[idx - params.T * len(ancilla_qubits)]\n",
    "    inverted_q_map = inv_qubit_mapping(qubit_mapping)\n",
    "\n",
    "\n",
    "    # Get the matrices\n",
    "    threshold = 0.05\n",
    "    pSoft, countMat, estim0Mat, estim1Mat = csi.iqConvertorEstim(memory, inverted_q_map, kde_dict, relError=1, absError=-1)\n",
    "    weightMat = -np.log(pSoft/(1-pSoft))    \n",
    "    pSoft_trunc, ratio = process_pSoft(pSoft, estim0Mat, estim1Mat, threshold)\n",
    "\n",
    "    # Save the data\n",
    "    mat_dict = {\n",
    "        'pSoft': pSoft, # the probability of a soft flip (ndarray)\n",
    "        'countMat': countMat, # the estimated outcome of the IQ point (ndarray)\n",
    "        'estim0Mat': estim0Mat, # the probability to sample the IQ point if the qubit is in state 0 (ndarray)\n",
    "        'estim1Mat': estim1Mat, # the probability to sample the IQ point if the qubit is in state 1 (ndarray)\n",
    "        'weightMat': weightMat, # the weight -np.log(pSoft/(1-pSoft)) (ndarray)\n",
    "        'pSoft_trunc': pSoft_trunc, # the pSoft matrix with \"leakage\" points as maximally ambiguous (ndarray)\n",
    "        'leakage proportion': ratio, # the proportion of classified IQ points (float)\n",
    "    }\n",
    "    with open('data/matrices/' + file, 'wb') as f:\n",
    "        pickle.dump(mat_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pSoft (100, 7154)\n",
      "countMat (100, 7154)\n",
      "estim0Mat (100, 7154)\n",
      "estim1Mat (100, 7154)\n",
      "weightMat (100, 7154)\n",
      "pSoft_trunc (100, 7154)\n",
      "leakage proportion ()\n"
     ]
    }
   ],
   "source": [
    "for key, value in mat_dict.items():\n",
    "    print(key, value.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
