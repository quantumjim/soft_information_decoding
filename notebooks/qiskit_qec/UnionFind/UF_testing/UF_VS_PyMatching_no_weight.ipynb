{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>notebook_name</th>\n",
       "      <th>backend_name</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>shots</th>\n",
       "      <th>tags_xp</th>\n",
       "      <th>sampled_state</th>\n",
       "      <th>num_qubits</th>\n",
       "      <th>job_status</th>\n",
       "      <th>extra</th>\n",
       "      <th>optimization_level</th>\n",
       "      <th>code</th>\n",
       "      <th>distance</th>\n",
       "      <th>rounds</th>\n",
       "      <th>logical</th>\n",
       "      <th>layout</th>\n",
       "      <th>descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2023-10-30 09:43:24.564124+01:00</td>\n",
       "      <td>bigger_rep_codes</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cmzpsb5daqbg008sjvb0</td>\n",
       "      <td>[]</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>_is_hex=True</td>\n",
       "      <td>Run bigger Repetition codes v4: new distances ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2023-10-30 09:43:20.984078+01:00</td>\n",
       "      <td>bigger_rep_codes</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cmzpsa5vayrg008cpk30</td>\n",
       "      <td>[]</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>_is_hex=True</td>\n",
       "      <td>Run bigger Repetition codes v4: new distances ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        creation_date     notebook_name    backend_name  \\\n",
       "243  2023-10-30 09:43:24.564124+01:00  bigger_rep_codes  ibm_sherbrooke   \n",
       "242  2023-10-30 09:43:20.984078+01:00  bigger_rep_codes  ibm_sherbrooke   \n",
       "\n",
       "                   job_id tags    shots tags_xp sampled_state  num_qubits  \\\n",
       "243  cmzpsb5daqbg008sjvb0   []  10000.0     NaN           NaN         NaN   \n",
       "242  cmzpsa5vayrg008cpk30   []  10000.0     NaN           NaN         NaN   \n",
       "\n",
       "         job_status extra  optimization_level                   code  \\\n",
       "243  JobStatus.DONE   NaN                 NaN  RepetitionCodeCircuit   \n",
       "242  JobStatus.DONE   NaN                 NaN  RepetitionCodeCircuit   \n",
       "\n",
       "     distance rounds logical        layout  \\\n",
       "243      10.0     10       1  _is_hex=True   \n",
       "242      10.0     10       0  _is_hex=True   \n",
       "\n",
       "                                                 descr  \n",
       "243  Run bigger Repetition codes v4: new distances ...  \n",
       "242  Run bigger Repetition codes v4: new distances ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Scratch import metadata_loader\n",
    "\n",
    "DEVICE = 'ibm_sherbrooke'\n",
    "\n",
    "md = metadata_loader(_extract=True, _drop_inutile=True)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"notebook_name\"] == \"bigger_rep_codes\"]\n",
    "max_distance = int(max(md.distance))\n",
    "max_distance = 10\n",
    "md = md[md[\"distance\"] == max_distance]\n",
    "md = md[md[\"backend_name\"]==DEVICE]\n",
    "\n",
    "md = md[:2]\n",
    "\n",
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = {}\n",
    "for job_id, logical in zip(md.job_id, md.logical):\n",
    "    mmr_name = f\"mmr_log_{logical}\"\n",
    "    memories[mmr_name] = provider.retrieve_job(job_id).result().get_memory()\n",
    "\n",
    "memory = memories[\"mmr_log_0\"][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UF Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from qiskit_qec.circuits import RepetitionCodeCircuit\n",
    "from soft_info import get_repcode_layout, get_KDEs, get_counts\n",
    "\n",
    "layout = get_repcode_layout(distance=max_distance, backend=provider.get_backend(\"ibm_nazca\"), _is_hex=True)\n",
    "kde_dict, scaler_dict = get_KDEs(provider, DEVICE, layout, bandwidths=0.2, plot=False)\n",
    "code = RepetitionCodeCircuit(max_distance, max_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_qec.decoders.hdrg_decoders import UnionFindDecoder\n",
    "\n",
    "dcd_pkl_str = f\"dist_{max_distance}_decoder.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(f\"dist_{max_distance}_decoder.pkl\", 'rb') as f:\n",
    "        decoder = pickle.load(f)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"decoder not found, creating a new one...\")\n",
    "    code = RepetitionCodeCircuit(max_distance, max_distance)\n",
    "    decoder = UnionFindDecoder(code)    \n",
    "\n",
    "    print(\"saving the decoder...\")\n",
    "    with open(dcd_pkl_str, 'wb') as f:\n",
    "        pickle.dump(decoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<01:19, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0111001110 000001000 010100001 010001010 010000010 010000000 100000000 010000000 000000000 000000000 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [8], 'Cluster_1': [8], 'Cluster_2': [1, 0, 1], 'Cluster_3': [8, 8, 9, 2, 2, 4, 5]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:08<01:17, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0010011000 011111000 001101100 001101000 001100100 001101011 001001101 001101011 000001000 001101000 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [], 'Cluster_1': [2], 'Cluster_2': [8, 4, 9, 6, 4, 7, 5, 4, 5, 4, 6, 5, 6], 'Cluster_3': [0, 1], 'Cluster_4': [7]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 110/1000 [00:09<01:16, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 1111110100 000101110 001000000 000101100 000110000 001100000 001100000 001100000 011000000 101000000 001000000\n",
      "flipped_qubit_dict {'Cluster_0': [], 'Cluster_1': [9, 8, 6, 6, 8, 9], 'Cluster_2': [3, 6, 0, 1], 'Cluster_3': [6]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 122/1000 [00:10<01:12, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 1110010100 011001010 110010100 100001010 010001100 100000010 000001000 000010000 100001000 100010000 100010000\n",
      "flipped_qubit_dict {'Cluster_0': [], 'Cluster_1': [], 'Cluster_2': [4], 'Cluster_3': [9, 9, 9, 9, 9, 9], 'Cluster_4': [4, 0, 1, 7, 1, 5, 6, 2, 3, 1, 2], 'Cluster_5': [7]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 258/1000 [00:23<01:10, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0101010100 111100110 000011000 111100110 011100000 110101100 010100000 110101100 010100000 100100000 110000000\n",
      "flipped_qubit_dict {'Cluster_0': [8], 'Cluster_1': [3], 'Cluster_2': [9, 6, 9, 6, 7, 7, 8, 9], 'Cluster_3': [], 'Cluster_4': [2, 3, 0, 1, 2, 3], 'Cluster_5': [5], 'Cluster_6': [7]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 322/1000 [00:28<00:57, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 1010111000 010100111 101000011 010111011 001110010 010010000 001110010 010010000 000000010 000001000 000000010\n",
      "flipped_qubit_dict {'Cluster_0': [4, 0, 1, 2, 4, 2, 3, 3], 'Cluster_1': [9, 6, 9, 8], 'Cluster_2': [], 'Cluster_3': [4, 5, 5], 'Cluster_4': [4, 2]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 366/1000 [00:32<00:56, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0010001000 011000000 001001100 011001000 001000110 011000010 001000010 011000000 011000010 000000010 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [0, 5, 1, 0, 1, 6, 1, 1, 2, 0, 4, 1], 'Cluster_1': [7, 7, 8, 9], 'Cluster_2': []}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 428/1000 [00:38<00:46, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0001110110 001000011 001001110 001000011 001001111 000000011 000101110 000000000 000100000 000001000 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [], 'Cluster_1': [9, 7, 7, 4, 5, 2, 4, 2, 4, 5, 3, 5, 6, 4, 5, 7, 6, 8], 'Cluster_2': [0]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [00:44<00:45, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0100111110 110111010 000011011 000111010 000011100 000010000 000010000 000000000 000000000 000000000 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [4, 5, 6, 5, 6, 6, 2, 7, 3, 3, 9, 4], 'Cluster_1': [0, 2]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 646/1000 [00:57<00:30, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0001100011 001101000 001111011 001100011 001011000 001000000 001100000 001011000 001100000 001111000 001000000\n",
      "flipped_qubit_dict {'Cluster_0': [5, 4, 7, 8, 5, 9, 4, 7, 6, 6, 7, 8, 4, 8], 'Cluster_1': [], 'Cluster_2': [], 'Cluster_3': [], 'Cluster_4': [2, 3]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 704/1000 [01:02<00:25, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 1100000110 011001010 001000011 101010010 001001111 101010010 001001100 111000000 001001100 000000000 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [3], 'Cluster_1': [], 'Cluster_2': [8], 'Cluster_3': [0, 1, 1], 'Cluster_4': [6, 5, 7], 'Cluster_5': [3], 'Cluster_6': [4], 'Cluster_7': [8], 'Cluster_8': [3]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 786/1000 [01:10<00:19, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 1110111010 010010001 011110110 010010001 111110110 011010001 111000110 011000001 111000010 000000001 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [9, 9, 7, 8, 9, 7, 8, 9], 'Cluster_1': [0, 0, 2, 1, 3, 4, 2, 3, 1, 0, 5, 4, 2, 5, 6]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 792/1000 [01:10<00:17, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0010000100 001000010 011000110 001000010 011000110 001000011 011011111 001000010 011010100 001000000 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [6, 7, 5], 'Cluster_1': [], 'Cluster_2': [], 'Cluster_3': [3], 'Cluster_4': [], 'Cluster_5': [4], 'Cluster_6': [0, 1], 'Cluster_7': [7, 8, 9]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 906/1000 [01:20<00:07, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 1000110100 110110011 010011101 000110001 000101101 000110101 000010001 110111101 000010001 000000001 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [1, 1, 2, 5, 8, 2, 4, 5, 3, 4, 5, 5, 6, 9, 7, 8, 8, 8, 8, 9], 'Cluster_1': [], 'Cluster_2': [5], 'Cluster_3': [5], 'Cluster_4': [0, 1]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 914/1000 [01:21<00:07, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 0001110110 110011001 111010101 110011011 111011101 000000001 111011111 110000011 110000111 000000000 000000110\n",
      "flipped_qubit_dict {'Cluster_0': [2], 'Cluster_1': [8], 'Cluster_2': [8], 'Cluster_3': [4], 'Cluster_4': [7, 9], 'Cluster_5': [0, 0, 1, 1, 4, 1, 2, 0, 3, 1], 'Cluster_6': [8]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 948/1000 [01:24<00:04, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meas_str: 1110101000 111111110 110000010 111111110 010000000 110000110 000000000 110000000 000000000 110000000 000000000\n",
      "flipped_qubit_dict {'Cluster_0': [8], 'Cluster_1': [2], 'Cluster_2': [9, 8, 9], 'Cluster_3': [4], 'Cluster_4': [6], 'Cluster_5': [0, 1]}\n",
      "logical: [1] \n",
      "\n",
      "------------ Wrong logical! ------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:29<00:00, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logical_counts: {'0': 984, '1': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from soft_info import soft_reweight, get_counts, rx_draw_2D\n",
    "from tqdm import tqdm\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "logical_counts = {'0':0, '1':0}\n",
    "for shot in tqdm(range(len(memory))):\n",
    "    \n",
    "    with open(dcd_pkl_str, 'rb') as f: # Reload the decoder each time to reset the graph\n",
    "        decoder = pickle.load(f)\n",
    "\n",
    "    IQ_data = memory[shot]\n",
    "\n",
    "    counts = get_counts([IQ_data], kde_dict, scaler_dict, layout, max_distance, verbose=False)\n",
    "    count_key = next(iter(counts.keys()))\n",
    "    \n",
    "    logical, flipped_qubit_dict = decoder.process(count_key, _return_err_str = True)\n",
    "    \n",
    "    if VERBOSE and logical[0] == 1:\n",
    "        print(\"\\nmeas_str:\", count_key)\n",
    "        print(\"flipped_qubit_dict\", flipped_qubit_dict)\n",
    "        print(\"logical:\", logical, \"\\n\")\n",
    "            \n",
    "    if logical[0] == 1:\n",
    "            print(\"------------ Wrong logical! ------------\\n\")\n",
    "    logical_counts[f\"{logical[0]}\"] += 1\n",
    "\n",
    "print( \"\\nLogical_counts:\", logical_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "import pymatching\n",
    "\n",
    "d = max_distance\n",
    "T = max_distance\n",
    "\n",
    "circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                 distance=d,\n",
    "                                 rounds=T,\n",
    "                                 after_clifford_depolarization=0.1)\n",
    "\n",
    "model = circuit.detector_error_model(decompose_errors=True)\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from soft_info import get_counts, soft_reweight_pymatching, counts_to_det_syndr, draw_matching_graph, reweight_edges_to_one\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "actual_observables = np.array([[False]]) # hardcoded, can be retrieved\n",
    "num_errors = 0\n",
    "\n",
    "i = 0\n",
    "w_idx_lst = []\n",
    "for shot in tqdm(range(len(memory))):\n",
    "    i += 1\n",
    "    IQ_data = memory[shot]\n",
    "\n",
    "    counts = get_counts([IQ_data], kde_dict, scaler_dict, layout, T, verbose=False)\n",
    "    count_key = next(iter(counts.keys()))\n",
    "    \n",
    "    #soft_reweight_pymatching(matching, d, T, IQ_data, kde_dict, layout, scaler_dict, common_measure=0.01, verbose=False)  \n",
    "    reweight_edges_to_one(matching)\n",
    "\n",
    "    array_processed_string = counts_to_det_syndr(count_key, verbose=False)\n",
    "\n",
    "    predicted_observables = matching.decode(array_processed_string)\n",
    "\n",
    "    if predicted_observables == [0]:\n",
    "        continue\n",
    "    \n",
    "    #print(f\"Wrong decoding at index {i}\")\n",
    "    w_idx_lst.append(i)\n",
    "\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Count key:\", count_key)\n",
    "        print(\"count_string_to_syndromes:\", array_processed_string)\n",
    "\n",
    "    if VERBOSE:\n",
    "        draw_matching_graph(matching, d, T)\n",
    "\n",
    "    if VERBOSE:\n",
    "        matched_edges = matching.decode_to_edges_array(array_processed_string)\n",
    "        print(\"matched_edges: \", matched_edges)\n",
    "        print(\"Estimated flip:\", predicted_observables)\n",
    "\n",
    "    num_errors += not np.array_equal(actual_observables[0, :], predicted_observables) # 0 can be changed to i if multiple observables and multiple syndromes per ovbservable\n",
    "\n",
    "print(\"Num errors:\", num_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-Sk8aHGSa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
