{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cpp_soft_info\n",
    "\n",
    "from cpp_soft_info import soft_reweight_pymatching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n"
     ]
    }
   ],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()\n",
    "\n",
    "job = provider.retrieve_job(\"cmyhbrqrmwhg008bs4h0\") # Mumbai job\n",
    "# job = provider.retrieve_job(\"cn6g47862r90008810pg\") # Sherbrooke job\n",
    "\n",
    "memory = job.result().get_memory() \n",
    "print(memory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the qubit mapping...\n"
     ]
    }
   ],
   "source": [
    "from soft_info import get_repcode_IQ_map\n",
    "\n",
    "# Mumbai\n",
    "layout = [25, 19, 26, 22, 16] # To implement: into scratch job_data\n",
    "d = 3\n",
    "synd_rounds = 3\n",
    "\n",
    "# # Sherbrooke\n",
    "# layout = get_repcode_layout(30, provider.get_backend('ibm_sherbrooke') )\n",
    "# synd_rounds = 35\n",
    "\n",
    "print(\"Generating the qubit mapping...\")\n",
    "qubit_mapping = get_repcode_IQ_map(layout, synd_rounds) #Hardcoded for repetition codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of grid_dict (num of qubits): 27\n"
     ]
    }
   ],
   "source": [
    "from Scratch import create_or_load_kde_grid\n",
    "from cpp import process_scaler_dict\n",
    "\n",
    "# Example usage\n",
    "other_date = None # if none then it will find the closest to the tobecalib_job date\n",
    "# other_date = \"2023-11-22T10:30:00\" # \"2023-11-22T\" works too \n",
    "grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, \"cmyhbrqrmwhg008bs4h0\", 300, 2, other_date=other_date)\n",
    "# grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, \"cn6g47862r90008810pg\", 300, 2, other_date=other_date)\n",
    "print(\"len of grid_dict (num of qubits):\", len(grid_dict.keys()))\n",
    "\n",
    "counts = cpp_soft_info.get_counts(memory, qubit_mapping, grid_dict, processed_scaler_dict, synd_rounds)\n",
    "# (sorted(counts.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the qubit mapping...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import stim\n",
    "import pymatching\n",
    "\n",
    "from soft_info import get_repcode_IQ_map\n",
    "\n",
    "circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                 distance=d,\n",
    "                                 rounds=synd_rounds,\n",
    "                                 after_clifford_depolarization=0.1)\n",
    "\n",
    "model = circuit.detector_error_model(decompose_errors=True)\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "print(\"Generating the qubit mapping...\")\n",
    "qubit_mapping = get_repcode_IQ_map(layout, synd_rounds) #Hardcoded for repetition codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decode_IQ_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 18\n"
     ]
    }
   ],
   "source": [
    "num_errors = cpp_soft_info.decode_IQ_shots(matching._matching_graph, memory, synd_rounds, qubit_mapping, grid_dict, processed_scaler_dict, 6e-3, 0.49, 0.1)\n",
    "\n",
    "print(\"num_errors:\", num_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Processing graph\n"
     ]
    }
   ],
   "source": [
    "print(len(cpp_soft_info.get_edges(matching._matching_graph)))\n",
    "cpp_soft_info.processGraph_test(matching._matching_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n",
      "(1, 9)\n"
     ]
    }
   ],
   "source": [
    "IQ_data = memory[0]\n",
    "print(IQ_data.shape)\n",
    "IQ_data = IQ_data.reshape(1, -1)\n",
    "print(IQ_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_soft_info.soft_reweight_pymatching(matching._matching_graph, IQ_data, synd_rounds, qubit_mapping, grid_dict, processed_scaler_dict, 6.836e-3, 0.49, 0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 69.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from soft_info import counts_to_det_syndr, draw_matching_graph\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "actual_observables = np.array([[False]]) # hardcoded, can be retrieved\n",
    "num_errors = 0\n",
    "\n",
    "i = 0\n",
    "w_idx_lst = []\n",
    "for shot in tqdm(range(len(memory))[:1000]):\n",
    "    matching = pymatching.Matching.from_detector_error_model(model)\n",
    "    i += 1\n",
    "    IQ_data = memory[shot]\n",
    "    IQ_data_reshaped = IQ_data.reshape(1, -1)\n",
    "\n",
    "    counts = cpp_soft_info.get_counts(IQ_data_reshaped, qubit_mapping, grid_dict, processed_scaler_dict, synd_rounds)\n",
    "    count_key = next(iter(counts.keys()))\n",
    "\n",
    "    # if count_key == '000 00 00 00':\n",
    "        #print(\"Skipping all zeros\")\n",
    "        # continue    \n",
    "\n",
    "    cpp_soft_info.soft_reweight_pymatching(matching._matching_graph, IQ_data_reshaped, synd_rounds, qubit_mapping, grid_dict, processed_scaler_dict, 6.836e-3, 0.49, 0.1) \n",
    "\n",
    "\n",
    "    array_processed_string = counts_to_det_syndr(count_key, _resets=False, verbose=False)\n",
    "\n",
    "    predicted_observables = matching.decode(array_processed_string)\n",
    "\n",
    "    actual_observables = [(int(count_key[0])+0)%2]\n",
    "    if predicted_observables == actual_observables: #== [0]:\n",
    "        continue\n",
    "    num_errors += 1\n",
    "    # print(\"num_errors:\", num_errors)\n",
    "    \n",
    "    #print(f\"Wrong decoding at index {i}\")\n",
    "    w_idx_lst.append(i)\n",
    "\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Count key:\", count_key)\n",
    "        print(\"count str to syndromes:\", array_processed_string)\n",
    "\n",
    "\n",
    "    if VERBOSE:\n",
    "        matched_edges = matching.decode_to_edges_array(array_processed_string)\n",
    "        print(\"matched_edges: \", matched_edges)\n",
    "        print(\"Estimated flip:\", predicted_observables)\n",
    "        print(\"Actual flip:\", actual_observables)\n",
    "    \n",
    "\n",
    "    if VERBOSE:\n",
    "        draw_matching_graph(matching, d, synd_rounds, syndromes=array_processed_string, matched_edges=matched_edges, figsize=(6, 6))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num errors:\", num_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
