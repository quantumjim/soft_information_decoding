{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'/Users/mha/My Drive/Desktop/Studium/Physik/MSc/Semester 3/IBM/IBM GIT/Soft-Info/build')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cpp_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old get_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n"
     ]
    }
   ],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()\n",
    "backend = provider.get_backend('ibmq_mumbai') \n",
    "job = provider.retrieve_job(\"cmyhbrqrmwhg008bs4h0\") # Mumbai job\n",
    "# job = provider.retrieve_job(\"cn6g47862r90008810pg\") # Sherbrooke job\n",
    "memory = job.result().get_memory()\n",
    "\n",
    "print(memory.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:00:39 Warning: Missing layout or synd_rounds, estimating outcomes without KDEs.. IN FILE: /Users/mha/My Drive/Desktop/Studium/Physik/MSc/Semester 3/IBM/IBM GIT/Soft-Info/src/soft_info/Probabilities/probabilities.py, LINE: 67\n",
      "10:00:39 Warning: Not enough kernels or no scaler provided. Using the magnitude of the real part for estimation... IN FILE: /Users/mha/My Drive/Desktop/Studium/Physik/MSc/Semester 3/IBM/IBM GIT/Soft-Info/src/soft_info/Probabilities/probabilities.py, LINE: 28\n",
      "{'000000000': 622, '000100000': 95, '000000010': 65, '000001000': 61, '000101000': 20, '000101010': 15, '000100010': 12, '000001010': 9, '001000000': 9, '000010101': 7, '010000000': 6, '010110011': 5, '100101000': 5, '100100010': 5, '000010000': 5, '000000100': 5, '100001000': 5, '001000100': 4, '001010001': 3, '001010000': 3, '100100000': 3, '010100100': 2, '000110101': 2, '000000110': 2, '100101010': 2, '100000000': 2, '100001010': 2, '001011000': 2, '000011000': 2, '000010100': 2, '010110010': 1, '010011011': 1, '001010101': 1, '000011101': 1, '010011001': 1, '000100100': 1, '001101000': 1, '001001000': 1, '010001100': 1, '000110111': 1, '000010010': 1, '001010100': 1, '001100000': 1, '000010001': 1, '010101000': 1, '001110001': 1, '010100010': 1, '001111010': 1}\n"
     ]
    }
   ],
   "source": [
    "from soft_info import get_counts\n",
    "\n",
    "counts_default = get_counts(memory)\n",
    "print(counts_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating the qubit mapping\n"
     ]
    }
   ],
   "source": [
    "from soft_info import get_KDEs, get_repcode_layout, get_repcode_IQ_map\n",
    "\n",
    "layout = [25, 19, 26, 22, 16] # To implement: into scratch job_data\n",
    "# layout = get_repcode_layout(30, provider.get_backend('ibm_sherbrooke') )\n",
    "# kde_dict, scaler_dict = get_KDEs(provider, 'ibm_sherbrooke', list(range(127)), bandwidths=0.2, plot=False)\n",
    "kde_dict, scaler_dict = get_KDEs(provider, 'ibmq_mumbai', list(range(27)), bandwidths=0.2, plot=False)\n",
    "\n",
    "# counts_kde = get_counts(memory, kde_dict, scaler_dict, layout, 3, verbose=True)\n",
    "#counts_kde = get_counts(memory, kde_dict, scaler_dict, layout, 35, verbose=True) # hardcoded num of rounds can be retrieved from metadata\n",
    "# (counts_kde)\n",
    "\n",
    "\n",
    "# synd_rounds = 35\n",
    "synd_rounds = 3\n",
    "print(\"generating the qubit mapping\")\n",
    "qubit_mapping = get_repcode_IQ_map(layout, synd_rounds) #Hardcoded for repetition codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE GRID DATA\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "grid_dict = {}\n",
    "num_points = 10\n",
    "for qubit_idx, (kde_0, kde_1) in kde_dict.items():\n",
    "    scaler = scaler_dict[qubit_idx]\n",
    "\n",
    "    # Retrieve the dataset for this qubit and split into real and imaginary parts\n",
    "    data = np.array(memory[0])  # TODO change that: Retrieving data from memory 0 to get the min and max values\n",
    "    data_real_imag = np.column_stack([np.real(data), np.imag(data)])\n",
    "\n",
    "    # Scale data\n",
    "    scaled_data = scaler.transform(data_real_imag)\n",
    "\n",
    "    # Create grid\n",
    "    grid_x, grid_y = np.linspace(scaled_data[:, 0].min() - 1, scaled_data[:, 0].max() + 1, num_points), \\\n",
    "                     np.linspace(scaled_data[:, 1].min() - 1, scaled_data[:, 1].max() + 1, num_points)\n",
    "    grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "    grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "\n",
    "    # Evaluate KDE on the grid for both states\n",
    "    grid_density_0 = (kde_0.score_samples(grid_points)).reshape(grid_x.shape)\n",
    "    grid_density_1 = (kde_1.score_samples(grid_points)).reshape(grid_x.shape)\n",
    "    \n",
    "    # Create an instance of GridData and store in dictionary\n",
    "    grid_dict[qubit_idx] = cpp_probabilities.GridData(grid_x, grid_y, grid_density_0, grid_density_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ((16191256.63047, 79778555.89041053), (-290404428.44672, 28557074.80284494)), 1: ((5646029.46578, 50568255.50599121), (-186472147.246225, 16267425.019498207)), 2: ((-4238816.391285, 88160499.3805419), (-391237681.971145, 29032984.73295442)), 3: ((-12240638.5723, 155118328.32731992), (-601195720.27544, 26260367.881752755)), 4: ((-22495357.2465, 76163548.3039887), (-283866370.470445, 25748324.91243394)), 5: ((-14245404.47146, 55197760.24809961), (-196167856.96216, 19290952.08405311)), 6: ((-36802784.474975, 60721563.428868), (-214231587.28699, 17274180.5970455)), 7: ((-21676680.22909, 92781647.52589713), (-454609690.78202, 31299065.422852404)), 8: ((-32365717.730365, 74614953.78947219), (-366640585.3899, 21497304.853535526)), 9: ((-10388631.422875, 58098621.79971227), (-225683537.41576, 18409504.110770237)), 10: ((1189200.634215, 27779842.93438666), (-99880449.50942, 10234355.218898227)), 11: ((-8313140.09236, 22722333.94450446), (-98752547.272965, 9961866.585303377)), 12: ((-5247261.520185, 26841567.365246035), (-113525605.569195, 12070309.215229347)), 13: ((-772868.277215, 29088583.293005303), (-118467701.82286, 8261055.246514626)), 14: ((-679804.64363, 18613348.236889705), (-77602839.23295, 8439695.623985326)), 15: ((-2093503.31037, 35954869.09773598), (-111989949.663205, 16902107.52523343)), 16: ((-15054689.84866, 43030085.92351306), (-171775482.20545, 11025414.663990451)), 17: ((-5682994.747965, 53162110.38005293), (-191358710.469185, 17710713.792064063)), 18: ((3759676.28392, 35706961.36362564), (-151186856.856455, 20429956.92084597)), 19: ((46078878.89246, 93626334.06410414), (-487182418.51347, 29400351.076957945)), 20: ((5782925.12813, 62410784.58008803), (-196942655.491005, 21348829.531102184)), 21: ((2563934.82494, 53812462.36516109), (-201269082.184315, 19773730.477754533)), 22: ((68660175.359795, 205405018.4420635), (-857861359.31856, 83371461.77232432)), 23: ((-8950903.583165, 69006313.569531), (-251808767.79903, 29913806.89794099)), 24: ((6626013.733605, 79111109.85992423), (-405526448.22288, 35812881.66092345)), 25: ((-7634851.820045, 81131595.10988283), (-325682916.04152, 30630348.076221693)), 26: ((5187241.311095, 56463708.38369554), (-237560938.532715, 19646500.454129662))}\n"
     ]
    }
   ],
   "source": [
    "def process_scaler_dict(scaler_dict):\n",
    "    processed_dict = {}\n",
    "    for qubit_idx, scaler in scaler_dict.items():\n",
    "        # Assuming the scaler is fit on complex data with real and imaginary parts as separate features\n",
    "        # Hence, the mean_ and scale_ arrays should have two elements each\n",
    "        if len(scaler.mean_) != 2 or len(scaler.scale_) != 2:\n",
    "            raise ValueError(f\"Scaler for qubit {qubit_idx} is not fit on complex data.\")\n",
    "        \n",
    "        mean_real, mean_imag = scaler.mean_\n",
    "        std_real, std_imag = scaler.scale_\n",
    "        processed_dict[qubit_idx] = ((mean_real, std_real), (mean_imag, std_imag))\n",
    "\n",
    "    return processed_dict\n",
    "\n",
    "processed_scaler_dict = process_scaler_dict(scaler_dict)\n",
    "\n",
    "print(processed_scaler_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000 00 00 00', 857),\n",
       " ('000 01 00 00', 18),\n",
       " ('000 00 01 00', 11),\n",
       " ('000 01 01 01', 11),\n",
       " ('000 10 10 10', 11),\n",
       " ('001 00 00 00', 8),\n",
       " ('100 00 10 00', 8),\n",
       " ('100 10 00 10', 7),\n",
       " ('000 10 00 00', 6),\n",
       " ('000 10 10 00', 6),\n",
       " ('001 01 00 01', 5),\n",
       " ('010 11 00 11', 5),\n",
       " ('000 00 00 01', 4),\n",
       " ('001 00 01 00', 4),\n",
       " ('001 01 00 00', 4),\n",
       " ('100 10 00 00', 4),\n",
       " ('000 00 10 00', 3),\n",
       " ('010 00 00 00', 3),\n",
       " ('100 00 00 00', 3),\n",
       " ('000 00 10 10', 2),\n",
       " ('000 01 01 00', 2),\n",
       " ('000 10 00 10', 2),\n",
       " ('000 00 00 10', 1),\n",
       " ('000 11 01 01', 1),\n",
       " ('000 11 11 10', 1),\n",
       " ('001 01 01 00', 1),\n",
       " ('001 01 01 01', 1),\n",
       " ('001 10 10 00', 1),\n",
       " ('001 11 10 10', 1),\n",
       " ('010 00 11 00', 1),\n",
       " ('010 01 00 11', 1),\n",
       " ('010 01 10 01', 1),\n",
       " ('010 10 00 00', 1),\n",
       " ('010 10 01 00', 1),\n",
       " ('010 11 00 00', 1),\n",
       " ('010 11 01 00', 1),\n",
       " ('100 00 10 01', 1),\n",
       " ('100 10 10 00', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = cpp_probabilities.get_counts(memory, qubit_mapping, grid_dict, processed_scaler_dict, synd_rounds)\n",
    "(sorted(counts.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([79778555.89041053, 28557074.80284494])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the mean and standard deviation out of the scaler_dict\n",
    "\n",
    "scaler = scaler_dict[0]\n",
    "\n",
    "mean = scaler.mean_\n",
    "std = scaler.scale_\n",
    "\n",
    "mean\n",
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New get counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating the qubit mapping\n",
      "rescaling the IQ data\n",
      "(1000, 18)\n"
     ]
    }
   ],
   "source": [
    "# RESCALE IQ DATA\n",
    "\n",
    "import warnings\n",
    "\n",
    "from soft_info import get_repcode_IQ_map\n",
    "\n",
    "def rescale_IQ_data(IQ_data, qubit_mapping, scaler_dict):\n",
    "    scaled_IQ_data = []\n",
    "\n",
    "    for shot in IQ_data:\n",
    "        scaled_shot = []\n",
    "        for idx, IQ_point in enumerate(shot):\n",
    "            if qubit_mapping is not None and idx in qubit_mapping:\n",
    "                qubit_idx = qubit_mapping[idx]\n",
    "                scaler = scaler_dict.get(qubit_idx)\n",
    "\n",
    "                if scaler is not None:\n",
    "                    # Scale the IQ point\n",
    "                    scaled_point = scaler.transform([[np.real(IQ_point), np.imag(IQ_point)]])\n",
    "                    scaled_shot.extend(scaled_point[0])  # Flatten the 2D array to 1D and extend the shot -> [real1, imag1, real2, imag2, ..., realN, imagN]\n",
    "                else:\n",
    "                    # Handle the case where no scaler is found for the qubit_idx\n",
    "                    warnings.warn(f\"No scaler found for qubit {qubit_idx}. IQ data will be appended unscaled.\")\n",
    "                    scaled_shot.extend([np.real(IQ_point), np.imag(IQ_point)])\n",
    "            else:\n",
    "                # Handle the case where idx is not in qubit_mapping\n",
    "                scaled_shot.extend([np.real(IQ_point), np.imag(IQ_point)])\n",
    "\n",
    "        scaled_IQ_data.append(scaled_shot)\n",
    "\n",
    "    return np.array(scaled_IQ_data)\n",
    "\n",
    "# synd_rounds = 35\n",
    "synd_rounds = 3\n",
    "print(\"generating the qubit mapping\")\n",
    "qubit_mapping = get_repcode_IQ_map(layout, synd_rounds) #Hardcoded for repetition codes\n",
    "print(\"rescaling the IQ data\")\n",
    "scaled_IQ_data = rescale_IQ_data(memory, qubit_mapping, scaler_dict)\n",
    "print(scaled_IQ_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000 00 00 00', 857),\n",
       " ('000 01 00 00', 18),\n",
       " ('000 00 01 00', 11),\n",
       " ('000 01 01 01', 11),\n",
       " ('000 10 10 10', 11),\n",
       " ('001 00 00 00', 8),\n",
       " ('100 00 10 00', 8),\n",
       " ('100 10 00 10', 7),\n",
       " ('000 10 00 00', 6),\n",
       " ('000 10 10 00', 6),\n",
       " ('001 01 00 01', 5),\n",
       " ('010 11 00 11', 5),\n",
       " ('000 00 00 01', 4),\n",
       " ('001 00 01 00', 4),\n",
       " ('001 01 00 00', 4),\n",
       " ('100 10 00 00', 4),\n",
       " ('000 00 10 00', 3),\n",
       " ('010 00 00 00', 3),\n",
       " ('100 00 00 00', 3),\n",
       " ('000 00 10 10', 2),\n",
       " ('000 01 01 00', 2),\n",
       " ('000 10 00 10', 2),\n",
       " ('000 00 00 10', 1),\n",
       " ('000 11 01 01', 1),\n",
       " ('000 11 11 10', 1),\n",
       " ('001 01 01 00', 1),\n",
       " ('001 01 01 01', 1),\n",
       " ('001 10 10 00', 1),\n",
       " ('001 11 10 10', 1),\n",
       " ('010 00 11 00', 1),\n",
       " ('010 01 00 11', 1),\n",
       " ('010 01 10 01', 1),\n",
       " ('010 10 00 00', 1),\n",
       " ('010 10 01 00', 1),\n",
       " ('010 11 00 00', 1),\n",
       " ('010 11 01 00', 1),\n",
       " ('100 00 10 01', 1),\n",
       " ('100 10 10 00', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = cpp_probabilities.get_counts_old(scaled_IQ_data, qubit_mapping, grid_dict, synd_rounds )\n",
    "(sorted(counts.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 1, 2: 0, 3: 1, 4: 1, 5: 0, 6: 1, 7: 0, 8: 0}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Assuming you have some function to create your grid data\n",
    "def create_your_grid_data(num_points):\n",
    "    # Replace this with your actual grid data creation logic\n",
    "    grid_x, grid_y = np.meshgrid(np.linspace(0, 1, num_points), np.linspace(0, 1, num_points))\n",
    "    grid_density_0 = np.random.rand(num_points, num_points)  # Placeholder values\n",
    "    grid_density_1 = np.random.rand(num_points, num_points)  # Placeholder values\n",
    "    return grid_x, grid_y, grid_density_0, grid_density_1\n",
    "\n",
    "def create_specific_grid_data(num_points):\n",
    "    # Create a meshgrid\n",
    "    grid_x, grid_y = np.meshgrid(np.linspace(0, 1, num_points), np.linspace(0, 1, num_points))\n",
    "\n",
    "    # Create grid densities: all zeros for grid_density_0 and all 0.5s for grid_density_1\n",
    "    grid_density_0 = np.zeros((num_points, num_points))\n",
    "    grid_density_1 = np.full((num_points, num_points), 0.5)\n",
    "\n",
    "    return grid_x, grid_y, grid_density_0, grid_density_1\n",
    "\n",
    "\n",
    "# Create instances of GridData for each qubit\n",
    "kde_grid_dict = {}\n",
    "for qubit_idx in range(2):  # Assuming two qubits\n",
    "    grid_x, grid_y, grid_density_0, grid_density_1 = create_specific_grid_data(100)\n",
    "\n",
    "    kde_grid_dict[qubit_idx] = cpp_probabilities.GridData(grid_x, grid_y, grid_density_0, grid_density_1)\n",
    "\n",
    "\n",
    "def generate_random_qubit_mapping(num_keys):\n",
    "    \"\"\"\n",
    "    Generates a random qubit mapping.\n",
    "\n",
    "    Args:\n",
    "    num_keys (int): The number of keys in the mapping.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are mapped randomly to either 0 or 1.\n",
    "    \"\"\"\n",
    "    qubit_mapping = {}\n",
    "    for i in range(num_keys):\n",
    "        qubit_mapping[i] = random.randint(0, 1)\n",
    "    return qubit_mapping\n",
    "\n",
    "# Example usage\n",
    "len_IQ = 9   # Number of keys in the mapping\n",
    "qubit_mapping = generate_random_qubit_mapping(len_IQ)\n",
    "print(qubit_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('111 11 11 11', 100)]\n"
     ]
    }
   ],
   "source": [
    "# Example NumPy array (replace this with your actual data)\n",
    "scaled_IQ_data_np = np.random.rand(int(1e2), len_IQ*2)  # 10 shots, len_IQ columns (2 measurements per shot)\n",
    "\n",
    "# Convert NumPy array to Eigen::MatrixXd\n",
    "scaled_IQ_data = cpp_probabilities.numpy_to_eigen(scaled_IQ_data_np)\n",
    "\n",
    "\n",
    "# Example number of syndrome rounds\n",
    "synd_rounds = 3\n",
    "\n",
    "# Call the get_counts function\n",
    "counts = cpp_probabilities.get_counts(scaled_IQ_data, qubit_mapping, kde_grid_dict, synd_rounds)\n",
    "print(sorted(counts.items(), key=lambda x: x[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-Sk8aHGSa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
