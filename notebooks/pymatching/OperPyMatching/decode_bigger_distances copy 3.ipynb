{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatching\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from soft_info import get_repcode_IQ_map, llh_ratio\n",
    "\n",
    "def process_string(input_str, verbose=False):\n",
    "    # Step 1: Invert the order of the string\n",
    "    reversed_str = input_str[::-1]\n",
    "    if verbose:\n",
    "        print(\"Reversed str:\", reversed_str)\n",
    "\n",
    "    # Step 2: Separate the last part of the string\n",
    "    last_part = reversed_str.split(\" \")[-1]\n",
    "    if verbose:\n",
    "        print(\"Count str:\", last_part)\n",
    "    \n",
    "    # Step 3: Perform XOR operations on the last part\n",
    "    xor_result = ''.join([str((int(last_part[i]) + int(last_part[i + 1])) % 2) for i in range(len(last_part) - 1)])\n",
    "    if verbose:\n",
    "        print(\"XOR result:\", xor_result)\n",
    "    \n",
    "    # Step 4: Remove the remaining spaces in the first part of the string\n",
    "    first_part = ''.join(reversed_str.split(\" \")[:-1])\n",
    "    if verbose:\n",
    "        print(\"First part:\", first_part)\n",
    "    \n",
    "    # Step 5: Separate each bit of the string into a list of a NumPy array\n",
    "    numpy_list = np.array([int(bit) for bit in first_part]+ [int(bit) for bit in xor_result])\n",
    "    if verbose:\n",
    "        print(\"Numpy list:\", numpy_list)\n",
    "    \n",
    "    return numpy_list\n",
    "\n",
    "\n",
    "def reweight_edges_to_one(matching: pymatching.Matching):\n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        fault_ids = edge_data.get('fault_ids', set())\n",
    "        error_probability = edge_data.get('error_probability', -1.0)\n",
    "        \n",
    "        if tgt_node is None:\n",
    "            matching.add_boundary_edge(src_node, weight=1, fault_ids=fault_ids, \n",
    "                              error_probability=error_probability, merge_strategy=\"replace\")\n",
    "        else:\n",
    "            matching.add_edge(src_node, tgt_node, weight=1, fault_ids=fault_ids, \n",
    "                          error_probability=error_probability, merge_strategy=\"replace\")\n",
    "\n",
    "\n",
    "def soft_reweight_pymatching(matching : pymatching.Matching,  d : int, T : int, IQ_data, \n",
    "                             kde_dict: dict, layout : list, scaler_dict : dict,\n",
    "                             p_data : float = None, p_meas : float = None, common_measure = None,\n",
    "                             verbose : bool = False):\n",
    "\n",
    "    p_data = p_data if p_data is not None else 6.836e-3  # Sherbrooke median\n",
    "    p_meas = p_meas if p_meas is not None else 0\n",
    "\n",
    "    if layout is not None:\n",
    "        qubit_mapping = get_repcode_IQ_map(layout, T)\n",
    "\n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        if verbose:\n",
    "            print(\"\\nEdge:\", (src_node, tgt_node))\n",
    "        fault_ids = edge_data.get('fault_ids', set())\n",
    "        error_probability = edge_data.get('error_probability', -1.0)\n",
    "        \n",
    "        if tgt_node is None:  # always second pose None\n",
    "            # Boundary edge (logical on it)\n",
    "            new_weight = -np.log(p_data / (1 - p_data))\n",
    "\n",
    "            if common_measure is not None:\n",
    "                new_weight = round(new_weight / common_measure) * common_measure\n",
    "                \n",
    "            matching.add_boundary_edge(src_node, weight=new_weight, fault_ids=fault_ids, \n",
    "                              error_probability=error_probability, merge_strategy=\"replace\")\n",
    "            if verbose:\n",
    "                print(\"Boundary edge weight: \", new_weight)\n",
    "\n",
    "            _has_time_component = False\n",
    "            continue\n",
    "        elif tgt_node == src_node + 1:  # always first pos the smaller\n",
    "            # Data edge\n",
    "            new_weight = -np.log(p_data / (1 - p_data))\n",
    "            if common_measure is not None:\n",
    "                new_weight = round(new_weight / common_measure) * common_measure\n",
    "            if verbose:\n",
    "                print(\"Data edge weight: \", new_weight)\n",
    "        elif tgt_node == src_node + (d-1):\n",
    "            # Time edge\n",
    "            #TODO implement adding a new edge for hard meas flip\n",
    "            new_weight = 0 #-np.log(p_meas / (1 - p_meas))\n",
    "            _has_time_component = True\n",
    "            if verbose:\n",
    "                print(\"Time edge weight: \", new_weight)\n",
    "        elif tgt_node == src_node + (d-1) + 1:\n",
    "            # mixed edge\n",
    "            # TODO implement adding a new DIAG edge for hard meas flip\n",
    "            new_weight = -np.log(p_data / (1 - p_data))# - np.log(p_meas / (1 - p_meas))\n",
    "            _has_time_component = True\n",
    "            if verbose:\n",
    "                print(\"Mixed edge weight: \", new_weight)\n",
    "\n",
    "        if _has_time_component: \n",
    "            #Structure of IQ data = [link_0, link_1, link_3, link_0, link_1, .., code_qubit_1, ...]\n",
    "            # equivalent to       = [node_0, node_1, node_3, node_4, node_5, .. ]\n",
    "            # =>\n",
    "            IQ_point = IQ_data[src_node]\n",
    "            layout_qubit_idx = qubit_mapping[src_node]\n",
    "            kde_0, kde_1 = kde_dict.get(layout_qubit_idx, (None, None))\n",
    "            scaler = scaler_dict.get(layout_qubit_idx, None)\n",
    "            llh_weight = llh_ratio(IQ_point, kde_0, kde_1, scaler)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"LLH weight: \", llh_weight)\n",
    "        \n",
    "            new_weight += llh_weight\n",
    "\n",
    "            # Round the weights to common measure\n",
    "            if common_measure is not None:\n",
    "                new_weight = round(new_weight / common_measure) * common_measure\n",
    "\n",
    "        # Update the edge weight\n",
    "        matching.add_edge(src_node, tgt_node, weight=new_weight, fault_ids=fault_ids, \n",
    "                          error_probability=error_probability, merge_strategy=\"replace\")\n",
    "\n",
    "\n",
    "\n",
    "def draw_matching_graph(matching, d, T):\n",
    "    G = nx.Graph()\n",
    "    pos = {}\n",
    "    edge_colors = []\n",
    "    \n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        if tgt_node is not None:\n",
    "            G.add_edge(src_node, tgt_node, weight=edge_data['weight'])\n",
    "            if edge_data.get('fault_ids'):\n",
    "                edge_colors.append('r')\n",
    "            else:\n",
    "                edge_colors.append('k')\n",
    "        \n",
    "        x_src = src_node % (d-1)\n",
    "        y_src = src_node // (d-1)\n",
    "        pos[src_node] = (x_src, -y_src)\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=True, node_color='white', edge_color=edge_colors, font_weight='bold', node_size=700, font_size=18)\n",
    "    \n",
    "    edge_weights = nx.get_edge_attributes(G, 'weight')\n",
    "    labels = {k: f\"{v:.2f}\" for k, v in edge_weights.items()}\n",
    "    \n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        if tgt_node is None:\n",
    "            x_src = src_node % (d-1)\n",
    "            y_src = src_node // (d-1)\n",
    "            color = 'r' if edge_data.get('fault_ids') == set() else 'k'\n",
    "            weight_text = f\"{edge_data.get('weight'):.2f}\"\n",
    "            if x_src == 0:\n",
    "                plt.plot([x_src, x_src - 0.5], [-y_src, -y_src], color=color)\n",
    "                plt.text(x_src - 0.3, -y_src + 0.05, weight_text)\n",
    "            elif x_src == d - 2:\n",
    "                plt.plot([x_src, x_src + 0.5], [-y_src, -y_src], color=color)\n",
    "                plt.text(x_src + 0.2, -y_src + 0.05, weight_text)\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='skyblue', node_size=700)\n",
    "    \n",
    "    plt.show()      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>notebook_name</th>\n",
       "      <th>backend_name</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>shots</th>\n",
       "      <th>tags_xp</th>\n",
       "      <th>sampled_state</th>\n",
       "      <th>num_qubits</th>\n",
       "      <th>job_status</th>\n",
       "      <th>extra</th>\n",
       "      <th>optimization_level</th>\n",
       "      <th>code</th>\n",
       "      <th>distance</th>\n",
       "      <th>rounds</th>\n",
       "      <th>logical</th>\n",
       "      <th>layout</th>\n",
       "      <th>descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2023-10-29 14:47:58.814875+01:00</td>\n",
       "      <td>bigger_rep_codes</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cmz653m3r3vg008wf9j0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>_is_hex=True</td>\n",
       "      <td>Run bigger Repetition codes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2023-10-29 14:47:43.903639+01:00</td>\n",
       "      <td>bigger_rep_codes</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cmz64zvvcq70008qdxcg</td>\n",
       "      <td>[]</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>_is_hex=True</td>\n",
       "      <td>Run bigger Repetition codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       creation_date     notebook_name    backend_name  \\\n",
       "76  2023-10-29 14:47:58.814875+01:00  bigger_rep_codes  ibm_sherbrooke   \n",
       "75  2023-10-29 14:47:43.903639+01:00  bigger_rep_codes  ibm_sherbrooke   \n",
       "\n",
       "                  job_id tags   shots tags_xp sampled_state  num_qubits  \\\n",
       "76  cmz653m3r3vg008wf9j0   []  1111.0     NaN           NaN         NaN   \n",
       "75  cmz64zvvcq70008qdxcg   []  1111.0     NaN           NaN         NaN   \n",
       "\n",
       "        job_status extra  optimization_level                   code  distance  \\\n",
       "76  JobStatus.DONE   NaN                 NaN  RepetitionCodeCircuit      30.0   \n",
       "75  JobStatus.DONE   NaN                 NaN  RepetitionCodeCircuit      30.0   \n",
       "\n",
       "   rounds logical        layout                        descr  \n",
       "76     30       1  _is_hex=True  Run bigger Repetition codes  \n",
       "75     30       0  _is_hex=True  Run bigger Repetition codes  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Scratch import metadata_loader\n",
    "\n",
    "md = metadata_loader(_extract=True, _drop_inutile=True)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"notebook_name\"] == \"bigger_rep_codes\"]\n",
    "max_distance = int(max(md.distance))\n",
    "max_distance = 30\n",
    "md = md[md[\"distance\"] == max_distance]\n",
    "md = md.sort_values(by='backend_name', ascending=False)\n",
    "\n",
    "md = md[:2]\n",
    "\n",
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmr_log_1': array([[ -9827335.+1.37223950e+07j, -53977778.+7.99818970e+07j,\n",
       "         -79071209.-9.83478680e+07j, ...,  -8432334.-7.54241200e+06j,\n",
       "          -5175264.-8.50117500e+06j,   6540639.-5.34872300e+06j],\n",
       "        [-10489210.+2.02035840e+07j, -83693508.+7.02712640e+07j,\n",
       "         -68739961.-8.00257260e+07j, ...,  -6971682.-7.36254800e+06j,\n",
       "          -4029180.-5.24985200e+06j,  12069718.-1.06493800e+07j],\n",
       "        [-14341855.+1.95327160e+07j, -72534674.+6.55941800e+07j,\n",
       "         -67845350.-1.14758427e+08j, ...,  -6694234.-5.57350800e+06j,\n",
       "         -10807815.-1.09097600e+07j,   7684249.-1.06278620e+07j],\n",
       "        ...,\n",
       "        [ -8225117.+9.95315900e+06j, -71635045.+6.52791880e+07j,\n",
       "         -62033555.-8.20048330e+07j, ...,   6253861.-8.49423500e+06j,\n",
       "           5556042.-8.86801300e+06j,   8736877.-1.35674410e+07j],\n",
       "        [-16130944.+1.36266200e+07j, -57588956.+5.27301930e+07j,\n",
       "         -58264550.-6.76114050e+07j, ...,  -7844011.-9.03883700e+06j,\n",
       "          -8234982.-9.29126300e+06j,   7097406.-1.05180100e+07j],\n",
       "        [-10159204.+1.71725800e+07j,  41608565.+2.31402110e+07j,\n",
       "         -60927093.-1.00602875e+08j, ...,  -7542062.-7.72305700e+06j,\n",
       "          -4630544.-8.98465800e+06j,   8467685.-8.91631100e+06j]]),\n",
       " 'mmr_log_0': array([[ -9495844.+2.37349820e+07j, -98249037.+7.07944800e+07j,\n",
       "         -91251145.-6.80010380e+07j, ...,   5499154.-8.33454300e+06j,\n",
       "           4616453.-6.24920600e+06j,   6210021.-1.08461780e+07j],\n",
       "        [-12499268.+1.98446980e+07j, -55167702.+7.80497620e+07j,\n",
       "         -62437023.-6.50206680e+07j, ...,  -5553466.-8.74111900e+06j,\n",
       "          -5543523.-8.35412500e+06j,  -5620493.-7.52561100e+06j],\n",
       "        [-14455590.+5.84343800e+06j, -53468562.+8.00115980e+07j,\n",
       "         -85745914.-8.54763890e+07j, ...,  -8138431.-7.90008200e+06j,\n",
       "          -5809081.-9.94645800e+06j,   6267843.-9.36213200e+06j],\n",
       "        ...,\n",
       "        [-15780259.+1.86127130e+07j, -47527731.+5.10565990e+07j,\n",
       "         -66990200.-8.15954630e+07j, ...,  -5954940.-7.28846500e+06j,\n",
       "           4369374.-1.00604390e+07j,   9012245.-8.04985600e+06j],\n",
       "        [ 18651242.+1.33791960e+07j, -66315235.+5.95471470e+07j,\n",
       "         -88377218.-1.01546996e+08j, ...,  -5061825.-6.49760600e+06j,\n",
       "          -5840643.-8.58432800e+06j, -11007985.-7.39117300e+06j],\n",
       "        [-23434190.+9.17077800e+06j, -68371948.+7.04234920e+07j,\n",
       "         -68312226.-1.16563832e+08j, ...,   5234503.-1.01368200e+07j,\n",
       "          -3762596.-9.95206800e+06j,   6642010.-8.85982200e+06j]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories = {}\n",
    "for job_id, logical in zip(md.job_id, md.logical):\n",
    "    mmr_name = f\"mmr_log_{logical}\"\n",
    "    memories[mmr_name] = provider.retrieve_job(job_id).result().get_memory()\n",
    "\n",
    "memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stim\n",
    "import pymatching\n",
    "\n",
    "from soft_info import get_repcode_layout, get_KDEs\n",
    "\n",
    "# Code parameters\n",
    "d=max_distance\n",
    "T=max_distance\n",
    "layout = get_repcode_layout(distance=max_distance, backend=provider.get_backend(\"ibm_sherbrooke\"), _is_hex=True)\n",
    "\n",
    "kde_dict, scaler_dict = get_KDEs(provider, 'ibm_sherbrooke', layout, bandwidths=0.2, plot=False)\n",
    "\n",
    "circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                 distance=d,\n",
    "                                 rounds=T,\n",
    "                                 after_clifford_depolarization=0.1)\n",
    "\n",
    "model = circuit.detector_error_model(decompose_errors=True)\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "memory = memories['mmr_log_0']\n",
    "#draw_matching_graph(matching, d, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1111/1111 [12:02<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from soft_info import get_counts\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "actual_observables = np.array([[False]]) # hardcoded, can be retrieved\n",
    "num_errors = 0\n",
    "\n",
    "i = 0\n",
    "w_idx_lst = []\n",
    "for shot in tqdm(range(len(memory))[:]):\n",
    "    i += 1\n",
    "    IQ_data = memory[shot]\n",
    "\n",
    "    counts = get_counts([IQ_data], kde_dict, scaler_dict, layout, T, verbose=False)\n",
    "    count_key = next(iter(counts.keys()))\n",
    "    \n",
    "    #soft_reweight_pymatching(matching, d, T, IQ_data, kde_dict, layout, scaler_dict, common_measure=0.01, verbose=False)  \n",
    "    reweight_edges_to_one(matching)\n",
    "\n",
    "    array_processed_string = process_string(count_key, verbose=False)\n",
    "\n",
    "    predicted_observables = matching.decode(array_processed_string)\n",
    "\n",
    "    if predicted_observables == [0]:\n",
    "        continue\n",
    "    \n",
    "    #print(f\"Wrong decoding at index {i}\")\n",
    "    w_idx_lst.append(i)\n",
    "\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Count key:\", count_key)\n",
    "        print(\"process_string:\", array_processed_string)\n",
    "\n",
    "    if VERBOSE:\n",
    "        draw_matching_graph(matching, d, T)\n",
    "\n",
    "    if VERBOSE:\n",
    "        matched_edges = matching.decode_to_edges_array(array_processed_string)\n",
    "        print(\"matched_edges: \", matched_edges)\n",
    "        print(\"Estimated flip:\", predicted_observables)\n",
    "\n",
    "    num_errors += not np.array_equal(actual_observables[0, :], predicted_observables) # 0 can be changed to i if multiple observables and multiple syndromes per ovbservable\n",
    "\n",
    "print(\"Num errors:\", num_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1111/1111 [11:39<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from soft_info import get_counts\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "actual_observables = np.array([[False]]) # hardcoded, can be retrieved\n",
    "num_errors = 0\n",
    "\n",
    "i = 0\n",
    "w_idx_lst = []\n",
    "for shot in tqdm(range(len(memory))[:]):\n",
    "    i += 1\n",
    "    IQ_data = memory[shot]\n",
    "\n",
    "    counts = get_counts([IQ_data], kde_dict, scaler_dict, layout, T, verbose=False)\n",
    "    count_key = next(iter(counts.keys()))\n",
    "    \n",
    "    #soft_reweight_pymatching(matching, d, T, IQ_data, kde_dict, layout, scaler_dict, common_measure=0.01, verbose=False)  \n",
    "    #reweight_edges_to_one(matching)\n",
    "\n",
    "    array_processed_string = process_string(count_key, verbose=False)\n",
    "\n",
    "    predicted_observables = matching.decode(array_processed_string)\n",
    "\n",
    "    if predicted_observables == [0]:\n",
    "        continue\n",
    "    \n",
    "    #print(f\"Wrong decoding at index {i}\")\n",
    "    w_idx_lst.append(i)\n",
    "\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Count key:\", count_key)\n",
    "        print(\"process_string:\", array_processed_string)\n",
    "\n",
    "    if VERBOSE:\n",
    "        draw_matching_graph(matching, d, T)\n",
    "\n",
    "    if VERBOSE:\n",
    "        matched_edges = matching.decode_to_edges_array(array_processed_string)\n",
    "        print(\"matched_edges: \", matched_edges)\n",
    "        print(\"Estimated flip:\", predicted_observables)\n",
    "\n",
    "    num_errors += not np.array_equal(actual_observables[0, :], predicted_observables) # 0 can be changed to i if multiple observables and multiple syndromes per ovbservable\n",
    "\n",
    "print(\"Num errors:\", num_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-Sk8aHGSa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
