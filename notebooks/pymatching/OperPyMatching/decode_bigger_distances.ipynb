{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatching\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from soft_info import get_repcode_IQ_map, llh_ratio\n",
    "\n",
    "def process_string(input_str, verbose=False):\n",
    "    # Step 1: Invert the order of the string\n",
    "    reversed_str = input_str[::-1]\n",
    "    if verbose:\n",
    "        print(\"Reversed str:\", reversed_str)\n",
    "\n",
    "    # Step 2: Separate the last part of the string\n",
    "    last_part = reversed_str.split(\" \")[-1]\n",
    "    if verbose:\n",
    "        print(\"Count str:\", last_part)\n",
    "    \n",
    "    # Step 3: Perform XOR operations on the last part\n",
    "    xor_result = ''.join([str((int(last_part[i]) + int(last_part[i + 1])) % 2) for i in range(len(last_part) - 1)])\n",
    "    if verbose:\n",
    "        print(\"XOR result:\", xor_result)\n",
    "    \n",
    "    # Step 4: Remove the remaining spaces in the first part of the string\n",
    "    first_part = ''.join(reversed_str.split(\" \")[:-1])\n",
    "    if verbose:\n",
    "        print(\"First part:\", first_part)\n",
    "    \n",
    "    # Step 5: Separate each bit of the string into a list of a NumPy array\n",
    "    numpy_list = np.array([int(bit) for bit in first_part]+ [int(bit) for bit in xor_result])\n",
    "    if verbose:\n",
    "        print(\"Numpy list:\", numpy_list)\n",
    "    \n",
    "    return numpy_list\n",
    "\n",
    "\n",
    "def reweight_edges_to_one(matching: pymatching.Matching):\n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        fault_ids = edge_data.get('fault_ids', set())\n",
    "        error_probability = edge_data.get('error_probability', -1.0)\n",
    "        \n",
    "        if tgt_node is None:\n",
    "            matching.add_boundary_edge(src_node, weight=1, fault_ids=fault_ids, \n",
    "                              error_probability=error_probability, merge_strategy=\"replace\")\n",
    "        else:\n",
    "            matching.add_edge(src_node, tgt_node, weight=1, fault_ids=fault_ids, \n",
    "                          error_probability=error_probability, merge_strategy=\"replace\")\n",
    "\n",
    "\n",
    "def soft_reweight_pymatching(matching : pymatching.Matching,  d : int, T : int, IQ_data, \n",
    "                             kde_dict: dict, layout : list, scaler_dict : dict,\n",
    "                             p_data : float = None, p_meas : float = None, common_measure = None,\n",
    "                             verbose : bool = False):\n",
    "\n",
    "    p_data = p_data if p_data is not None else 6.836e-3  # Sherbrooke median\n",
    "    p_meas = p_meas if p_meas is not None else 0\n",
    "\n",
    "    if layout is not None:\n",
    "        qubit_mapping = get_repcode_IQ_map(layout, T)\n",
    "\n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        if verbose:\n",
    "            print(\"\\nEdge:\", (src_node, tgt_node))\n",
    "        fault_ids = edge_data.get('fault_ids', set())\n",
    "        error_probability = edge_data.get('error_probability', -1.0)\n",
    "        \n",
    "        if tgt_node is None:  # always second pose None\n",
    "            # Boundary edge (logical on it)\n",
    "            new_weight = -np.log(p_data / (1 - p_data))\n",
    "\n",
    "            if common_measure is not None:\n",
    "                new_weight = round(new_weight / common_measure) * common_measure\n",
    "                \n",
    "            matching.add_boundary_edge(src_node, weight=new_weight, fault_ids=fault_ids, \n",
    "                              error_probability=error_probability, merge_strategy=\"replace\")\n",
    "            if verbose:\n",
    "                print(\"Boundary edge weight: \", new_weight)\n",
    "\n",
    "            _has_time_component = False\n",
    "            continue\n",
    "        elif tgt_node == src_node + 1:  # always first pos the smaller\n",
    "            # Data edge\n",
    "            new_weight = -np.log(p_data / (1 - p_data))\n",
    "            if common_measure is not None:\n",
    "                new_weight = round(new_weight / common_measure) * common_measure\n",
    "            if verbose:\n",
    "                print(\"Data edge weight: \", new_weight)\n",
    "        elif tgt_node == src_node + (d-1):\n",
    "            # Time edge\n",
    "            #TODO implement adding a new edge for hard meas flip\n",
    "            new_weight = 0 #-np.log(p_meas / (1 - p_meas))\n",
    "            _has_time_component = True\n",
    "            if verbose:\n",
    "                print(\"Time edge weight: \", new_weight)\n",
    "        elif tgt_node == src_node + (d-1) + 1:\n",
    "            # mixed edge\n",
    "            # TODO implement adding a new DIAG edge for hard meas flip\n",
    "            new_weight = -np.log(p_data / (1 - p_data))# - np.log(p_meas / (1 - p_meas))\n",
    "            _has_time_component = True\n",
    "            if verbose:\n",
    "                print(\"Mixed edge weight: \", new_weight)\n",
    "\n",
    "        if _has_time_component: \n",
    "            #Structure of IQ data = [link_0, link_1, link_3, link_0, link_1, .., code_qubit_1, ...]\n",
    "            # equivalent to       = [node_0, node_1, node_3, node_4, node_5, .. ]\n",
    "            # =>\n",
    "            IQ_point = IQ_data[src_node]\n",
    "            layout_qubit_idx = qubit_mapping[src_node]\n",
    "            kde_0, kde_1 = kde_dict.get(layout_qubit_idx, (None, None))\n",
    "            scaler = scaler_dict.get(layout_qubit_idx, None)\n",
    "            llh_weight = llh_ratio(IQ_point, kde_0, kde_1, scaler)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"LLH weight: \", llh_weight)\n",
    "        \n",
    "            new_weight += llh_weight\n",
    "\n",
    "            # Round the weights to common measure\n",
    "            if common_measure is not None:\n",
    "                new_weight = round(new_weight / common_measure) * common_measure\n",
    "\n",
    "        # Update the edge weight\n",
    "        matching.add_edge(src_node, tgt_node, weight=new_weight, fault_ids=fault_ids, \n",
    "                          error_probability=error_probability, merge_strategy=\"replace\")\n",
    "\n",
    "\n",
    "\n",
    "def draw_matching_graph(matching, d, T):\n",
    "    G = nx.Graph()\n",
    "    pos = {}\n",
    "    edge_colors = []\n",
    "    \n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        if tgt_node is not None:\n",
    "            G.add_edge(src_node, tgt_node, weight=edge_data['weight'])\n",
    "            if edge_data.get('fault_ids'):\n",
    "                edge_colors.append('r')\n",
    "            else:\n",
    "                edge_colors.append('k')\n",
    "        \n",
    "        x_src = src_node % (d-1)\n",
    "        y_src = src_node // (d-1)\n",
    "        pos[src_node] = (x_src, -y_src)\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=True, node_color='white', edge_color=edge_colors, font_weight='bold', node_size=700, font_size=18)\n",
    "    \n",
    "    edge_weights = nx.get_edge_attributes(G, 'weight')\n",
    "    labels = {k: f\"{v:.2f}\" for k, v in edge_weights.items()}\n",
    "    \n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "    for edge in matching.edges():\n",
    "        src_node, tgt_node, edge_data = edge\n",
    "        if tgt_node is None:\n",
    "            x_src = src_node % (d-1)\n",
    "            y_src = src_node // (d-1)\n",
    "            color = 'r' if edge_data.get('fault_ids') == set() else 'k'\n",
    "            weight_text = f\"{edge_data.get('weight'):.2f}\"\n",
    "            if x_src == 0:\n",
    "                plt.plot([x_src, x_src - 0.5], [-y_src, -y_src], color=color)\n",
    "                plt.text(x_src - 0.3, -y_src + 0.05, weight_text)\n",
    "            elif x_src == d - 2:\n",
    "                plt.plot([x_src, x_src + 0.5], [-y_src, -y_src], color=color)\n",
    "                plt.text(x_src + 0.2, -y_src + 0.05, weight_text)\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='skyblue', node_size=700)\n",
    "    \n",
    "    plt.show()      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>notebook_name</th>\n",
       "      <th>backend_name</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>shots</th>\n",
       "      <th>tags_xp</th>\n",
       "      <th>sampled_state</th>\n",
       "      <th>num_qubits</th>\n",
       "      <th>job_status</th>\n",
       "      <th>extra</th>\n",
       "      <th>optimization_level</th>\n",
       "      <th>code</th>\n",
       "      <th>distance</th>\n",
       "      <th>rounds</th>\n",
       "      <th>logical</th>\n",
       "      <th>layout</th>\n",
       "      <th>descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2023-10-29 14:43:41.752908+01:00</td>\n",
       "      <td>bigger_rep_codes</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cmz633cvayrg008sp2a0</td>\n",
       "      <td>[]</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>_is_hex=True</td>\n",
       "      <td>Run bigger Repetition codes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2023-10-29 14:43:49.136614+01:00</td>\n",
       "      <td>bigger_rep_codes</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cmz635cvayrg008sp2ag</td>\n",
       "      <td>[]</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>_is_hex=True</td>\n",
       "      <td>Run bigger Repetition codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       creation_date     notebook_name    backend_name  \\\n",
       "51  2023-10-29 14:43:41.752908+01:00  bigger_rep_codes  ibm_sherbrooke   \n",
       "52  2023-10-29 14:43:49.136614+01:00  bigger_rep_codes  ibm_sherbrooke   \n",
       "\n",
       "                  job_id tags    shots tags_xp sampled_state  num_qubits  \\\n",
       "51  cmz633cvayrg008sp2a0   []  10000.0     NaN           NaN         NaN   \n",
       "52  cmz635cvayrg008sp2ag   []  10000.0     NaN           NaN         NaN   \n",
       "\n",
       "        job_status extra  optimization_level                   code  distance  \\\n",
       "51  JobStatus.DONE   NaN                 NaN  RepetitionCodeCircuit      10.0   \n",
       "52  JobStatus.DONE   NaN                 NaN  RepetitionCodeCircuit      10.0   \n",
       "\n",
       "   rounds logical        layout                        descr  \n",
       "51     10       0  _is_hex=True  Run bigger Repetition codes  \n",
       "52     10       1  _is_hex=True  Run bigger Repetition codes  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Scratch import metadata_loader\n",
    "\n",
    "md = metadata_loader(_extract=True, _drop_inutile=True)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"notebook_name\"] == \"bigger_rep_codes\"]\n",
    "max_distance = int(max(md.distance))\n",
    "max_distance = 10\n",
    "md = md[md[\"distance\"] == max_distance]\n",
    "md = md.sort_values(by='backend_name', ascending=False)\n",
    "\n",
    "md = md[:2]\n",
    "\n",
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmr_log_0': array([[-1.07835540e+07+1.60007760e+07j, -4.34302570e+07+6.96242610e+07j,\n",
       "         -7.66192810e+07-1.01656696e+08j, ...,\n",
       "         -1.35120390e+08-9.77335290e+07j, -3.80560740e+07+6.36918740e+07j,\n",
       "         -4.85890250e+07-4.91702220e+07j],\n",
       "        [-1.74411220e+07+1.59327660e+07j, -2.78251510e+07+9.61105720e+07j,\n",
       "         -8.27942290e+07-6.93373260e+07j, ...,\n",
       "         -9.07659150e+07-8.55185450e+07j, -4.64208250e+07+6.32030470e+07j,\n",
       "         -4.33537600e+07-6.12943710e+07j],\n",
       "        [-1.54824580e+07+2.18220430e+07j, -6.89706470e+07+8.39149230e+07j,\n",
       "         -8.66970110e+07-1.03769749e+08j, ...,\n",
       "         -9.09095960e+07-1.00895483e+08j,  2.93957050e+07+5.42357540e+07j,\n",
       "         -4.63021990e+07-4.44538090e+07j],\n",
       "        ...,\n",
       "        [-1.39799180e+07+2.69024710e+07j, -6.32237650e+07+8.82667040e+07j,\n",
       "         -5.41600650e+07-7.07844530e+07j, ...,\n",
       "         -1.03823050e+08-6.60265260e+07j, -3.28060750e+07+5.71764790e+07j,\n",
       "         -4.21334650e+07-3.51620440e+07j],\n",
       "        [-2.26475890e+07+1.08688000e+07j, -7.83379020e+07+5.57964840e+07j,\n",
       "         -4.49446620e+07-8.25838230e+07j, ...,\n",
       "         -1.15430337e+08-1.29970139e+08j, -4.31034770e+07+7.30380210e+07j,\n",
       "          2.77266150e+07-5.34374360e+07j],\n",
       "        [-1.70805520e+07+2.07884260e+07j, -3.27609510e+07+4.82693720e+07j,\n",
       "         -6.04363530e+07-7.41615820e+07j, ...,\n",
       "         -1.15424203e+08-9.67325870e+07j, -4.03741830e+07+7.17580610e+07j,\n",
       "          3.34193000e+07-4.02555640e+07j]]),\n",
       " 'mmr_log_1': array([[-15692787.+1.88561960e+07j, -80711076.+8.91906020e+07j,\n",
       "         -87022795.-6.44187120e+07j, ...,  75725902.-1.21354580e+08j,\n",
       "         -28710712.+6.20943080e+07j,  44185553.-4.49834680e+07j],\n",
       "        [-17120213.+1.69376750e+07j,  23946988.+3.47431000e+07j,\n",
       "         -74781675.-9.12627200e+07j, ...,  72066487.-1.01721992e+08j,\n",
       "          19959988.+6.10444990e+07j,  26781351.-4.77705380e+07j],\n",
       "        [-19335587.+3.34220460e+07j, -46818366.+8.77273130e+07j,\n",
       "         -61405134.-7.04816920e+07j, ...,  80569010.-1.03369401e+08j,\n",
       "          16784749.+8.25859120e+07j,  17967845.-2.02450010e+07j],\n",
       "        ...,\n",
       "        [-16345637.+2.46346140e+07j, -54743861.+5.96369150e+07j,\n",
       "         -78909730.-7.98283930e+07j, ...,  80997282.-1.01116520e+08j,\n",
       "          23078698.+6.85586680e+07j,  34355029.-7.26538330e+07j],\n",
       "        [ -9473397.+1.67778250e+07j, -55211766.+5.55506080e+07j,\n",
       "         -62476911.-7.80322320e+07j, ...,  53501505.-1.02813635e+08j,\n",
       "          43115339.+6.01581220e+07j,  47870070.-4.31179720e+07j],\n",
       "        [-12487791.+2.30842620e+07j, -67437817.+7.46774740e+07j,\n",
       "         -72204421.-7.04013450e+07j, ...,  67383748.-1.01053483e+08j,\n",
       "          36118069.+7.42037660e+07j,  36013478.-4.25054610e+07j]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories = {}\n",
    "for job_id, logical in zip(md.job_id, md.logical):\n",
    "    mmr_name = f\"mmr_log_{logical}\"\n",
    "    memories[mmr_name] = provider.retrieve_job(job_id).result().get_memory()\n",
    "\n",
    "memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stim\n",
    "import pymatching\n",
    "\n",
    "from soft_info import get_repcode_layout, get_KDEs\n",
    "\n",
    "# Code parameters\n",
    "d=max_distance\n",
    "T=max_distance\n",
    "layout = get_repcode_layout(distance=max_distance, backend=provider.get_backend(\"ibm_sherbrooke\"), _is_hex=True)\n",
    "\n",
    "kde_dict, scaler_dict = get_KDEs(provider, 'ibm_sherbrooke', layout, bandwidths=0.2, plot=False)\n",
    "\n",
    "circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                 distance=d,\n",
    "                                 rounds=T,\n",
    "                                 after_clifford_depolarization=0.1)\n",
    "\n",
    "model = circuit.detector_error_model(decompose_errors=True)\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "memory = memories['mmr_log_0']\n",
    "#draw_matching_graph(matching, d, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [15:33<00:00,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from soft_info import get_counts\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "actual_observables = np.array([[False]]) # hardcoded, can be retrieved\n",
    "num_errors = 0\n",
    "\n",
    "i = 0\n",
    "w_idx_lst = []\n",
    "for shot in tqdm(range(len(memory))[:3333]):\n",
    "    i += 1\n",
    "    IQ_data = memory[shot]\n",
    "\n",
    "    counts = get_counts([IQ_data], kde_dict, scaler_dict, layout, T, verbose=False)\n",
    "    count_key = next(iter(counts.keys()))\n",
    "    \n",
    "    soft_reweight_pymatching(matching, d, T, IQ_data, kde_dict, layout, scaler_dict, common_measure=0.01, verbose=False)  \n",
    "\n",
    "    array_processed_string = process_string(count_key, verbose=False)\n",
    "\n",
    "    predicted_observables = matching.decode(array_processed_string)\n",
    "\n",
    "    if predicted_observables == [0]:\n",
    "        continue\n",
    "    \n",
    "    #print(f\"Wrong decoding at index {i}\")\n",
    "    w_idx_lst.append(i)\n",
    "\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Count key:\", count_key)\n",
    "        print(\"process_string:\", array_processed_string)\n",
    "\n",
    "    if VERBOSE:\n",
    "        draw_matching_graph(matching, d, T)\n",
    "\n",
    "    if VERBOSE:\n",
    "        matched_edges = matching.decode_to_edges_array(array_processed_string)\n",
    "        print(\"matched_edges: \", matched_edges)\n",
    "        print(\"Estimated flip:\", predicted_observables)\n",
    "\n",
    "    num_errors += not np.array_equal(actual_observables[0, :], predicted_observables) # 0 can be changed to i if multiple observables and multiple syndromes per ovbservable\n",
    "\n",
    "print(\"Num errors:\", num_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from soft_info import get_counts\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "actual_observables = np.array([[False]]) # hardcoded, can be retrieved\n",
    "num_errors = 0\n",
    "\n",
    "i = 0\n",
    "w_idx_lst = []\n",
    "for shot in tqdm(range(len(memory))[:]):\n",
    "    i += 1\n",
    "    IQ_data = memory[shot]\n",
    "\n",
    "    counts = get_counts([IQ_data], kde_dict, scaler_dict, layout, T, verbose=False)\n",
    "    count_key = next(iter(counts.keys()))\n",
    "    \n",
    "    #soft_reweight_pymatching(matching, d, T, IQ_data, kde_dict, layout, scaler_dict, common_measure=0.01, verbose=False)  \n",
    "    reweight_edges_to_one(matching)\n",
    "\n",
    "    array_processed_string = process_string(count_key, verbose=False)\n",
    "\n",
    "    predicted_observables = matching.decode(array_processed_string)\n",
    "\n",
    "    if predicted_observables == [0]:\n",
    "        continue\n",
    "    \n",
    "    #print(f\"Wrong decoding at index {i}\")\n",
    "    w_idx_lst.append(i)\n",
    "\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Count key:\", count_key)\n",
    "        print(\"process_string:\", array_processed_string)\n",
    "\n",
    "    if VERBOSE:\n",
    "        draw_matching_graph(matching, d, T)\n",
    "\n",
    "    if VERBOSE:\n",
    "        matched_edges = matching.decode_to_edges_array(array_processed_string)\n",
    "        print(\"matched_edges: \", matched_edges)\n",
    "        print(\"Estimated flip:\", predicted_observables)\n",
    "\n",
    "    num_errors += not np.array_equal(actual_observables[0, :], predicted_observables) # 0 can be changed to i if multiple observables and multiple syndromes per ovbservable\n",
    "\n",
    "print(\"Num errors:\", num_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-Sk8aHGSa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
