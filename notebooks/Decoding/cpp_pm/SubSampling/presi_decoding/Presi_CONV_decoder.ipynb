{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state = Z0\n",
      "shape: (40, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>notebook_name</th>\n",
       "      <th>backend_name</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>meas_level</th>\n",
       "      <th>shots</th>\n",
       "      <th>num_qubits</th>\n",
       "      <th>job_status</th>\n",
       "      <th>execution_date</th>\n",
       "      <th>code</th>\n",
       "      <th>distance</th>\n",
       "      <th>rounds</th>\n",
       "      <th>logical</th>\n",
       "      <th>descr</th>\n",
       "      <th>resets</th>\n",
       "      <th>xbasis</th>\n",
       "      <th>path_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>2024-03-24 15:59:50.864000+01:00</td>\n",
       "      <td>Torino_RepCodes_jobs</td>\n",
       "      <td>ibm_torino</td>\n",
       "      <td>cr03zsqdvs8g008j7ra0</td>\n",
       "      <td>[Subset 56, 50 rounds, 0 log, xbasis=False]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>2024-03-24 16:51:12.990431+01:00</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>subset RepCodes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'mean_gate_error': 0.006452510204489, 'min_ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>2024-03-24 15:59:44.592000+01:00</td>\n",
       "      <td>Torino_RepCodes_jobs</td>\n",
       "      <td>ibm_torino</td>\n",
       "      <td>cr03zr7k5z700081s2tg</td>\n",
       "      <td>[Subset 56, 50 rounds, 0 log, xbasis=False]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>2024-03-24 16:50:44.865382+01:00</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>subset RepCodes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'mean_gate_error': 0.006452510204489, 'min_ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         creation_date         notebook_name backend_name  \\\n",
       "5483  2024-03-24 15:59:50.864000+01:00  Torino_RepCodes_jobs   ibm_torino   \n",
       "5482  2024-03-24 15:59:44.592000+01:00  Torino_RepCodes_jobs   ibm_torino   \n",
       "\n",
       "                    job_id                                         tags  \\\n",
       "5483  cr03zsqdvs8g008j7ra0  [Subset 56, 50 rounds, 0 log, xbasis=False]   \n",
       "5482  cr03zr7k5z700081s2tg  [Subset 56, 50 rounds, 0 log, xbasis=False]   \n",
       "\n",
       "      meas_level   shots  num_qubits      job_status  \\\n",
       "5483         1.0  1398.0         NaN  JobStatus.DONE   \n",
       "5482         1.0  1398.0         NaN  JobStatus.DONE   \n",
       "\n",
       "                        execution_date                   code  distance  \\\n",
       "5483  2024-03-24 16:51:12.990431+01:00  RepetitionCodeCircuit        56   \n",
       "5482  2024-03-24 16:50:44.865382+01:00  RepetitionCodeCircuit        56   \n",
       "\n",
       "      rounds logical            descr resets xbasis  \\\n",
       "5483      50       0  subset RepCodes    NaN  False   \n",
       "5482      50       0  subset RepCodes    NaN  False   \n",
       "\n",
       "                                              path_info  \n",
       "5483  {'mean_gate_error': 0.006452510204489, 'min_ga...  \n",
       "5482  {'mean_gate_error': 0.006452510204489, 'min_ga...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Scratch import metadata_loader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"ibm_torino\"\n",
    "LOGICAL = str(0)\n",
    "XBASIS = False\n",
    "ROUNDS = 50\n",
    "\n",
    "state = \"X\" if XBASIS else \"Z\"\n",
    "state += LOGICAL\n",
    "print(f\"state = {state}\")\n",
    "\n",
    "\n",
    "# Load the metadata\n",
    "md = metadata_loader(True, True)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"code\"] == \"RepetitionCodeCircuit\"]\n",
    "md = md[md[\"descr\"] == 'subset RepCodes']\n",
    "md = md.dropna(subset=[\"rounds\"])\n",
    "md = md[md[\"meas_level\"] == 1]\n",
    "md['rounds'] = md['rounds'].astype(int)\n",
    "md['distance'] = md['distance'].astype(int)\n",
    "\n",
    "md = md[md[\"backend_name\"] == DEVICE]\n",
    "md = md[md[\"logical\"] == LOGICAL]\n",
    "md = md[md[\"xbasis\"] == XBASIS]\n",
    "md = md[md[\"rounds\"] == ROUNDS]\n",
    "\n",
    "# md = md[1:6]\n",
    "print(\"shape:\", md.shape)\n",
    "md[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group job ids by closest calibration date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from Scratch import find_closest_calib_jobs\n",
    "import pandas as pd\n",
    "\n",
    "jobs_by_calibration_date = {}\n",
    "for index, row in md.iterrows():\n",
    "    job_id = row['job_id']\n",
    "\n",
    "    _, _, calib_creation_date = find_closest_calib_jobs(tobecalib_job=job_id, verbose=False)\n",
    "\n",
    "    if calib_creation_date not in jobs_by_calibration_date.keys():\n",
    "        jobs_by_calibration_date[calib_creation_date] = [job_id]\n",
    "    else:\n",
    "        jobs_by_calibration_date[calib_creation_date].append(job_id)\n",
    "\n",
    "# Takes 15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{datetime.datetime(2024, 3, 23, 9, 58, 21, 614000, tzinfo=datetime.timezone.utc): ['cr03zsqdvs8g008j7ra0', 'cr03zr7k5z700081s2tg', 'cr03zppdvs8g008j7r90', 'cr03zn6dvs8g008j7r80', 'cr03zkp8gdp0008fxbtg', 'cr03zj6czq6g0081jwe0', 'cr03zgek5z700081s2r0', 'cr03zexdvs8g008j7r70', 'cr03zdds9z7g008dqshg', 'cr03zbxs9z7g008dqsh0', 'cr03zandvs8g008j7r6g', 'cr03z8xdvs8g008j7r60', 'cr03z7cdvs8g008j7r5g', 'cr03z5wdvs8g008j7r50', 'cr03z4ck5z700081s2pg', 'cr03z2wczq6g0081jwbg', 'cr03z1cdvs8g008j7r4g', 'cr03yzk8gdp0008fxbr0', 'cr03yybk5z700081s2ng', 'cr03ywk8gdp0008fxbqg'], datetime.datetime(2024, 3, 16, 15, 5, 33, 808000, tzinfo=datetime.timezone.utc): ['cqtvae1pkcdg008e3py0', 'cqtvachpkcdg008e3pxg', 'cqtvab988ev000813aeg', 'cqtva9s4x0mg008acne0', 'cqtva8988ev000813ae0', 'cqtva6r88ev000813ad0', 'cqtva10txzj0008y0a30', 'cqtv9zz9nfw0008ht1y0', 'cqtv9yq88ev000813ac0', 'cqtv9wq4x0mg008acncg', 'cqtv9vf9nfw0008ht1xg'], datetime.datetime(2024, 3, 16, 15, 3, 15, 271000, tzinfo=datetime.timezone.utc): ['cqtv9sz4x0mg008acnc0', 'cqtv9rf88ev000813abg', 'cqtv9py4x0mg008acnb0', 'cqtv9nptxzj0008y0a2g', 'cqtv9metxzj0008y0a20', 'cqtv9jy88ev000813aag', 'cqtv9he4x0mg008acnag', 'cqtv9g636d60008j01ag', 'cqtv9entxzj0008y0a1g']}\n",
      "\n",
      "num of calibrations: 3\n",
      "num of jobs per calibration: [20, 11, 9]\n"
     ]
    }
   ],
   "source": [
    "print(jobs_by_calibration_date)\n",
    "print()\n",
    "print(f\"num of calibrations: {len(jobs_by_calibration_date)}\")\n",
    "print(f\"num of jobs per calibration: {([len(jobs) for jobs in jobs_by_calibration_date.values()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = md[\"distance\"].values[0]\n",
    "\n",
    "distances = np.arange(7, d+1, 4)\n",
    "distances = distances[::-1]\n",
    "distances = [3]\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:51:18 Warning: Z0 decoding. Negative T2 error -0.06 % for qubit 90, setting to 0.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 52\n",
      "21:51:21 Warning: Could not get two gate error of ECR due to 'Could not find the desired property for ecr', taking CX instead.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 67\n",
      "21:51:21 Warning: Could not get two gate error of CX due to 'Could not find the desired property for cx', taking 0.5 instead.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 71\n",
      "Found jobs for backend ibm_torino with closest execution date 2024-03-23 09:55:40.182587+00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving jobs of 2024-03-23 09:58:21.614000+00:00 calibration: 100%|██████████| 20/20 [00:49<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to get pSoft and countMat at 2024-03-25 21:52:21.347758\n",
      "Finished getting pSoft and countMat at 2024-03-25 21:58:59.158307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:48<00:00, 108.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:00:50 Warning: Z0 decoding. Negative T2 error -0.00 % for qubit 12, setting to 0.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 52\n",
      "22:00:53 Warning: Could not get two gate error of ECR due to 'Could not find the desired property for ecr', taking CX instead.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 67\n",
      "22:00:53 Warning: Could not get two gate error of CX due to 'Could not find the desired property for cx', taking 0.5 instead.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 71\n",
      "Found jobs for backend ibm_torino with closest execution date 2024-03-16 14:56:22.522112+00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving jobs of 2024-03-16 15:05:33.808000+00:00 calibration: 100%|██████████| 11/11 [00:27<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to get pSoft and countMat at 2024-03-25 22:01:31.241900\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pymatching\n",
    "import stim\n",
    "\n",
    "from soft_info import get_noise_dict_from_backend, get_avgs_from_dict, get_repcode_IQ_map\n",
    "from soft_info import RepetitionCodeStimCircuit, inv_qubit_mapping\n",
    "from soft_info import get_cols_to_keep, generate_subsets_with_center, get_subsample_layout\n",
    "from Scratch import load_calibration_memory\n",
    "import cpp_soft_info\n",
    "\n",
    "SOFT_MUL = 0.5\n",
    "file_name  = f'./results/CONV_{DEVICE}_{state}_{ROUNDS}_soft_{SOFT_MUL}.json'\n",
    "\n",
    "rel_error = 1\n",
    "_RESETS = False\n",
    "nb_intervals = -1\n",
    "\n",
    "# KDE BANDWIDTHS\n",
    "lin = [0.4, 0.7, 20]\n",
    "lin = [0.4, 0.7, 1]\n",
    "num_points = 51\n",
    "bandwidths = np.linspace(lin[0], lin[1], lin[2])\n",
    "\n",
    "\n",
    "for calib_date in jobs_by_calibration_date.keys():\n",
    "    # get the noise dict of that date\n",
    "    noise_dict = get_noise_dict_from_backend(provider, DEVICE, date = calib_date)\n",
    "\n",
    "    # get the KDE of that date\n",
    "    nb_shots_calib = None\n",
    "    all_memories = load_calibration_memory(provider, tobecalib_backend=DEVICE, other_date=calib_date, nb_shots=nb_shots_calib)\n",
    "    kde_dict = cpp_soft_info.get_KDEs(all_memories, bandwidths, relError=rel_error, absError=-1, num_points=51) # Less num_points bcs just 1 bandwidth\n",
    "\n",
    "    # Retrieve the memories\n",
    "    memories = []\n",
    "    for job_id in tqdm(jobs_by_calibration_date[calib_date], desc=f\"Retrieving jobs of {calib_date} calibration\"):\n",
    "        d = md[md[\"job_id\"] == job_id][\"distance\"].values[0] \n",
    "        T = md[md[\"job_id\"] == job_id][\"rounds\"].values[0] # Should be 10\n",
    "\n",
    "        # Get the job\n",
    "        job = provider.retrieve_job(job_id)\n",
    "        memory = job.result().get_memory()\n",
    "        memories.append(memory)\n",
    "\n",
    "    # Stack the memories vertically\n",
    "    big_memory = np.vstack(memories)\n",
    "\n",
    "    # Get the layout of the last job (same as previous)\n",
    "    layout_des = job.deserialize_layout(job.initial_layouts()[0]) # only 1 layout\n",
    "    link_qubits = list(layout_des['link_qubit'].values())\n",
    "    code_qubits = list(layout_des['code_qubit'].values())\n",
    "\n",
    "    # Get the pSoft and countMat matrices\n",
    "    big_layout = link_qubits + code_qubits\n",
    "    inverted_q_map = inv_qubit_mapping(get_repcode_IQ_map(big_layout, synd_rounds=T))\n",
    "    print(f\"Starting to get pSoft and countMat at {datetime.now()}\")\n",
    "    pSoft, countMat = cpp_soft_info.iqConvertor(big_memory, inverted_q_map, kde_dict, rel_error, -1)\n",
    "    print(f\"Finished getting pSoft and countMat at {datetime.now()}\")\n",
    "\n",
    "    # Subsample decoding\n",
    "    for D_NEW in tqdm(distances):\n",
    "        subsets = generate_subsets_with_center(d, D_NEW)\n",
    "\n",
    "        num_errors_kde = []\n",
    "        num_errors_hard = []\n",
    "        for subset in (subsets):             \n",
    "            cols_to_keep = get_cols_to_keep(subset, T, d)\n",
    "            pSoft_sub = pSoft[:, cols_to_keep]\n",
    "            countMat_sub = countMat[:, cols_to_keep]\n",
    "\n",
    "            # Get the layout\n",
    "            layout = get_subsample_layout(subset, link_qubits, code_qubits)\n",
    "            qubit_mapping = get_repcode_IQ_map(layout, synd_rounds=T)\n",
    "\n",
    "            # Get the noise avgs\n",
    "            avgs = get_avgs_from_dict(noise_dict, layout)\n",
    "            noise_list = [avgs[\"two_gate\"], avgs[\"single_gate\"], avgs[\"t1_err\"], avgs[\"t2_err\"]]\n",
    "            readout = avgs[\"readout\"]\n",
    "            noise_list += [readout, readout*(1-SOFT_MUL), readout*SOFT_MUL]    \n",
    "            #[twog_err, sglg_err, t1_err, t2_err, readout_err, hard_err, soft_err]\n",
    "\n",
    "            # Stim model\n",
    "            subsampling = (D_NEW != d)\n",
    "            code = RepetitionCodeStimCircuit(D_NEW, T, xbasis=XBASIS, resets=_RESETS, \n",
    "                                            noise_list=noise_list, subsampling=subsampling)\n",
    "            model = code.circuits[LOGICAL].detector_error_model(decompose_errors=False)\n",
    "\n",
    "            result_soft, result_hard = cpp_soft_info.decodeConvertorAll(model, countMat_sub, pSoft_sub, \n",
    "                                                                        T, int(LOGICAL), _RESETS)\n",
    "            \n",
    "            num_errors_kde.append(result_soft.num_errors)\n",
    "            num_errors_hard.append(result_hard.num_errors)\n",
    "    \n",
    "        result_kde_json = {\n",
    "            \"decoding\": \"kde\",\n",
    "            \"d_new\": str(D_NEW),\n",
    "            \"num_errors\": np.mean(num_errors_kde),\n",
    "            \"error_list\": num_errors_kde,\n",
    "            \"additional_info\": {\n",
    "                \"rel_error\": rel_error,\n",
    "                \"bandwidth_linspace\": lin,\n",
    "                \"num_points_bandwidths\": num_points,\n",
    "                \"soft_multiplicator\": SOFT_MUL,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        result_hard_json = {\n",
    "            \"decoding\": \"hard\",\n",
    "            \"d_new\": str(D_NEW),\n",
    "            \"num_errors\": np.mean(num_errors_hard),\n",
    "            \"error_list\": num_errors_hard,\n",
    "            \"noise_list\": noise_list,\n",
    "        }\n",
    "\n",
    "        if not os.path.exists(file_name):\n",
    "            data = {}\n",
    "        else:\n",
    "            with open(file_name, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "        if job_id not in data.keys():\n",
    "            data[job_id] = [result_kde_json, result_hard_json]\n",
    "        else:\n",
    "            data[job_id].append(result_kde_json)\n",
    "            data[job_id].append(result_hard_json)\n",
    "        \n",
    "        with open(file_name, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
