{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scratch import metadata_loader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"ibm_sherbrooke\"\n",
    "LOGICAL = str(0)\n",
    "pairs_to_process = [(10, 10), (20, 20), (30, 35), (40, 35), (55, 35)]\n",
    "\n",
    "# Load the metadata\n",
    "md = metadata_loader(True, True)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"code\"] == \"RepetitionCodeCircuit\"]\n",
    "md = md.dropna(subset=[\"rounds\"])\n",
    "md = md[md[\"meas_level\"] == 1]\n",
    "md['rounds'] = md['rounds'].astype(int)\n",
    "md['distance'] = md['distance'].astype(int)\n",
    "\n",
    "md = md[md[\"backend_name\"] == DEVICE]\n",
    "md = md[md[\"logical\"] == LOGICAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group job ids by closest calibration date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from Scratch import find_closest_calib_jobs\n",
    "import pandas as pd\n",
    "\n",
    "jobs_by_calibration_date = {}\n",
    "for index, row in md.iterrows():\n",
    "    if (row['distance'], row['rounds']) not in pairs_to_process:\n",
    "        continue\n",
    "    job_id = row['job_id']\n",
    "\n",
    "    _, _, calib_creation_date = find_closest_calib_jobs(tobecalib_job=job_id, verbose=False)\n",
    "\n",
    "    if calib_creation_date not in jobs_by_calibration_date.keys():\n",
    "        jobs_by_calibration_date[calib_creation_date] = [job_id]\n",
    "    else:\n",
    "        jobs_by_calibration_date[calib_creation_date].append(job_id)\n",
    "\n",
    "# Takes 21s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2023, 11, 9, 16, 47, 14, 556645, tzinfo=datetime.timezone.utc): ['cnn25s724wx0008f9kz0',\n",
       "  'cn6hm589recg008x0jvg',\n",
       "  'cn6hk3mxhnxg008djq30',\n",
       "  'cn6h9gpss5h00087k140',\n",
       "  'cn6h85r62r90008814pg',\n",
       "  'cn6h75464yf0008g84h0',\n",
       "  'cn6h5tfss5h00087k0w0',\n",
       "  'cn6h4f164yf0008g84ag',\n",
       "  'cn6h3dnxhnxg008djny0',\n",
       "  'cn6h20ranbvg008dab10',\n",
       "  'cn6h0mjss5h00087k0a0',\n",
       "  'cn6gzk664yf0008g83f0',\n",
       "  'cn6gy68ss5h00087jzsg',\n",
       "  'cn6gwrkss5h00087jzpg',\n",
       "  'cn6gvnyxhnxg008djn4g',\n",
       "  'cn6grptss5h00087jz80',\n",
       "  'cn6gqa59recg008x0ghg',\n",
       "  'cn6gnxzss5h00087jyz0',\n",
       "  'cn6gmvb62r90008812sg',\n",
       "  'cn6gee1anbvg008da9k0',\n",
       "  'cn6gczv9recg008x0fng',\n",
       "  'cn6gbx79recg008x0ff0',\n",
       "  'cn6gaga62r90008811tg',\n",
       "  'cn6g93cxhnxg008djkwg',\n",
       "  'cn6g81rss5h00087jxeg',\n",
       "  'cn6g6mtxhnxg008djkkg',\n",
       "  'cn6g57c62r900088110g',\n",
       "  'cn6g44862r90008810ng',\n",
       "  'cn6bdpevayrg008ermxg',\n",
       "  'cn6bca1rmwhg008k4xx0',\n",
       "  'cn6bb7wrmwhg008k4xa0',\n",
       "  'cn6b9pprmwhg008k4x60',\n",
       "  'cn6b89s3r3vg008fcvzg',\n",
       "  'cn6b76wrmwhg008k4x20',\n",
       "  'cn6b5v7p1am0008qeza0',\n",
       "  'cn6b4fhvcq70008qvs30',\n",
       "  'cn6b3ed3r3vg008fcvng',\n",
       "  'cn6b228vayrg008erk30',\n",
       "  'cn6b0p2rmwhg008k4wag',\n",
       "  'cn6azkedaqbg008szfq0',\n",
       "  'cn5wnxzvayrg008eqx80',\n",
       "  'cn5wmj2rmwhg008k46ag',\n",
       "  'cn5wkgpvcq70008qv4p0',\n",
       "  'cn2ae91p1am0008q77k0',\n",
       "  'cn2acwbvayrg008egnkg',\n",
       "  'cn2abv7rmwhg008jxgk0'],\n",
       " datetime.datetime(2023, 10, 27, 7, 46, 44, 189709, tzinfo=datetime.timezone.utc): ['cmzpsmyrmwhg008btx3g',\n",
       "  'cmzpsa5vayrg008cpk30',\n",
       "  'cmzprwvvcq70008qf12g',\n",
       "  'cmzppjavayrg008cpk0g',\n",
       "  'cmz649hp1am0008q1f7g',\n",
       "  'cmz63rfdaqbg008shr20',\n",
       "  'cmz633cvayrg008sp2a0']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_by_calibration_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-11-09 20:02:27+00:00.\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-11-09 20:02:27+00:00.\n",
      "Searching for ibm_sherbrooke and 23.11.09_16h47_300pts_2std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding jobs of 2023-11-09 16:47:14.556645+00:00 calibration:   0%|          | 0/46 [09:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 80\u001b[0m\n\u001b[1;32m     69\u001b[0m nb_intervals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(nb_intervals)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# result_grid = cpp_soft_info.decode_IQ_fast(model, IQ_data,\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#                                 rounds, int(LOGICAL), _RESETS, qubit_mapping, grid_dict,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#                                 processed_scaler_dict, _detailed=_DETAILED, nb_intervals=nb_intervals)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#     \"nb_intervals\": nb_intervals,\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m result_kde \u001b[38;5;241m=\u001b[39m \u001b[43mcpp_soft_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_IQ_kde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIQ_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLOGICAL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_RESETS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mqubit_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkde_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_DETAILED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelError\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabsError\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnb_intervals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_intervals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m result_kde_json \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoding\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkde_interval_offset_0.5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m: result_kde\u001b[38;5;241m.\u001b[39mnum_errors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     },\n\u001b[1;32m     93\u001b[0m }\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m############# SAVING THE RESULT ##############\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pymatching\n",
    "import stim \n",
    "from soft_info import get_noise_dict_from_backend, get_avgs_from_dict, find_longest_path_in_hex, get_repcode_IQ_map\n",
    "from src import cpp_soft_info\n",
    "from Scratch import load_calibration_memory, create_or_load_kde_grid\n",
    "\n",
    "_DETAILED = False\n",
    "\n",
    "rel_error = 1\n",
    "_RESETS = False\n",
    "\n",
    "# KDE BANDWIDTHS\n",
    "lin = [0.4, 0.7, 20]\n",
    "num_points = 51\n",
    "\n",
    "# lin = [0.6, 0.7, 1]\n",
    "# num_points = 2\n",
    "\n",
    "bandwidths = np.linspace(lin[0], lin[1], lin[2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for calib_date in jobs_by_calibration_date.keys():\n",
    "\n",
    "    # get the noise dict of that date\n",
    "    noise_dict = get_noise_dict_from_backend(provider, DEVICE, date = calib_date)\n",
    "\n",
    "    # get the KDE of that date\n",
    "    all_memories = load_calibration_memory(provider, tobecalib_backend=DEVICE, other_date=calib_date)\n",
    "    kde_dict = cpp_soft_info.get_KDEs(all_memories, bandwidths, relError=rel_error, absError=-1, num_points=num_points) # Less num_points bcs just 1 bandwidth\n",
    "\n",
    "    # get the kde_grid of that date\n",
    "    grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, tobecalib_backend=DEVICE, other_date=calib_date, num_grid_points=300, num_std_dev=2)\n",
    "\n",
    "    # get the longest path of that device\n",
    "    longest_path, _, _ = find_longest_path_in_hex(provider.get_backend(DEVICE))\n",
    "\n",
    "    # decode each job of that date\n",
    "    for job_id in tqdm(jobs_by_calibration_date[calib_date], desc=f\"Decoding jobs of {calib_date} calibration\"):\n",
    "        distance = md[md[\"job_id\"] == job_id][\"distance\"].values[0]\n",
    "        rounds = md[md[\"job_id\"] == job_id][\"rounds\"].values[0]\n",
    "        IQ_data = provider.retrieve_job(job_id).result().get_memory()\n",
    "\n",
    "        # Get the layout for the avgs\n",
    "        bounded_path = longest_path[:2 * distance - 1]\n",
    "        layout = bounded_path[1::2] + bounded_path[::2]\n",
    "        qubit_mapping = get_repcode_IQ_map(layout, rounds)\n",
    "\n",
    "        # Get the avgs\n",
    "        avgs = get_avgs_from_dict(noise_dict, layout)\n",
    "\n",
    "        # Initialize the stim model\n",
    "        circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                distance=distance,\n",
    "                                rounds=rounds,\n",
    "                                after_clifford_depolarization=avgs[\"two_gate\"], #two-qubit-fidelity,\n",
    "                                after_reset_flip_probability=0 if not _RESETS else avgs[\"readout\"], #reset error\n",
    "                                before_measure_flip_probability=avgs[\"readout\"], #measurement error,\n",
    "                                before_round_data_depolarization=avgs[\"idle\"]) #idle error)\n",
    "        model = circuit.detector_error_model(decompose_errors=False)\n",
    "        matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "        ############# DECODING ##############\n",
    "\n",
    "        for nb_intervals in np.linspace(1, 2**10, 75):\n",
    "            nb_intervals = int(nb_intervals)\n",
    "            result_grid = cpp_soft_info.decode_IQ_fast(model, IQ_data,\n",
    "                                            rounds, int(LOGICAL), _RESETS, qubit_mapping, grid_dict,\n",
    "                                            processed_scaler_dict, _detailed=_DETAILED, nb_intervals=nb_intervals)\n",
    "\n",
    "            result_grid_json  = {\n",
    "                \"decoding\": \"grid\",\n",
    "                \"num_errors\": result_grid.num_errors,\n",
    "                \"nb_intervals\": nb_intervals,\n",
    "            }\n",
    "\n",
    "            result_kde = cpp_soft_info.decode_IQ_kde(model, IQ_data, rounds, int(LOGICAL), _RESETS, \n",
    "                                            qubit_mapping, kde_dict, _DETAILED, relError=rel_error, absError=-1,\n",
    "                                            nb_intervals=nb_intervals)\n",
    "            \n",
    "            result_kde_json = {\n",
    "                \"decoding\": \"kde\",\n",
    "                \"num_errors\": result_kde.num_errors,\n",
    "                \"nb_intervals\": nb_intervals,\n",
    "                \"additional_info\": {            \n",
    "                    \"rel_error\": rel_error,\n",
    "                    \"bandwidth_linspace\": lin,\n",
    "                    \"num_points_bandwidths\": num_points\n",
    "                },\n",
    "            }\n",
    "\n",
    "\n",
    "            ############# SAVING THE RESULT ##############\n",
    "\n",
    "            with open(f\"../results/infoPerfo_v1.json\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                if job_id not in data.keys():\n",
    "                    data[job_id] = [result_grid_json, result_kde_json]\n",
    "                else:\n",
    "                    data[job_id].append(result_grid_json)\n",
    "                    data[job_id].append(result_kde_json)\n",
    "            \n",
    "            with open(f\"../results/infoPerfo_v1.json\", \"w\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
