{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scratch import metadata_loader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"ibm_sherbrooke\"\n",
    "LOGICAL = str(0)\n",
    "pairs_to_process = [(10, 10), (20, 20), (30, 35), (40, 35), (55, 35)]\n",
    "\n",
    "# Load the metadata\n",
    "md = metadata_loader(True, True)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"code\"] == \"RepetitionCodeCircuit\"]\n",
    "md = md.dropna(subset=[\"rounds\"])\n",
    "md = md[md[\"meas_level\"] == 1]\n",
    "md['rounds'] = md['rounds'].astype(int)\n",
    "md['distance'] = md['distance'].astype(int)\n",
    "\n",
    "md = md[md[\"backend_name\"] == DEVICE]\n",
    "md = md[md[\"logical\"] == LOGICAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group job ids by closest calibration date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from Scratch import find_closest_calib_jobs\n",
    "import pandas as pd\n",
    "\n",
    "jobs_by_calibration_date = {}\n",
    "for index, row in md.iterrows():\n",
    "    if (row['distance'], row['rounds']) not in pairs_to_process:\n",
    "        continue\n",
    "    job_id = row['job_id']\n",
    "\n",
    "    _, _, calib_creation_date = find_closest_calib_jobs(tobecalib_job=job_id, verbose=False)\n",
    "\n",
    "    if calib_creation_date not in jobs_by_calibration_date.keys():\n",
    "        jobs_by_calibration_date[calib_creation_date] = [job_id]\n",
    "    else:\n",
    "        jobs_by_calibration_date[calib_creation_date].append(job_id)\n",
    "\n",
    "# Takes 21s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2023, 11, 9, 16, 47, 14, 556645, tzinfo=datetime.timezone.utc): ['cnn25s724wx0008f9kz0',\n",
       "  'cn6hm589recg008x0jvg',\n",
       "  'cn6hk3mxhnxg008djq30',\n",
       "  'cn6h9gpss5h00087k140',\n",
       "  'cn6h85r62r90008814pg',\n",
       "  'cn6h75464yf0008g84h0',\n",
       "  'cn6h5tfss5h00087k0w0',\n",
       "  'cn6h4f164yf0008g84ag',\n",
       "  'cn6h3dnxhnxg008djny0',\n",
       "  'cn6h20ranbvg008dab10',\n",
       "  'cn6h0mjss5h00087k0a0',\n",
       "  'cn6gzk664yf0008g83f0',\n",
       "  'cn6gy68ss5h00087jzsg',\n",
       "  'cn6gwrkss5h00087jzpg',\n",
       "  'cn6gvnyxhnxg008djn4g',\n",
       "  'cn6grptss5h00087jz80',\n",
       "  'cn6gqa59recg008x0ghg',\n",
       "  'cn6gnxzss5h00087jyz0',\n",
       "  'cn6gmvb62r90008812sg',\n",
       "  'cn6gee1anbvg008da9k0',\n",
       "  'cn6gczv9recg008x0fng',\n",
       "  'cn6gbx79recg008x0ff0',\n",
       "  'cn6gaga62r90008811tg',\n",
       "  'cn6g93cxhnxg008djkwg',\n",
       "  'cn6g81rss5h00087jxeg',\n",
       "  'cn6g6mtxhnxg008djkkg',\n",
       "  'cn6g57c62r900088110g',\n",
       "  'cn6g44862r90008810ng',\n",
       "  'cn6bdpevayrg008ermxg',\n",
       "  'cn6bca1rmwhg008k4xx0',\n",
       "  'cn6bb7wrmwhg008k4xa0',\n",
       "  'cn6b9pprmwhg008k4x60',\n",
       "  'cn6b89s3r3vg008fcvzg',\n",
       "  'cn6b76wrmwhg008k4x20',\n",
       "  'cn6b5v7p1am0008qeza0',\n",
       "  'cn6b4fhvcq70008qvs30',\n",
       "  'cn6b3ed3r3vg008fcvng',\n",
       "  'cn6b228vayrg008erk30',\n",
       "  'cn6b0p2rmwhg008k4wag',\n",
       "  'cn6azkedaqbg008szfq0',\n",
       "  'cn5wnxzvayrg008eqx80',\n",
       "  'cn5wmj2rmwhg008k46ag',\n",
       "  'cn5wkgpvcq70008qv4p0',\n",
       "  'cn2ae91p1am0008q77k0',\n",
       "  'cn2acwbvayrg008egnkg',\n",
       "  'cn2abv7rmwhg008jxgk0'],\n",
       " datetime.datetime(2023, 10, 27, 7, 46, 44, 189709, tzinfo=datetime.timezone.utc): ['cmzpsmyrmwhg008btx3g',\n",
       "  'cmzpsa5vayrg008cpk30',\n",
       "  'cmzprwvvcq70008qf12g',\n",
       "  'cmzppjavayrg008cpk0g',\n",
       "  'cmz649hp1am0008q1f7g',\n",
       "  'cmz63rfdaqbg008shr20',\n",
       "  'cmz633cvayrg008sp2a0']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_by_calibration_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-11-09 20:02:27+00:00.\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-11-09 20:02:27+00:00.\n",
      "Searching for ibm_sherbrooke and 23.11.09_16h47_300pts_2std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding jobs of 2023-11-09 16:47:14.556645+00:00 calibration: 100%|██████████| 46/46 [08:25<00:00, 10.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-10-27 08:32:22.841567+00:00.\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-10-27 08:32:22.841567+00:00.\n",
      "Searching for ibm_sherbrooke and 23.10.27_07h46_300pts_2std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding jobs of 2023-10-27 07:46:44.189709+00:00 calibration: 100%|██████████| 7/7 [01:16<00:00, 10.94s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pymatching\n",
    "import stim \n",
    "from soft_info import get_noise_dict_from_backend, get_avgs_from_dict, find_longest_path_in_hex, get_repcode_IQ_map\n",
    "import cpp_soft_info\n",
    "from Scratch import load_calibration_memory, create_or_load_kde_grid\n",
    "\n",
    "_DETAILED = False\n",
    "\n",
    "rel_error = 1\n",
    "_RESETS = False\n",
    "nb_intervals = -1\n",
    "\n",
    "# KDE BANDWIDTHS\n",
    "lin = [0.4, 0.7, 20]\n",
    "num_points = 51\n",
    "\n",
    "# lin = [0.6, 0.7, 1]\n",
    "# num_points = 2\n",
    "\n",
    "bandwidths = np.linspace(lin[0], lin[1], lin[2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for calib_date in jobs_by_calibration_date.keys():\n",
    "\n",
    "    # get the noise dict of that date\n",
    "    noise_dict = get_noise_dict_from_backend(provider, DEVICE, date = calib_date)\n",
    "\n",
    "    # get the KDE of that date\n",
    "    all_memories = load_calibration_memory(provider, tobecalib_backend=DEVICE, other_date=calib_date)\n",
    "    kde_dict = cpp_soft_info.get_KDEs(all_memories, bandwidths, relError=rel_error, absError=-1, num_points=51) # Less num_points bcs just 1 bandwidth\n",
    "\n",
    "    # get the kde_grid of that date\n",
    "    grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, tobecalib_backend=DEVICE, other_date=calib_date, num_grid_points=300, num_std_dev=2)\n",
    "\n",
    "    # get the longest path of that device\n",
    "    longest_path, _, _ = find_longest_path_in_hex(provider.get_backend(DEVICE))\n",
    "\n",
    "    # decode each job of that date\n",
    "    for job_id in tqdm(jobs_by_calibration_date[calib_date], desc=f\"Decoding jobs of {calib_date} calibration\"):\n",
    "        distance = md[md[\"job_id\"] == job_id][\"distance\"].values[0]\n",
    "        rounds = md[md[\"job_id\"] == job_id][\"rounds\"].values[0]\n",
    "        IQ_data = provider.retrieve_job(job_id).result().get_memory()\n",
    "\n",
    "        # Get the layout for the avgs\n",
    "        bounded_path = longest_path[:2 * distance - 1]\n",
    "        layout = bounded_path[1::2] + bounded_path[::2]\n",
    "        qubit_mapping = get_repcode_IQ_map(layout, rounds)\n",
    "\n",
    "        # Get the avgs\n",
    "        avgs = get_avgs_from_dict(noise_dict, layout)\n",
    "\n",
    "        # Initialize the stim model\n",
    "        circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                distance=distance,\n",
    "                                rounds=rounds,\n",
    "                                after_clifford_depolarization=avgs[\"two_gate\"], #two-qubit-fidelity,\n",
    "                                after_reset_flip_probability=0 if not _RESETS else avgs[\"readout\"], #reset error\n",
    "                                before_measure_flip_probability=avgs[\"readout\"], #measurement error,\n",
    "                                before_round_data_depolarization=avgs[\"idle\"]) #idle error)\n",
    "        model = circuit.detector_error_model(decompose_errors=False)\n",
    "        matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "        ############# DECODING ##############\n",
    "\n",
    "        result_grid = cpp_soft_info.decode_IQ_fast(model, IQ_data,\n",
    "                                           rounds, int(LOGICAL), _RESETS, qubit_mapping, grid_dict,\n",
    "                                           processed_scaler_dict, _detailed=_DETAILED, nb_intervals=nb_intervals)\n",
    "\n",
    "        result_grid_json  = {\n",
    "            \"decoding\": \"grid\",\n",
    "            \"num_errors\": result_grid.num_errors,\n",
    "        }\n",
    "\n",
    "        result_kde = cpp_soft_info.decode_IQ_kde(model, IQ_data, rounds, int(LOGICAL), _RESETS, \n",
    "                                         qubit_mapping, kde_dict, _DETAILED, relError=rel_error, absError=-1,\n",
    "                                         nb_intervals=nb_intervals)\n",
    "        \n",
    "        result_kde_json = {\n",
    "            \"decoding\": \"kde\",\n",
    "            \"num_errors\": result_kde.num_errors,\n",
    "            \"additional_info\": {            \n",
    "                \"rel_error\": rel_error,\n",
    "                \"bandwidth_linspace\": lin,\n",
    "                \"num_points_bandwidths\": num_points\n",
    "            },\n",
    "        }\n",
    "\n",
    "        matching = pymatching.Matching.from_detector_error_model(model)\n",
    "        result_informed = cpp_soft_info.decode_IQ_shots_flat_informed(matching._matching_graph, IQ_data,\n",
    "                                                rounds, int(LOGICAL), _RESETS, qubit_mapping, grid_dict, processed_scaler_dict,\n",
    "                                                p_data = -1, p_mixed = -1, p_meas = -1, common_measure=-1, _detailed=_DETAILED, _ntnn_edges = True)\n",
    "\n",
    "\n",
    "        result_informed_json = {\n",
    "            \"decoding\": \"informed\",\n",
    "            \"num_errors\": result_informed.num_errors,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        ############# SAVING THE RESULT ##############\n",
    "\n",
    "        with open(f\"../results/softInfo_vs_informed.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            if job_id not in data.keys():\n",
    "                data[job_id] = [result_grid_json, result_kde_json, result_informed_json]\n",
    "            else:\n",
    "                data[job_id].append(result_grid_json)\n",
    "                data[job_id].append(result_kde_json)\n",
    "                data[job_id].append(result_informed_json)\n",
    "        \n",
    "        with open(f\"../results/softInfo_vs_informed.json\", \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandwidths: [0.4        0.41578947 0.43157895 0.44736842 0.46315789 0.47894737\n",
      " 0.49473684 0.51052632 0.52631579 0.54210526 0.55789474 0.57368421\n",
      " 0.58947368 0.60526316 0.62105263 0.63684211 0.65263158 0.66842105\n",
      " 0.68421053 0.7       ]\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-11-09 20:02:27+00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding jobs of 2023-11-09 16:47:14.556645+00:00 calibration: 100%|██████████| 46/46 [19:37<00:00, 25.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-10-27 08:32:22.841567+00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding jobs of 2023-10-27 07:46:44.189709+00:00 calibration: 100%|██████████| 7/7 [03:11<00:00, 27.30s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pymatching\n",
    "import stim \n",
    "from soft_info import get_noise_dict_from_backend, get_avgs_from_dict, find_longest_path_in_hex, get_repcode_IQ_map\n",
    "import cpp_soft_info\n",
    "from Scratch import load_calibration_memory, create_or_load_kde_grid\n",
    "\n",
    "_DETAILED = False\n",
    "\n",
    "rel_error = -1\n",
    "_RESETS = False\n",
    "nb_intervals = -1\n",
    "\n",
    "# KDE BANDWIDTHS\n",
    "lin = [0.4, 0.7, 20]\n",
    "num_points = 51\n",
    "\n",
    "# lin = [0.6, 0.7, 1]\n",
    "# num_points = 2\n",
    "\n",
    "bandwidths = np.linspace(lin[0], lin[1], lin[2])\n",
    "print(\"bandwidths:\", bandwidths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for calib_date in jobs_by_calibration_date.keys():\n",
    "\n",
    "    # get the noise dict of that date\n",
    "    noise_dict = get_noise_dict_from_backend(provider, DEVICE, date = calib_date)\n",
    "\n",
    "    # get the KDE of that date\n",
    "    all_memories = load_calibration_memory(provider, tobecalib_backend=DEVICE, other_date=calib_date)\n",
    "    kde_dict = cpp_soft_info.get_KDEs(all_memories, bandwidths, relError=rel_error, absError=-1, num_points=51) # Less num_points bcs just 1 bandwidth\n",
    "\n",
    "    # get the longest path of that device\n",
    "    longest_path, _, _ = find_longest_path_in_hex(provider.get_backend(DEVICE))\n",
    "\n",
    "    # decode each job of that date\n",
    "    for job_id in tqdm(jobs_by_calibration_date[calib_date], desc=f\"Decoding jobs of {calib_date} calibration\"):\n",
    "        distance = md[md[\"job_id\"] == job_id][\"distance\"].values[0]\n",
    "        rounds = md[md[\"job_id\"] == job_id][\"rounds\"].values[0]\n",
    "        IQ_data = provider.retrieve_job(job_id).result().get_memory()\n",
    "\n",
    "        # Get the layout for the avgs\n",
    "        bounded_path = longest_path[:2 * distance - 1]\n",
    "        layout = bounded_path[1::2] + bounded_path[::2]\n",
    "        qubit_mapping = get_repcode_IQ_map(layout, rounds)\n",
    "\n",
    "        # Get the avgs\n",
    "        avgs = get_avgs_from_dict(noise_dict, layout)\n",
    "\n",
    "        # Initialize the stim model\n",
    "        circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                distance=distance,\n",
    "                                rounds=rounds,\n",
    "                                after_clifford_depolarization=avgs[\"two_gate\"], #two-qubit-fidelity,\n",
    "                                after_reset_flip_probability=0 if not _RESETS else avgs[\"readout\"], #reset error\n",
    "                                before_measure_flip_probability=avgs[\"readout\"], #measurement error,\n",
    "                                before_round_data_depolarization=avgs[\"idle\"]) #idle error)\n",
    "        model = circuit.detector_error_model(decompose_errors=False)\n",
    "        matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "        ############# DECODING ##############\n",
    "\n",
    "\n",
    "        result_kde = cpp_soft_info.decode_IQ_kde(model, IQ_data, rounds, int(LOGICAL), _RESETS, \n",
    "                                         qubit_mapping, kde_dict, _DETAILED, relError=rel_error, absError=-1,\n",
    "                                         nb_intervals=nb_intervals)\n",
    "        \n",
    "        result_kde_json = {\n",
    "            \"decoding\": \"kde_relError\",\n",
    "            \"num_errors\": result_kde.num_errors,\n",
    "            \"additional_info\": {            \n",
    "                \"rel_error\": rel_error,\n",
    "                \"bandwidth_linspace\": lin,\n",
    "                \"num_points_bandwidths\": num_points\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "        ############# SAVING THE RESULT ##############\n",
    "\n",
    "        with open(f\"../results/softInfo_vs_informed.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            if job_id not in data.keys():\n",
    "                data[job_id] = [result_kde_json]\n",
    "            else:\n",
    "                data[job_id].append(result_kde_json)\n",
    "        \n",
    "        with open(f\"../results/softInfo_vs_informed.json\", \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandwidths: [0.6]\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-11-09 20:02:27+00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding jobs of 2023-11-09 16:47:14.556645+00:00 calibration: 100%|██████████| 46/46 [07:05<00:00,  9.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found jobs for backend ibm_sherbrooke with closest execution date 2023-10-27 08:32:22.841567+00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding jobs of 2023-10-27 07:46:44.189709+00:00 calibration: 100%|██████████| 7/7 [00:58<00:00,  8.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pymatching\n",
    "import stim \n",
    "from soft_info import get_noise_dict_from_backend, get_avgs_from_dict, find_longest_path_in_hex, get_repcode_IQ_map\n",
    "import cpp_soft_info\n",
    "from Scratch import load_calibration_memory, create_or_load_kde_grid\n",
    "\n",
    "_DETAILED = False\n",
    "\n",
    "rel_error = 1\n",
    "_RESETS = False\n",
    "nb_intervals = -1\n",
    "\n",
    "# KDE BANDWIDTHS\n",
    "# lin = [0.4, 0.7, 20]\n",
    "# num_points = 51\n",
    "\n",
    "lin = [0.6, 0.7, 1]\n",
    "num_points = 2\n",
    "\n",
    "bandwidths = np.linspace(lin[0], lin[1], lin[2])\n",
    "print(\"bandwidths:\", bandwidths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for calib_date in jobs_by_calibration_date.keys():\n",
    "\n",
    "    # get the noise dict of that date\n",
    "    noise_dict = get_noise_dict_from_backend(provider, DEVICE, date = calib_date)\n",
    "\n",
    "    # get the KDE of that date\n",
    "    all_memories = load_calibration_memory(provider, tobecalib_backend=DEVICE, other_date=calib_date)\n",
    "    kde_dict = cpp_soft_info.get_KDEs(all_memories, bandwidths, relError=rel_error, absError=-1, num_points=51) # Less num_points bcs just 1 bandwidth\n",
    "\n",
    "    # get the longest path of that device\n",
    "    longest_path, _, _ = find_longest_path_in_hex(provider.get_backend(DEVICE))\n",
    "\n",
    "    # decode each job of that date\n",
    "    for job_id in tqdm(jobs_by_calibration_date[calib_date], desc=f\"Decoding jobs of {calib_date} calibration\"):\n",
    "        distance = md[md[\"job_id\"] == job_id][\"distance\"].values[0]\n",
    "        rounds = md[md[\"job_id\"] == job_id][\"rounds\"].values[0]\n",
    "        IQ_data = provider.retrieve_job(job_id).result().get_memory()\n",
    "\n",
    "        # Get the layout for the avgs\n",
    "        bounded_path = longest_path[:2 * distance - 1]\n",
    "        layout = bounded_path[1::2] + bounded_path[::2]\n",
    "        qubit_mapping = get_repcode_IQ_map(layout, rounds)\n",
    "\n",
    "        # Get the avgs\n",
    "        avgs = get_avgs_from_dict(noise_dict, layout)\n",
    "\n",
    "        # Initialize the stim model\n",
    "        circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                distance=distance,\n",
    "                                rounds=rounds,\n",
    "                                after_clifford_depolarization=avgs[\"two_gate\"], #two-qubit-fidelity,\n",
    "                                after_reset_flip_probability=0 if not _RESETS else avgs[\"readout\"], #reset error\n",
    "                                before_measure_flip_probability=avgs[\"readout\"], #measurement error,\n",
    "                                before_round_data_depolarization=avgs[\"idle\"]) #idle error)\n",
    "        model = circuit.detector_error_model(decompose_errors=False)\n",
    "        matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "        ############# DECODING ##############\n",
    "\n",
    "\n",
    "        result_kde = cpp_soft_info.decode_IQ_kde(model, IQ_data, rounds, int(LOGICAL), _RESETS, \n",
    "                                         qubit_mapping, kde_dict, _DETAILED, relError=rel_error, absError=-1,\n",
    "                                         nb_intervals=nb_intervals)\n",
    "        \n",
    "        result_kde_json = {\n",
    "            \"decoding\": \"kde_bandwidth\",\n",
    "            \"num_errors\": result_kde.num_errors,\n",
    "            \"additional_info\": {            \n",
    "                \"rel_error\": rel_error,\n",
    "                \"bandwidth_linspace\": lin,\n",
    "                \"num_points_bandwidths\": num_points\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "        ############# SAVING THE RESULT ##############\n",
    "\n",
    "        with open(f\"../results/softInfo_vs_informed.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            if job_id not in data.keys():\n",
    "                data[job_id] = [result_kde_json]\n",
    "            else:\n",
    "                data[job_id].append(result_kde_json)\n",
    "        \n",
    "        with open(f\"../results/softInfo_vs_informed.json\", \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
