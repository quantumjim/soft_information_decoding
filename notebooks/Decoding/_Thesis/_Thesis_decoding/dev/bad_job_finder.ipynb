{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dec \n",
    "from result_saver import SaverProvider\n",
    "\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape md before: (40, 18)\n",
      "State: X0 50\n",
      "shape md: (20, 18)\n",
      "Calibration dates: dict_keys([datetime.datetime(2024, 3, 23, 13, 12, 1, 375000, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 3, 23, 13, 8, 53, 174000, tzinfo=datetime.timezone.utc)])\n",
      "Num of calibrations: 2\n",
      "Num of jobs per calibration: [12, 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'ibm_sherbrooke'\n",
    "LOGICAL = '0'\n",
    "XBASIS = True\n",
    "ROUNDS = 50\n",
    "\n",
    "\n",
    "md = dec.load_metadata(DEVICE, LOGICAL, XBASIS, ROUNDS)\n",
    "jobs_dict = dec.organize_jobs_by_calibration_date(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:29:14 Warning: Negative T2 error -0.08 % for qubit 38, setting to 0. T1: 6.421500990479847e-05, T2: 0.00015673252358240422. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 54\n",
      "08:29:14 Warning: Negative T2 error -0.01 % for qubit 39, setting to 0. T1: 0.00013169172467058469, T2: 0.00027539403593426396. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 54\n",
      "08:29:14 Warning: Negative T2 error -0.01 % for qubit 111, setting to 0. T1: 0.00016588647661947383, T2: 0.00034179903119965343. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 54\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2024-03-23 13:11:56.380893+00:00.\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2024-03-23 13:12:25.263713+00:00.\n"
     ]
    }
   ],
   "source": [
    "# for calib_date in jobs_dict:\n",
    "\n",
    "calib_date = list(jobs_dict.keys())[1]\n",
    "\n",
    "kde_dict, kde_dict_PS, msmt_error_dict, noise_dict = dec.retrieve_calib_data(provider, DEVICE, calib_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_memory, d, T, link_qubits, code_qubits, shots_per_job = dec.retrieve_memories_and_job_info(provider, jobs_dict[calib_date], md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soft_info import inv_qubit_mapping, get_repcode_IQ_map\n",
    "\n",
    "layout = link_qubits + code_qubits\n",
    "inv_q_mapping = inv_qubit_mapping(get_repcode_IQ_map(layout, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "\n",
    "pSoft, ratio, countMat, pSoft_PS, ratio_PS, countMat_PS = dec.get_pSoft_and_countMat(big_memory, kde_dict, kde_dict_PS, inv_q_mapping, threshold, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d_small in: \n",
    "d_small = 51\n",
    "\n",
    "pSoft_subset_big, countMat_subset_big, num_subsets, num_shots = dec.get_big_subset_mats(d_small, T, d, pSoft, countMat)\n",
    "# pSoft_subset_big_PS, countMat_subset_big_PS, num_subsets_PS, num_shots_PS = dec.get_big_subset_mats(d_small, T, d, pSoft_PS, countMat_PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.007733045348037615, 0.0003030722578189126, 0.0013368546211912028, 0.0037228032381900335, 0.023176929849005327, 0.01809322065246072, 0.005083709196544605]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "_RESETS = False\n",
    "\n",
    "model_mean_for_soft, model_mean_for_hard, model_mean_mean_for_hard, model_mean_mean_for_hard_PS, noise_list = dec.get_stim_models(noise_dict, msmt_error_dict, np.mean(pSoft), 0.01, d_small,\n",
    "                                                                                                                      d, T, LOGICAL, XBASIS, _RESETS, link_qubits, code_qubits)\n",
    "\n",
    "print(noise_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors s_K: 1\n",
      "num_errors h_K: 5\n",
      "num_errors h_K_mean: 1\n"
     ]
    }
   ],
   "source": [
    "import cpp_soft_info as csi\n",
    "\n",
    "res_s_K = csi.decodeConvertorAll(model_mean_for_soft, countMat_subset_big, pSoft_subset_big, T, \n",
    "                                                int(LOGICAL), _RESETS, decode_hard=False)\n",
    "res_h_K = csi.decodeConvertorAll(model_mean_for_hard, countMat_subset_big, pSoft_subset_big, T,\n",
    "                                                int(LOGICAL), _RESETS, decode_hard=True)\n",
    "res_h_K_mean = csi.decodeConvertorAll(model_mean_mean_for_hard, countMat_subset_big, pSoft_subset_big, T,\n",
    "                                                int(LOGICAL), _RESETS, decode_hard=True)\n",
    "\n",
    "print(f\"num_errors s_K: {res_s_K.num_errors}\")\n",
    "print(f\"num_errors h_K: {res_h_K.num_errors}\")\n",
    "print(f\"num_errors h_K_mean: {res_h_K_mean.num_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_shots_half: 12056\n",
      "num_errors s_K: 0\n",
      "num_errors h_K: 0\n",
      "num_errors h_K_mean: 0\n",
      "num_shots_half: 12056\n",
      "num_errors s_K: 0\n",
      "num_errors h_K: 0\n",
      "num_errors h_K_mean: 0\n",
      "num_shots_half: 12056\n",
      "num_errors s_K: 0\n",
      "num_errors h_K: 0\n",
      "num_errors h_K_mean: 0\n",
      "num_shots_half: 12056\n",
      "num_errors s_K: 0\n",
      "num_errors h_K: 1\n",
      "num_errors h_K_mean: 0\n",
      "num_shots_half: 12056\n",
      "num_errors s_K: 0\n",
      "num_errors h_K: 0\n",
      "num_errors h_K_mean: 0\n",
      "num_shots_half: 12056\n",
      "num_errors s_K: 0\n",
      "num_errors h_K: 2\n",
      "num_errors h_K_mean: 0\n",
      "num_shots_half: 12056\n",
      "num_errors s_K: 0\n",
      "num_errors h_K: 1\n",
      "num_errors h_K_mean: 0\n",
      "num_shots_half: 12056\n",
      "num_errors s_K: 1\n",
      "num_errors h_K: 1\n",
      "num_errors h_K_mean: 1\n"
     ]
    }
   ],
   "source": [
    "for job_idx, job_id in enumerate(jobs_dict[calib_date]):\n",
    "    num_shots_half = countMat_subset_big.shape[0] // 2\n",
    "    print(f\"num_shots_half: {num_shots_half}\")\n",
    "\n",
    "    rows = list(range(job_idx*1507, (job_idx+1)*1507)) + list(range(num_shots_half + job_idx*1507, num_shots_half + (job_idx+1)*1507))\n",
    "    countMatSub = countMat_subset_big[rows]\n",
    "    pSoftSub = pSoft_subset_big[rows]\n",
    "\n",
    "    res_s_K = csi.decodeConvertorAll(model_mean_for_soft, countMatSub, pSoftSub, T,\n",
    "                                                int(LOGICAL), _RESETS, decode_hard=False)\n",
    "    res_h_K = csi.decodeConvertorAll(model_mean_for_hard, countMatSub, pSoftSub, T,\n",
    "                                                int(LOGICAL), _RESETS, decode_hard=True)\n",
    "    res_h_K_mean = csi.decodeConvertorAll(model_mean_mean_for_hard, countMatSub, pSoftSub, T,\n",
    "                                                int(LOGICAL), _RESETS, decode_hard=True)\n",
    "    print(f\"num_errors s_K: {res_s_K.num_errors}\")\n",
    "    print(f\"num_errors h_K: {res_h_K.num_errors}\")\n",
    "    print(f\"num_errors h_K_mean: {res_h_K_mean.num_errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num errors in result: 23178\n",
      "num errors in num_errs_per_job: 23178\n",
      "num errors in result: 23753\n",
      "num errors in num_errs_per_job: 23753\n",
      "num errors in result: 23646\n",
      "num errors in num_errs_per_job: 23646\n",
      "num errors in result: 23096\n",
      "num errors in num_errs_per_job: 23096\n",
      "num errors in result: 23710\n",
      "num errors in num_errs_per_job: 23710\n",
      "num errors in result: 23830\n",
      "num errors in num_errs_per_job: 23830\n"
     ]
    }
   ],
   "source": [
    "job_ids = jobs_dict[calib_date] \n",
    "\n",
    "\n",
    "result_dict = {\n",
    "                'dict_s_K': dec.res_to_job_subset_res(res_s_K, shots_per_job, num_subsets, job_ids),\n",
    "                'dict_h_K': dec.res_to_job_subset_res(res_h_K, shots_per_job, num_subsets, job_ids),\n",
    "                'dict_h_K_mean': dec.res_to_job_subset_res(res_h_K_mean, shots_per_job, num_subsets, job_ids),\n",
    "                'dict_s_KPS': dec.res_to_job_subset_res(res_s_KPS, shots_per_job, num_subsets_PS, job_ids),\n",
    "                'dict_h_KPS': dec.res_to_job_subset_res(res_h_KPS, shots_per_job, num_subsets_PS, job_ids),\n",
    "                'dict_h_K_meanPS': dec.res_to_job_subset_res(res_h_K_meanPS, shots_per_job, num_subsets_PS, job_ids),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008774633384354788, 0.0003030722578189126, 0.0013368546211912028, 0.0037228032381900335, 0.023176929849005327, 0.01809322065246072, 0.005083709196544605]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "pSoft_mean = np.mean(pSoft) \n",
    "pSoft_PS_mean = np.mean(pSoft_PS)\n",
    "\n",
    "file_name = 'test.json'\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "                data = {}\n",
    "else:\n",
    "    with open(file_name, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "for job_id in job_ids:\n",
    "    if job_id not in data:\n",
    "        data[job_id] = {\"additional_info\": {\n",
    "            'threshold': threshold,\n",
    "            'ratio_leaked': ratio,\n",
    "            'ratio_leaked_PS': ratio_PS,\n",
    "            'pSoft_mean': pSoft_mean,\n",
    "            'pSoft_PS_mean': pSoft_PS_mean,\n",
    "            'noise_list': [float(noise) for noise in noise_list],\n",
    "        }, \"distances\": {}}\n",
    "\n",
    "    # if str(d_small) not in data[job_id]['distances']:\n",
    "    #     data[job_id][\"distances\"][str(d_small)] = {'tot_shots': num_shots}\n",
    "\n",
    "    # for method, res_dict in result_dict.items():\n",
    "    #     data[job_id]['distances'][str(d_small)][method[5:]] = {\n",
    "    #         'mean_errs': np.mean(res_dict[job_id]),\n",
    "    #         'errs': res_dict[job_id],\n",
    "    #     }\n",
    "\n",
    "with open(file_name, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(noise_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
