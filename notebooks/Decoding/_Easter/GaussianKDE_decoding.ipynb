{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state = X0\n",
      "shape: (1, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>notebook_name</th>\n",
       "      <th>backend_name</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>meas_level</th>\n",
       "      <th>shots</th>\n",
       "      <th>num_qubits</th>\n",
       "      <th>job_status</th>\n",
       "      <th>execution_date</th>\n",
       "      <th>code</th>\n",
       "      <th>distance</th>\n",
       "      <th>rounds</th>\n",
       "      <th>logical</th>\n",
       "      <th>descr</th>\n",
       "      <th>resets</th>\n",
       "      <th>xbasis</th>\n",
       "      <th>path_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>2024-03-23 14:11:49.436000+01:00</td>\n",
       "      <td>Sherbrooke_RepCodes_jobs</td>\n",
       "      <td>ibm_sherbrooke</td>\n",
       "      <td>cqzda58czq6g0081he8g</td>\n",
       "      <td>[Subset 52, 50 rounds, 0 log, xbasis=True]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JobStatus.DONE</td>\n",
       "      <td>2024-03-23 15:41:07.958655+01:00</td>\n",
       "      <td>RepetitionCodeCircuit</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>subset RepCodes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{'mean_gate_error': 0.007733045348037, 'min_ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         creation_date             notebook_name  \\\n",
       "5086  2024-03-23 14:11:49.436000+01:00  Sherbrooke_RepCodes_jobs   \n",
       "\n",
       "        backend_name                job_id  \\\n",
       "5086  ibm_sherbrooke  cqzda58czq6g0081he8g   \n",
       "\n",
       "                                            tags  meas_level   shots  \\\n",
       "5086  [Subset 52, 50 rounds, 0 log, xbasis=True]         1.0  1507.0   \n",
       "\n",
       "      num_qubits      job_status                    execution_date  \\\n",
       "5086         NaN  JobStatus.DONE  2024-03-23 15:41:07.958655+01:00   \n",
       "\n",
       "                       code  distance  rounds logical            descr resets  \\\n",
       "5086  RepetitionCodeCircuit        52      50       0  subset RepCodes    NaN   \n",
       "\n",
       "     xbasis                                          path_info  \n",
       "5086   True  {'mean_gate_error': 0.007733045348037, 'min_ga...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Scratch import metadata_loader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "DEVICE = \"ibm_sherbrooke\"\n",
    "LOGICAL = str(0)\n",
    "XBASIS = True\n",
    "ROUNDS = 50\n",
    "\n",
    "state = \"X\" if XBASIS else \"Z\"\n",
    "state += LOGICAL\n",
    "print(f\"state = {state}\")\n",
    "\n",
    "\n",
    "# Load the metadata\n",
    "while True:\n",
    "    try:\n",
    "        md = metadata_loader(True, True)\n",
    "        break\n",
    "    except:\n",
    "        sleep(5)\n",
    "md = md[md[\"job_status\"] == \"JobStatus.DONE\"]\n",
    "md = md[md[\"code\"] == \"RepetitionCodeCircuit\"]\n",
    "md = md[md[\"descr\"] == 'subset RepCodes']\n",
    "md = md.dropna(subset=[\"rounds\"])\n",
    "md = md[md[\"meas_level\"] == 1]\n",
    "md['rounds'] = md['rounds'].astype(int)\n",
    "md['distance'] = md['distance'].astype(int)\n",
    "\n",
    "md = md[md[\"backend_name\"] == DEVICE]\n",
    "md = md[md[\"logical\"] == LOGICAL]\n",
    "md = md[md[\"xbasis\"] == XBASIS]\n",
    "md = md[md[\"rounds\"] == ROUNDS]\n",
    "\n",
    "md = md[0:1]\n",
    "print(\"shape:\", md.shape)\n",
    "# md[18:]\n",
    "md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group job ids by closest calibration date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from Scratch import find_closest_calib_jobs\n",
    "import pandas as pd\n",
    "\n",
    "DOUBLE_MSMT = False # to get also 03-16\n",
    "\n",
    "jobs_by_calibration_date = {}\n",
    "for index, row in md.iterrows():\n",
    "    job_id = row['job_id']\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            _, _, calib_creation_date = find_closest_calib_jobs(tobecalib_job=job_id, verbose=False, double_msmt=DOUBLE_MSMT)\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "\n",
    "    if calib_creation_date not in jobs_by_calibration_date.keys():\n",
    "        jobs_by_calibration_date[calib_creation_date] = [job_id]\n",
    "    else:\n",
    "        jobs_by_calibration_date[calib_creation_date].append(job_id)\n",
    "\n",
    "# Takes 15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{datetime.datetime(2024, 3, 23, 13, 12, 1, 375000, tzinfo=datetime.timezone.utc): ['cqzda58czq6g0081he8g']}\n",
      "\n",
      "num of calibrations: 1\n",
      "num of jobs per calibration: [1]\n"
     ]
    }
   ],
   "source": [
    "print(jobs_by_calibration_date)\n",
    "print()\n",
    "print(f\"num of calibrations: {len(jobs_by_calibration_date)}\")\n",
    "print(f\"num of jobs per calibration: {([len(jobs) for jobs in jobs_by_calibration_date.values()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51, 47, 43, 39, 35, 31, 27, 23, 19, 15, 11,  7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = md[\"distance\"].values[0]\n",
    "\n",
    "distances = np.arange(7, d+1, 4)\n",
    "distances = distances[::-1]\n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:57:03 Warning: Z0 decoding. Negative T2 error -0.08 % for qubit 38, setting to 0.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 52\n",
      "13:57:03 Warning: Z0 decoding. Negative T2 error -0.01 % for qubit 39, setting to 0.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 52\n",
      "13:57:03 Warning: Z0 decoding. Negative T2 error -0.01 % for qubit 111, setting to 0.. IN FILE: /Users/mha/My_Drive/Desktop/Studium/Physik/MSc/Semester_3/IBM/IBM_GIT/Soft-Info/src/soft_info/Hardware/backend_noise.py, LINE: 52\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2024-03-23 13:11:56.380893+00:00.\n",
      "\n",
      "Qubit 20 shape mmr0: (31496,)\n",
      "\n",
      "Found jobs for backend ibm_sherbrooke with closest execution date 2024-03-23 13:12:25.263713+00:00.\n",
      "\n",
      "Qubit 20 for PS shape mmr0: (9078,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving jobs of 2024-03-23 13:12:01.375000+00:00 calibration: 100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big_memory shape: (1507, 2602)\n",
      "Starting to get pSoftG at 2024-04-01 13:58:03.936511\n",
      "Starting to get pSoftGKDE at 2024-04-01 13:58:04.489853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [1:33:03<00:00, 54.21s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished to get pSoftGKDE at 2024-04-01 15:31:08.203429\n",
      "Starting to get pSoftGKDE_PS at 2024-04-01 15:31:08.203445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [43:11<00:00, 25.16s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished to get pSoftGKDE_PS at 2024-04-01 16:14:19.918078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [03:53<00:00, 19.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pymatching\n",
    "import stim\n",
    "\n",
    "from soft_info import get_noise_dict_from_backend, get_avgs_from_dict, get_repcode_IQ_map\n",
    "from soft_info import RepetitionCodeStimCircuit, inv_qubit_mapping, gaussianIQConvertor\n",
    "from soft_info import get_cols_to_keep, generate_subsets_with_center, get_subsample_layout\n",
    "from Scratch import load_calibration_memory\n",
    "import cpp_soft_info as csi\n",
    "from soft_info import gaussianKDEIQconvertor, get_KDEs\n",
    "\n",
    "file_name  = f'./results/result_day2/GAUSSIANKDE{DEVICE}_{state}_{ROUNDS}.json'\n",
    "\n",
    "HANDLE_OUTLIERS = True\n",
    "\n",
    "rel_error = 1\n",
    "_RESETS = False\n",
    "nb_intervals = -1\n",
    "\n",
    "# KDE BANDWIDTHS\n",
    "lin = [0.6, 1.2, 1]\n",
    "num_points = 20\n",
    "# lin = [0.1, 0.7, 1]\n",
    "# num_points = 7\n",
    "bandwidths = np.linspace(lin[0], lin[1], lin[2])\n",
    "\n",
    "bandwidth = 0.1 # Gaussians\n",
    "# bandwidths = 0.2 # Tophat\n",
    "\n",
    "\n",
    "for calib_date in jobs_by_calibration_date.keys():\n",
    "    # get the noise dict of that date\n",
    "    noise_dict = get_noise_dict_from_backend(provider, DEVICE, date = calib_date)\n",
    "\n",
    "    # get the KDE of that date\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            all_memories, gmm_dict, _ = load_calibration_memory(provider, tobecalib_backend=DEVICE, \n",
    "                                                                        other_date=calib_date, post_process=True,\n",
    "                                                                        double_msmt=False)\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "    print(f\"\\nQubit 20 shape mmr0: {all_memories[20]['mmr_0'].shape}\\n\")\n",
    "\n",
    "    # kde_dict = csi.get_KDEs(all_memories, bandwidths, relError=rel_error, absError=-1, num_points=num_points)\n",
    "    kde_dict, scaler_dict = get_KDEs(all_memories, bandwidths = bandwidth)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            all_memories_PS, gmm_dict_PS, msmt_err_dict_PS = load_calibration_memory(provider, tobecalib_backend=DEVICE, \n",
    "                                                                            other_date=calib_date, post_process=True,\n",
    "                                                                            double_msmt=True)\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "\n",
    "    print(f\"\\nQubit 20 for PS shape mmr0: {all_memories_PS[20]['mmr_0'].shape}\\n\")\n",
    "    # kde_dict_PS = csi.get_KDEs(all_memories_PS, bandwidths, relError=rel_error, absError=-1, num_points=num_points)\n",
    "    kde_dict_PS, scaler_dict_PS = get_KDEs(all_memories_PS, bandwidths = bandwidth)\n",
    "\n",
    "    # Get the mean msmt errors\n",
    "    p_soft_mean = 0\n",
    "    p_hard_mean = 0\n",
    "    for key, value in msmt_err_dict_PS.items():\n",
    "        p_soft_mean += value['p_soft']\n",
    "        p_hard_mean += value['p_hard']\n",
    "    p_soft_mean /= len(msmt_err_dict_PS)\n",
    "    p_hard_mean /= len(msmt_err_dict_PS)\n",
    "    # print(msmt_err_dict_PS, p_soft_mean, p_hard_mean)\n",
    "\n",
    "    # for i in range(127):\n",
    "    #     print(f\"qubit {i}: {kde_dict[i].bestBandwidth}\", end=' ')\n",
    "    # print(\"\\nPS\", end=' ')\n",
    "    # for i in range(127):\n",
    "    #     print(f\"qubit {i}: {kde_dict_PS[i].bestBandwidth}\", end=' ')\n",
    "\n",
    "    # Retrieve the memories\n",
    "    memories = []\n",
    "    for job_id in tqdm(jobs_by_calibration_date[calib_date], desc=f\"Retrieving jobs of {calib_date} calibration\"):\n",
    "        d = md[md[\"job_id\"] == job_id][\"distance\"].values[0] \n",
    "        T = md[md[\"job_id\"] == job_id][\"rounds\"].values[0] # Should be 10\n",
    "\n",
    "        # Get the job\n",
    "        job = provider.retrieve_job(job_id)\n",
    "        memory = job.result().get_memory()\n",
    "        memories.append(memory)\n",
    "\n",
    "    # Stack the memories vertically\n",
    "    big_memory = np.vstack(memories)\n",
    "    NB_SHOTS = big_memory.shape[0]\n",
    "\n",
    "    # big_memory = big_memory[:NB_SHOTS//100] # 1% of the data\n",
    "    print(f\"big_memory shape: {big_memory.shape}\")\n",
    "\n",
    "    # Get the layout of the last job (same as previous)\n",
    "    layout_des = job.deserialize_layout(job.initial_layouts()[0]) # only 1 layout\n",
    "    link_qubits = list(layout_des['link_qubit'].values())\n",
    "    code_qubits = list(layout_des['code_qubit'].values())\n",
    "\n",
    "    # Get the pSoft and countMat matrices\n",
    "    big_layout = link_qubits + code_qubits\n",
    "    inverted_q_map = inv_qubit_mapping(get_repcode_IQ_map(big_layout, synd_rounds=T))\n",
    "\n",
    "    # print(f\"Starting to get pSoft and countMat at {datetime.now()}\")\n",
    "    # pSoft, countMat = csi.iqConvertor(big_memory, inverted_q_map, kde_dict, rel_error, -1,\n",
    "    #                                             handleOutliers = HANDLE_OUTLIERS)\n",
    "    \n",
    "    # print(f\"Starting to get pSoft_PS and countMat_PS at {datetime.now()}\")\n",
    "    # pSoft_PS, countMat_PS = csi.iqConvertor(big_memory, inverted_q_map, kde_dict_PS, rel_error, -1,\n",
    "    #                                                   handleOutliers = HANDLE_OUTLIERS)\n",
    "    \n",
    "    print(f\"Starting to get pSoftG at {datetime.now()}\")\n",
    "    countMatG, pSoftG = gaussianIQConvertor(big_memory, inverted_q_map, gmm_dict)\n",
    "\n",
    "    print(f\"Starting to get pSoftGKDE at {datetime.now()}\")\n",
    "    countMatGKDE, pSoftGKDE = gaussianKDEIQconvertor(big_memory, inverted_q_map, kde_dict, scaler_dict)\n",
    "    print(f\"Finished to get pSoftGKDE at {datetime.now()}\")\n",
    "\n",
    "    print(f\"Starting to get pSoftGKDE_PS at {datetime.now()}\")\n",
    "    countMatGKDE_PS, pSoftGKDE_PS = gaussianKDEIQconvertor(big_memory, inverted_q_map, kde_dict_PS, scaler_dict_PS)\n",
    "    print(f\"Finished to get pSoftGKDE_PS at {datetime.now()}\")\n",
    "\n",
    "\n",
    "    # Subsample decoding\n",
    "    for D_NEW in tqdm(distances):\n",
    "        subsets = generate_subsets_with_center(d, D_NEW)\n",
    "\n",
    "        err_s_G_mean = []\n",
    "        err_s_G_indiv = []\n",
    "        err_h_G_indiv = []\n",
    "        err_h_G_mean = []\n",
    "        # err_s_K_mean = []\n",
    "        # err_s_K_indiv = []\n",
    "        # err_h_K_indiv = []\n",
    "        # err_h_K_mean = []\n",
    "        # err_s_KPS_mean = []\n",
    "        # err_s_KPS_indiv = []\n",
    "        # err_h_KPS_indiv = []\n",
    "        # err_h_KPS_mean = []\n",
    "        err_h_G_mean_mean = []\n",
    "        # err_h_K_mean_mean = []\n",
    "        # err_h_KPS_mean_mean = []\n",
    "        err_s_GKDE_mean = []\n",
    "        err_s_GKDE_indiv = []\n",
    "        err_h_GKDE_indiv = []\n",
    "        err_h_GKDE_mean = []\n",
    "        err_h_GKDE_mean_mean = []\n",
    "\n",
    "        err_s_GKDE_PS_mean = []\n",
    "        err_s_GKDE_PS_indiv = []\n",
    "        err_h_GKDE_PS_indiv = []\n",
    "        err_h_GKDE_PS_mean = []\n",
    "        err_h_GKDE_PS_mean_mean = []\n",
    "        for subset in (subsets):             \n",
    "            cols_to_keep = get_cols_to_keep(subset, T, d)\n",
    "\n",
    "            # Get the subset of pSoft and countMat\n",
    "            # pSoft_sub = pSoft[:, cols_to_keep]\n",
    "            # pSoft_PS_sub = pSoft_PS[:, cols_to_keep]\n",
    "            pSoftG_sub = pSoftG[:, cols_to_keep]\n",
    "            # countMat_sub = countMat[:, cols_to_keep]\n",
    "            # countMat_PS_sub = countMat_PS[:, cols_to_keep]\n",
    "            countMatG_sub = countMatG[:, cols_to_keep]\n",
    "            countMatGKDE_sub = countMatGKDE[:, cols_to_keep]\n",
    "            pSoftGKDE_sub = pSoftGKDE[:, cols_to_keep]\n",
    "            countMatGKDE_PS_sub = countMatGKDE_PS[:, cols_to_keep]\n",
    "            pSoftGKDE_PS_sub = pSoftGKDE_PS[:, cols_to_keep]\n",
    "\n",
    "            # Means for hard decoding\n",
    "            # pSoft_mean = np.mean(pSoft_sub)\n",
    "            # pSoft_PS_mean = np.mean(pSoft_PS_sub)\n",
    "            pSoftG_mean = np.mean(pSoftG_sub)\n",
    "            pSoftGKDE_mean = np.mean(pSoftGKDE_sub)\n",
    "            pSoftGKDE_PS_mean = np.mean(pSoftGKDE_PS_sub)\n",
    "\n",
    "            # Get the layout\n",
    "            layout = get_subsample_layout(subset, link_qubits, code_qubits)\n",
    "            qubit_mapping = get_repcode_IQ_map(layout, synd_rounds=T)\n",
    "\n",
    "            # Get the noise avgs\n",
    "            avgs = get_avgs_from_dict(noise_dict, layout)\n",
    "            noise_list = [avgs[\"two_gate\"], avgs[\"single_gate\"], avgs[\"t1_err\"], avgs[\"t2_err\"]]\n",
    "            readout = avgs[\"readout\"]\n",
    "            noise_list += [(p_hard_mean+p_soft_mean), p_hard_mean, p_soft_mean]\n",
    "            #[twog_err, sglg_err, t1_err, t2_err, readout_err, hard_err, soft_err]\n",
    "\n",
    "            # Stim models\n",
    "            subsampling = (D_NEW != d)\n",
    "\n",
    "            code_indiv_for_soft = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "                                                            subsampling=subsampling, no_fin_soft=True, layout=layout,\n",
    "                                                            msmt_err_dict=msmt_err_dict_PS)\n",
    "            model_indiv_for_soft = code_indiv_for_soft.circuits[LOGICAL].detector_error_model()\n",
    "\n",
    "            code_indiv_for_hard = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "                                                            subsampling=subsampling, no_fin_soft=False, layout=layout,\n",
    "                                                            msmt_err_dict=msmt_err_dict_PS)\n",
    "            model_indiv_for_hard = code_indiv_for_hard.circuits[LOGICAL].detector_error_model()\n",
    "\n",
    "            code_mean_for_soft = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "                                                            subsampling=subsampling, no_fin_soft=True, layout=None,\n",
    "                                                            msmt_err_dict=None)\n",
    "            model_mean_for_soft = code_mean_for_soft.circuits[LOGICAL].detector_error_model()\n",
    "\n",
    "            code_mean_for_hard = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "                                                            subsampling=subsampling, no_fin_soft=False, layout=None,\n",
    "                                                            msmt_err_dict=None)\n",
    "            model_mean_for_hard = code_mean_for_hard.circuits[LOGICAL].detector_error_model()\n",
    "            \n",
    "\n",
    "            # Decoding\n",
    "\n",
    "            ### Gaussian KDE\n",
    "            res_s_GKDE_mean = csi.decodeConvertorAll(model_mean_for_soft, countMatGKDE_sub, pSoftGKDE_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            res_s_GKDE_indiv = csi.decodeConvertorAll(model_indiv_for_soft, countMatGKDE_sub, pSoftGKDE_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            res_h_GKDE_indiv = csi.decodeConvertorAll(model_indiv_for_hard, countMatGKDE_sub, pSoftGKDE_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            res_h_GKDE_mean = csi.decodeConvertorAll(model_mean_for_hard, countMatGKDE_sub, pSoftGKDE_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            noise_list[-1] = pSoftGKDE_mean\n",
    "            code_mean_mean = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "                                                            subsampling=subsampling, no_fin_soft=False, layout=None,\n",
    "                                                            msmt_err_dict=None)\n",
    "            model_mean_mean = code_mean_mean.circuits[LOGICAL].detector_error_model()\n",
    "            res_h_GKDE_mean_mean = csi.decodeConvertorAll(model_mean_mean, countMatGKDE_sub, pSoftGKDE_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "\n",
    "            ### Gaussian KDE PS\n",
    "            res_s_GKDE_PS_mean = csi.decodeConvertorAll(model_mean_for_soft, countMatGKDE_PS_sub, pSoftGKDE_PS_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            res_s_GKDE_PS_indiv = csi.decodeConvertorAll(model_indiv_for_soft, countMatGKDE_PS_sub, pSoftGKDE_PS_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            res_h_GKDE_PS_indiv = csi.decodeConvertorAll(model_indiv_for_hard, countMatGKDE_PS_sub, pSoftGKDE_PS_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            res_h_GKDE_PS_mean = csi.decodeConvertorAll(model_mean_for_hard, countMatGKDE_PS_sub, pSoftGKDE_PS_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            noise_list[-1] = pSoftGKDE_PS_mean\n",
    "            code_mean_mean = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "                                                            subsampling=subsampling, no_fin_soft=False, layout=None,\n",
    "                                                            msmt_err_dict=None)\n",
    "            model_mean_mean = code_mean_mean.circuits[LOGICAL].detector_error_model()\n",
    "            res_h_GKDE_PS_mean_mean = csi.decodeConvertorAll(model_mean_mean, countMatGKDE_PS_sub, pSoftGKDE_PS_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "\n",
    "            ### Gaussian\n",
    "            res_s_G_mean = csi.decodeConvertorAll(model_mean_for_soft, countMatG_sub, pSoftG_sub, T,\n",
    "                                                  int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            res_s_G_indiv = csi.decodeConvertorAll(model_indiv_for_soft, countMatG_sub, pSoftG_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            res_h_G_indiv = csi.decodeConvertorAll(model_indiv_for_hard, countMatG_sub, pSoftG_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            res_h_G_mean = csi.decodeConvertorAll(model_mean_for_hard, countMatG_sub, pSoftG_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            noise_list[-1] = pSoftG_mean\n",
    "            code_mean_mean = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "                                                            subsampling=subsampling, no_fin_soft=False, layout=None,\n",
    "                                                            msmt_err_dict=None)\n",
    "            model_mean_mean = code_mean_mean.circuits[LOGICAL].detector_error_model()\n",
    "            res_h_G_mean_mean = csi.decodeConvertorAll(model_mean_mean, countMatG_sub, pSoftG_sub, T,\n",
    "                                                    int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            # ### KDE\n",
    "            # res_s_K_mean = csi.decodeConvertorAll(model_mean_for_soft, countMat_sub, pSoft_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            # res_s_K_indiv = csi.decodeConvertorAll(model_indiv_for_soft, countMat_sub, pSoft_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            # res_h_K_indiv = csi.decodeConvertorAll(model_indiv_for_hard, countMat_sub, pSoft_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            # res_h_K_mean = csi.decodeConvertorAll(model_mean_for_hard, countMat_sub, pSoft_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            # noise_list[-1] = pSoft_mean\n",
    "            # code_mean_mean = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "            #                                             subsampling=subsampling, no_fin_soft=False, layout=None,\n",
    "            #                                             msmt_err_dict=None)\n",
    "            # model_mean_mean = code_mean_mean.circuits[LOGICAL].detector_error_model()\n",
    "            # res_h_K_mean_mean = csi.decodeConvertorAll(model_mean_mean, countMat_sub, pSoft_sub, T,\n",
    "            #                                             int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            # ### KDE PS\n",
    "            # res_s_KPS_mean = csi.decodeConvertorAll(model_mean_for_soft, countMat_PS_sub, pSoft_PS_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            # res_s_KPS_indiv = csi.decodeConvertorAll(model_indiv_for_soft, countMat_PS_sub, pSoft_PS_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=False)\n",
    "            # res_h_KPS_indiv = csi.decodeConvertorAll(model_indiv_for_hard, countMat_PS_sub, pSoft_PS_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            # res_h_KPS_mean = csi.decodeConvertorAll(model_mean_for_hard, countMat_PS_sub, pSoft_PS_sub, T,\n",
    "            #                                         int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            # noise_list[-1] = pSoft_PS_mean\n",
    "            # code_mean_mean = RepetitionCodeStimCircuit(D_NEW, T, XBASIS, _RESETS, noise_list=noise_list,\n",
    "            #                                             subsampling=subsampling, no_fin_soft=False, layout=None,\n",
    "            #                                             msmt_err_dict=None)\n",
    "            # model_mean_mean = code_mean_mean.circuits[LOGICAL].detector_error_model()\n",
    "            # res_h_KPS_mean_mean = csi.decodeConvertorAll(model_mean_mean, countMat_PS_sub, pSoft_PS_sub, T,\n",
    "            #                                             int(LOGICAL), _RESETS, decode_hard=True)\n",
    "            \n",
    "            # Append the results\n",
    "            err_s_GKDE_mean.append(res_s_GKDE_mean.num_errors)\n",
    "            err_s_GKDE_indiv.append(res_s_GKDE_indiv.num_errors)\n",
    "            err_h_GKDE_indiv.append(res_h_GKDE_indiv.num_errors)\n",
    "            err_h_GKDE_mean.append(res_h_GKDE_mean.num_errors)\n",
    "\n",
    "            err_h_GKDE_mean_mean.append(res_h_GKDE_mean_mean.num_errors)\n",
    "\n",
    "            err_s_GKDE_PS_mean.append(res_s_GKDE_PS_mean.num_errors)\n",
    "            err_s_GKDE_PS_indiv.append(res_s_GKDE_PS_indiv.num_errors)\n",
    "            err_h_GKDE_PS_indiv.append(res_h_GKDE_PS_indiv.num_errors)\n",
    "            err_h_GKDE_PS_mean.append(res_h_GKDE_PS_mean.num_errors)\n",
    "\n",
    "            err_h_GKDE_PS_mean_mean.append(res_h_GKDE_PS_mean_mean.num_errors)\n",
    "\n",
    "\n",
    "            err_s_G_mean.append(res_s_G_mean.num_errors)\n",
    "            err_s_G_indiv.append(res_s_G_indiv.num_errors)\n",
    "            err_h_G_indiv.append(res_h_G_indiv.num_errors)\n",
    "            err_h_G_mean.append(res_h_G_mean.num_errors)\n",
    "            # err_s_K_mean.append(res_s_K_mean.num_errors)\n",
    "            # err_s_K_indiv.append(res_s_K_indiv.num_errors)\n",
    "            # err_h_K_indiv.append(res_h_K_indiv.num_errors)\n",
    "            # err_h_K_mean.append(res_h_K_mean.num_errors)\n",
    "            # err_s_KPS_mean.append(res_s_KPS_mean.num_errors)\n",
    "            # err_s_KPS_indiv.append(res_s_KPS_indiv.num_errors)\n",
    "            # err_h_KPS_indiv.append(res_h_KPS_indiv.num_errors)\n",
    "            # err_h_KPS_mean.append(res_h_KPS_mean.num_errors)\n",
    "\n",
    "            err_h_G_mean_mean.append(res_h_G_mean_mean.num_errors)\n",
    "            # err_h_K_mean_mean.append(res_h_K_mean_mean.num_errors)\n",
    "            # err_h_KPS_mean_mean.append(res_h_KPS_mean_mean.num_errors)\n",
    "\n",
    "\n",
    "        # Save the results\n",
    "\n",
    "        json_GKDE = {\n",
    "            \"decoding\": \"GaussianKDE\",\n",
    "            \"d_new\": str(D_NEW),\n",
    "            \"error_list_dict\": {\n",
    "                \"soft_mean\": err_s_GKDE_mean,\n",
    "                \"soft_indiv\": err_s_GKDE_indiv,\n",
    "                \"hard_indiv\": err_h_GKDE_indiv,\n",
    "                \"hard_mean\": err_h_GKDE_mean,\n",
    "                \"hard_mean_mean\": err_h_GKDE_mean_mean,\n",
    "            },\n",
    "            \"error_mean_dict\": {\n",
    "                \"soft_mean\": np.mean(err_s_GKDE_mean),\n",
    "                \"soft_indiv\": np.mean(err_s_GKDE_indiv),\n",
    "                \"hard_indiv\": np.mean(err_h_GKDE_indiv),\n",
    "                \"hard_mean\": np.mean(err_h_GKDE_mean),\n",
    "                \"hard_mean_mean\": np.mean(err_h_GKDE_mean_mean),\n",
    "                \"pSoftGKDE_mean\": pSoftGKDE_mean,\n",
    "            },\n",
    "            \"additional_info\": {\n",
    "                \"calib_date\": str(calib_date),\n",
    "                \"noise_list\": noise_list,\n",
    "                \"calib_readout\": readout,\n",
    "                \"p_soft_mean\": p_soft_mean,\n",
    "                \"p_hard_mean\": p_hard_mean,\n",
    "                \"p_softGKDE_mean\": pSoftGKDE_mean,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        json_GKDE_PS = {\n",
    "            \"decoding\": \"GaussianKDE_PS\",\n",
    "            \"d_new\": str(D_NEW),\n",
    "            \"error_list_dict\": {\n",
    "                \"soft_mean\": err_s_GKDE_PS_mean,\n",
    "                \"soft_indiv\": err_s_GKDE_PS_indiv,\n",
    "                \"hard_indiv\": err_h_GKDE_PS_indiv,\n",
    "                \"hard_mean\": err_h_GKDE_PS_mean,\n",
    "                \"hard_mean_mean\": err_h_GKDE_PS_mean_mean,\n",
    "            },\n",
    "            \"error_mean_dict\": {\n",
    "                \"soft_mean\": np.mean(err_s_GKDE_PS_mean),\n",
    "                \"soft_indiv\": np.mean(err_s_GKDE_PS_indiv),\n",
    "                \"hard_indiv\": np.mean(err_h_GKDE_PS_indiv),\n",
    "                \"hard_mean\": np.mean(err_h_GKDE_PS_mean),\n",
    "                \"hard_mean_mean\": np.mean(err_h_GKDE_PS_mean_mean),\n",
    "            },\n",
    "            \"additional_info\": {\n",
    "                \"p_softGKDE_PS_mean\": pSoftGKDE_PS_mean,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        json_Gaussian = {\n",
    "            \"decoding\": \"1Dgaussian\",\n",
    "            \"d_new\": str(D_NEW),\n",
    "            \"error_list_dict\": {\n",
    "                \"soft_mean\": err_s_G_mean,\n",
    "                \"soft_indiv\": err_s_G_indiv,\n",
    "                \"hard_indiv\": err_h_G_indiv,\n",
    "                \"hard_mean\": err_h_G_mean,\n",
    "                \"hard_mean_mean\": err_h_G_mean_mean,\n",
    "            },\n",
    "            \"error_mean_dict\": {\n",
    "                \"soft_mean\": np.mean(err_s_G_mean),\n",
    "                \"soft_indiv\": np.mean(err_s_G_indiv),\n",
    "                \"hard_indiv\": np.mean(err_h_G_indiv),\n",
    "                \"hard_mean\": np.mean(err_h_G_mean),\n",
    "                \"hard_mean_mean\": np.mean(err_h_G_mean_mean),\n",
    "            },      \n",
    "            \"additional_info\": {\n",
    "                \"calib_date\": str(calib_date),\n",
    "                \"noise_list\": noise_list,\n",
    "                \"calib_readout\": readout,\n",
    "                \"p_soft_mean\": p_soft_mean,\n",
    "                \"p_hard_mean\": p_hard_mean,\n",
    "                \"p_softG_mean\": pSoftG_mean,\n",
    "            },    \n",
    "        }\n",
    "\n",
    "        # json_KDE = {\n",
    "        #     \"decoding\": \"kde\",\n",
    "        #     \"d_new\": str(D_NEW),\n",
    "        #     \"error_list_dict\": {\n",
    "        #         \"soft_mean\": err_s_K_mean,\n",
    "        #         \"soft_indiv\": err_s_K_indiv,\n",
    "        #         \"hard_indiv\": err_h_K_indiv,\n",
    "        #         \"hard_mean\": err_h_K_mean,\n",
    "        #         \"hard_mean_mean\": err_h_K_mean_mean,\n",
    "        #     },\n",
    "        #     \"error_mean_dict\": {\n",
    "        #         \"soft_mean\": np.mean(err_s_K_mean),\n",
    "        #         \"soft_indiv\": np.mean(err_s_K_indiv),\n",
    "        #         \"hard_indiv\": np.mean(err_h_K_indiv),\n",
    "        #         \"hard_mean\": np.mean(err_h_K_mean),\n",
    "        #         \"hard_mean_mean\": np.mean(err_h_K_mean_mean),\n",
    "        #     },   \n",
    "        #     \"additional_info\": {\n",
    "        #         \"rel_error\": rel_error,\n",
    "        #         \"bandwidth_linspace\": lin,\n",
    "        #         \"num_points_bandwidths\": num_points,\n",
    "        #         \"pSoft_mean\": pSoft_mean,\n",
    "        #     },        \n",
    "        # }\n",
    "\n",
    "        # json_KDE_PS = {\n",
    "        #     \"decoding\": \"kde_PS\",\n",
    "        #     \"d_new\": str(D_NEW),\n",
    "        #     \"error_list_dict\": {\n",
    "        #         \"soft_mean\": err_s_KPS_mean,\n",
    "        #         \"soft_indiv\": err_s_KPS_indiv,\n",
    "        #         \"hard_indiv\": err_h_KPS_indiv,\n",
    "        #         \"hard_mean\": err_h_KPS_mean,\n",
    "        #         \"hard_mean_mean\": err_h_KPS_mean_mean,\n",
    "        #     },\n",
    "        #     \"error_mean_dict\": {\n",
    "        #         \"soft_mean\": np.mean(err_s_KPS_mean),\n",
    "        #         \"soft_indiv\": np.mean(err_s_KPS_indiv),\n",
    "        #         \"hard_indiv\": np.mean(err_h_KPS_indiv),\n",
    "        #         \"hard_mean\": np.mean(err_h_KPS_mean),\n",
    "        #         \"hard_mean_mean\": np.mean(err_h_KPS_mean_mean),\n",
    "        #         \"pSoft_PS_mean\": pSoft_PS_mean,\n",
    "        #     },   \n",
    "        # }\n",
    "\n",
    "        if not os.path.exists(file_name):\n",
    "            data = {}\n",
    "        else:\n",
    "            with open(file_name, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "        if job_id not in data.keys():\n",
    "            data[job_id] = [{'totshots': NB_SHOTS}, json_Gaussian, json_GKDE, json_GKDE_PS]\n",
    "            # data[job_id] = [{'totshots': NB_SHOTS}, json_Gaussian, json_KDE, json_KDE_PS]\n",
    "        else:\n",
    "            data[job_id].append(json_Gaussian)\n",
    "            data[job_id].append(json_GKDE)\n",
    "            data[job_id].append(json_GKDE_PS)\n",
    "            # data[job_id].append(json_KDE)\n",
    "            # data[job_id].append(json_KDE_PS)\n",
    "        \n",
    "        with open(file_name, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
