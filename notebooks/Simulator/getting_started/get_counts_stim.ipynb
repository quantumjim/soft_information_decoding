{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the RepCode circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_saver import SaverProvider\n",
    "\n",
    "provider = SaverProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding the longest path starting from 27 qubits: 100%|██████████| 27/27 [00:00<00:00, 24726.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from qiskit_qec.circuits import RepetitionCodeCircuit\n",
    "from soft_info import get_repcode_layout\n",
    "\n",
    "DISTANCE = 3\n",
    "ROUNDS = 3\n",
    "DEVICE = \"ibmq_mumbai\"\n",
    "LOGICAL = '1'\n",
    "SHOTS = 1e4\n",
    "\n",
    "code = RepetitionCodeCircuit(DISTANCE, ROUNDS)\n",
    "backend = provider.get_backend(DEVICE)\n",
    "layout = get_repcode_layout(DISTANCE, backend, _is_hex=False)\n",
    "\n",
    "qc = code.circuit[LOGICAL]                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_qec.noise import PauliNoiseModel\n",
    "\n",
    "def get_noise_model(p1Q, p2Q, pXY, pZ, pRO, pRE):\n",
    "\n",
    "    error_dict = {\n",
    "        'reset': {\n",
    "            \"chan\": {\n",
    "                        'i':1-pRE,\n",
    "                        'x':pRE\n",
    "                    }\n",
    "                },\n",
    "        'measure': {\n",
    "            \"chan\": {\n",
    "                        'i':1-pRO,\n",
    "                        'x':pRO\n",
    "                    }\n",
    "                },\n",
    "        'h': {\n",
    "            \"chan\": {\n",
    "                        'i':1-p1Q\n",
    "                    }|\n",
    "                    {\n",
    "                        i:p1Q/3\n",
    "                        for i in 'xyz'\n",
    "                    }\n",
    "                },\n",
    "        #idling error attached to a custom gate \"idle_1\" (assumed to be the identity acting on a single qubit)\n",
    "        'idle_1': {\n",
    "            \"chan\": {\n",
    "                        'i':1-pXY,\n",
    "                        'x':pXY/2,\n",
    "                        'y':pXY/2\n",
    "                    }\n",
    "                },\n",
    "        #another type of idling error attached to a custom gate \"idle_2\" (assumed to be the identity acting on a single qubit)\n",
    "        'idle_2': {\n",
    "            \"chan\": {\n",
    "                        'i':1-pZ,\n",
    "                        'z':pZ\n",
    "                    }\n",
    "                },\n",
    "\n",
    "        'cx': {\n",
    "            \"chan\": {\n",
    "                        'ii':1-p2Q\n",
    "                    }|\n",
    "                    {\n",
    "                        i+j:p2Q/15\n",
    "                        for i in 'ixyz'\n",
    "                        for j in 'ixyz'\n",
    "                        if i+j!='ii'\n",
    "                    }\n",
    "                },\n",
    "        'swap': {\n",
    "            \"chan\": {\n",
    "                        'ii':1-p2Q\n",
    "                    }|\n",
    "                    {\n",
    "                        i+j:p2Q/15\n",
    "                        for i in 'ixyz'\n",
    "                        for j in 'ixyz'\n",
    "                        if i+j!='ii'\n",
    "                    }\n",
    "                }\n",
    "                }\n",
    "\n",
    "    noise_model = PauliNoiseModel(fromdict=error_dict)\n",
    "\n",
    "    return noise_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get counts via stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('111 00 00 00', 3781),\n",
       " ('111 10 10 10', 426),\n",
       " ('101 00 00 00', 424),\n",
       " ('111 10 00 00', 422),\n",
       " ('111 01 00 00', 406),\n",
       " ('110 00 00 00', 405),\n",
       " ('111 01 01 00', 404),\n",
       " ('011 00 00 00', 400),\n",
       " ('111 01 01 01', 395),\n",
       " ('111 10 10 00', 392),\n",
       " ('101 01 00 00', 80),\n",
       " ('010 00 00 00', 65),\n",
       " ('110 01 00 00', 60),\n",
       " ('011 10 00 00', 56),\n",
       " ('111 11 01 01', 53),\n",
       " ('101 10 00 00', 52),\n",
       " ('111 11 11 01', 52),\n",
       " ('111 00 00 01', 52),\n",
       " ('110 10 00 00', 52),\n",
       " ('101 10 10 10', 52),\n",
       " ('111 00 00 10', 51),\n",
       " ('011 10 10 00', 50),\n",
       " ('110 10 10 10', 50),\n",
       " ('110 10 10 00', 50),\n",
       " ('111 00 01 01', 49),\n",
       " ('110 01 01 01', 49),\n",
       " ('111 11 11 11', 49),\n",
       " ('111 00 01 00', 46),\n",
       " ('011 01 01 01', 46),\n",
       " ('110 01 01 00', 46),\n",
       " ('011 01 01 00', 45),\n",
       " ('101 01 01 01', 45),\n",
       " ('101 01 01 00', 45),\n",
       " ('111 11 00 00', 44),\n",
       " ('111 00 10 10', 44),\n",
       " ('001 00 00 00', 43),\n",
       " ('111 11 11 00', 43),\n",
       " ('111 11 11 10', 42),\n",
       " ('111 11 01 00', 41),\n",
       " ('111 11 10 10', 40),\n",
       " ('100 00 00 00', 39),\n",
       " ('011 10 10 10', 38),\n",
       " ('011 01 00 00', 38),\n",
       " ('111 11 10 00', 37),\n",
       " ('111 00 10 00', 37),\n",
       " ('101 10 10 00', 33),\n",
       " ('101 01 10 01', 23),\n",
       " ('101 11 00 00', 21),\n",
       " ('101 10 01 00', 21),\n",
       " ('011 00 10 00', 21),\n",
       " ('101 00 11 00', 18),\n",
       " ('110 00 01 00', 17),\n",
       " ('111 01 11 11', 12),\n",
       " ('110 11 01 00', 12),\n",
       " ('010 10 00 00', 11),\n",
       " ('111 10 11 10', 10),\n",
       " ('110 00 01 01', 10),\n",
       " ('101 11 00 11', 10),\n",
       " ('110 00 10 10', 10),\n",
       " ('001 10 00 00', 10),\n",
       " ('001 01 01 01', 9),\n",
       " ('011 10 00 10', 9),\n",
       " ('100 01 00 00', 9),\n",
       " ('101 00 01 00', 9),\n",
       " ('001 10 10 10', 9),\n",
       " ('111 10 11 01', 8),\n",
       " ('011 11 11 10', 8),\n",
       " ('111 01 11 01', 8),\n",
       " ('010 01 01 00', 8),\n",
       " ('111 10 11 00', 8),\n",
       " ('011 11 00 00', 8),\n",
       " ('101 11 11 00', 8),\n",
       " ('011 11 10 00', 7),\n",
       " ('111 10 10 11', 7),\n",
       " ('100 01 01 01', 7),\n",
       " ('101 10 01 01', 7),\n",
       " ('110 11 01 01', 7),\n",
       " ('110 01 00 01', 7),\n",
       " ('101 11 10 00', 7),\n",
       " ('111 10 01 00', 7),\n",
       " ('001 01 00 00', 7),\n",
       " ('110 11 11 11', 6),\n",
       " ('011 00 10 10', 6),\n",
       " ('101 00 10 00', 6),\n",
       " ('011 00 01 01', 6),\n",
       " ('111 01 10 00', 6),\n",
       " ('011 00 01 00', 6),\n",
       " ('110 11 10 00', 6),\n",
       " ('011 11 11 00', 6),\n",
       " ('101 00 10 10', 6),\n",
       " ('011 11 10 10', 6),\n",
       " ('010 01 01 01', 6),\n",
       " ('111 01 00 01', 6),\n",
       " ('010 10 10 10', 6),\n",
       " ('111 10 00 10', 6),\n",
       " ('011 11 01 00', 6),\n",
       " ('011 11 11 01', 6),\n",
       " ('001 10 10 00', 6),\n",
       " ('111 01 00 10', 6),\n",
       " ('110 00 00 01', 6),\n",
       " ('110 00 00 10', 6),\n",
       " ('001 01 01 00', 6),\n",
       " ('100 10 00 00', 5),\n",
       " ('110 11 10 10', 5),\n",
       " ('010 01 00 00', 5),\n",
       " ('101 00 00 01', 5),\n",
       " ('011 11 11 11', 5),\n",
       " ('100 01 01 00', 5),\n",
       " ('101 11 01 01', 5),\n",
       " ('000 00 00 00', 5),\n",
       " ('101 11 00 01', 5),\n",
       " ('111 01 10 10', 5),\n",
       " ('110 11 00 00', 5),\n",
       " ('100 10 10 10', 5),\n",
       " ('101 11 10 10', 5),\n",
       " ('101 00 11 01', 5),\n",
       " ('011 00 00 10', 5),\n",
       " ('111 01 11 00', 5),\n",
       " ('111 10 00 01', 5),\n",
       " ('101 11 01 00', 5),\n",
       " ('100 00 01 00', 5),\n",
       " ('001 00 10 00', 5),\n",
       " ('110 11 11 10', 5),\n",
       " ('111 00 11 10', 4),\n",
       " ('001 00 11 00', 4),\n",
       " ('110 11 11 01', 4),\n",
       " ('110 11 11 00', 4),\n",
       " ('011 11 01 01', 4),\n",
       " ('111 10 11 11', 4),\n",
       " ('111 01 10 01', 4),\n",
       " ('110 10 01 00', 4),\n",
       " ('011 00 00 01', 4),\n",
       " ('101 10 01 10', 4),\n",
       " ('101 11 11 01', 4),\n",
       " ('101 11 11 11', 4),\n",
       " ('111 01 11 10', 4),\n",
       " ('010 10 10 00', 4),\n",
       " ('011 01 10 00', 4),\n",
       " ('101 01 10 10', 4),\n",
       " ('110 10 11 10', 4),\n",
       " ('111 01 01 10', 3),\n",
       " ('101 00 00 10', 3),\n",
       " ('010 00 01 00', 3),\n",
       " ('001 01 10 01', 3),\n",
       " ('110 01 11 00', 3),\n",
       " ('101 10 00 10', 3),\n",
       " ('101 11 11 10', 3),\n",
       " ('110 00 10 00', 3),\n",
       " ('100 10 10 00', 3),\n",
       " ('101 01 11 00', 3),\n",
       " ('101 00 01 01', 3),\n",
       " ('101 00 11 11', 2),\n",
       " ('111 01 01 11', 2),\n",
       " ('110 11 10 01', 2),\n",
       " ('001 11 11 10', 2),\n",
       " ('111 10 01 01', 2),\n",
       " ('111 00 10 01', 2),\n",
       " ('101 00 10 01', 2),\n",
       " ('101 01 10 00', 2),\n",
       " ('010 11 00 00', 2),\n",
       " ('110 10 00 10', 2),\n",
       " ('110 01 11 01', 2),\n",
       " ('100 10 01 00', 2),\n",
       " ('111 10 10 01', 2),\n",
       " ('100 00 11 00', 2),\n",
       " ('011 11 01 11', 2),\n",
       " ('010 01 00 01', 2),\n",
       " ('100 11 00 11', 2),\n",
       " ('100 00 10 00', 2),\n",
       " ('011 01 11 00', 2),\n",
       " ('000 11 10 00', 2),\n",
       " ('011 10 10 11', 2),\n",
       " ('001 11 01 01', 2),\n",
       " ('101 11 01 10', 2),\n",
       " ('011 10 01 00', 2),\n",
       " ('101 01 01 11', 2),\n",
       " ('010 00 10 00', 2),\n",
       " ('001 11 00 11', 1),\n",
       " ('100 11 11 00', 1),\n",
       " ('001 10 01 00', 1),\n",
       " ('011 10 11 11', 1),\n",
       " ('100 01 00 11', 1),\n",
       " ('010 10 00 10', 1),\n",
       " ('001 11 00 01', 1),\n",
       " ('100 00 10 10', 1),\n",
       " ('100 00 01 01', 1),\n",
       " ('100 10 11 01', 1),\n",
       " ('110 10 10 11', 1),\n",
       " ('101 00 10 11', 1),\n",
       " ('011 01 11 10', 1),\n",
       " ('110 01 01 11', 1),\n",
       " ('110 10 10 01', 1),\n",
       " ('010 01 11 10', 1),\n",
       " ('100 11 00 00', 1),\n",
       " ('011 10 10 01', 1),\n",
       " ('011 10 01 01', 1),\n",
       " ('110 00 01 10', 1),\n",
       " ('100 10 00 01', 1),\n",
       " ('110 00 10 11', 1),\n",
       " ('001 01 11 01', 1),\n",
       " ('000 10 00 00', 1),\n",
       " ('101 00 01 11', 1),\n",
       " ('001 01 11 10', 1),\n",
       " ('111 11 00 01', 1),\n",
       " ('001 00 01 10', 1),\n",
       " ('001 00 00 10', 1),\n",
       " ('101 10 00 01', 1),\n",
       " ('011 10 11 01', 1),\n",
       " ('010 11 01 01', 1),\n",
       " ('100 00 00 01', 1),\n",
       " ('000 10 10 10', 1),\n",
       " ('000 00 01 00', 1),\n",
       " ('011 10 00 01', 1),\n",
       " ('010 11 11 10', 1),\n",
       " ('110 01 01 10', 1),\n",
       " ('001 00 00 01', 1),\n",
       " ('011 00 11 10', 1),\n",
       " ('001 00 10 10', 1),\n",
       " ('101 10 11 11', 1),\n",
       " ('010 00 00 01', 1),\n",
       " ('110 01 10 01', 1),\n",
       " ('101 01 11 01', 1),\n",
       " ('001 11 01 00', 1),\n",
       " ('110 10 11 11', 1),\n",
       " ('000 01 00 00', 1),\n",
       " ('010 11 11 00', 1),\n",
       " ('100 10 01 10', 1),\n",
       " ('101 01 00 01', 1),\n",
       " ('011 01 10 10', 1),\n",
       " ('010 11 10 00', 1),\n",
       " ('111 11 01 11', 1),\n",
       " ('011 10 01 10', 1),\n",
       " ('010 10 01 00', 1),\n",
       " ('001 00 01 00', 1),\n",
       " ('001 10 01 11', 1),\n",
       " ('011 10 11 00', 1),\n",
       " ('100 11 11 11', 1),\n",
       " ('010 11 11 11', 1),\n",
       " ('001 10 01 10', 1),\n",
       " ('000 00 00 01', 1),\n",
       " ('001 00 01 01', 1),\n",
       " ('011 01 00 01', 1),\n",
       " ('001 11 00 00', 1),\n",
       " ('100 11 01 01', 1),\n",
       " ('010 00 01 01', 1),\n",
       " ('111 01 00 11', 1),\n",
       " ('110 01 11 10', 1),\n",
       " ('101 00 01 10', 1),\n",
       " ('100 11 10 10', 1),\n",
       " ('000 11 10 01', 1),\n",
       " ('000 11 10 11', 1),\n",
       " ('001 01 11 11', 1),\n",
       " ('111 11 10 01', 1),\n",
       " ('011 01 11 11', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit_qec.utils import get_counts_via_stim\n",
    "\n",
    "noise_model = get_noise_model(p1Q=1e-4, p2Q=6e-3, pXY=1e-4, pZ=1e-4, pRO=1e-1, pRE=0)\n",
    "counts = get_counts_via_stim(qc, shots=int(SHOTS), noise_model=noise_model)\n",
    "sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "(sorted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# counts to IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 3, 2: 1, 3: 3, 4: 1, 5: 3, 6: 0, 7: 2, 8: 5}\n",
      "Specified job execution date: 2023-11-21 19:54:05.610765+01:00\n",
      "Found jobs for backend ibmq_mumbai with closest execution date 2023-11-21 18:54:05.610765+00:00.\n"
     ]
    }
   ],
   "source": [
    "from soft_info import get_repcode_IQ_map, get_KDEs\n",
    "\n",
    "IQ_map = get_repcode_IQ_map(layout, ROUNDS)\n",
    "print(IQ_map)\n",
    "\n",
    "mumbai_calib_job = \"cne879d72scg008df4j0\" # 21.11.23\n",
    "kde_dict, scaler_dict = get_KDEs(provider, mumbai_calib_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-20827979.42945149 -89806035.96672024]]\n",
      "(-20827979.429451488-89806035.96672024j)\n"
     ]
    }
   ],
   "source": [
    "# sample from the kde\n",
    "\n",
    "kde0, kde1 = kde_dict[10]\n",
    "scaler = scaler_dict[10]\n",
    "sample = kde0.sample()\n",
    "\n",
    "\n",
    "# invert the scaling\n",
    "sample = scaler.inverse_transform(sample)\n",
    "print(sample)\n",
    "\n",
    "\n",
    "IQ_point = complex(sample[0][0], sample[0][1])\n",
    "\n",
    "\n",
    "print(IQ_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:02<00:00, 85.74it/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Determine the total number of shots and number of qubits\n",
    "total_shots = sum(shots for _, shots in sorted_counts)\n",
    "len_IQ_array = len(IQ_map)\n",
    "\n",
    "# Preallocate the NumPy array\n",
    "IQ_memory = np.zeros((total_shots, len_IQ_array), dtype=np.complex128)\n",
    "\n",
    "# Fill the array\n",
    "shot_idx = 0\n",
    "for count_str, shots in tqdm(sorted_counts):\n",
    "    for _ in range(shots):\n",
    "        num_spaces = 0\n",
    "        for IQ_idx, bit in enumerate(count_str[:]):  # invert the order of count str to get IQ order\n",
    "            if bit == ' ':\n",
    "                num_spaces += 1\n",
    "                continue\n",
    "            qubit_idx = IQ_map[IQ_idx - num_spaces]\n",
    "            [kde0, kde1], scaler = kde_dict[qubit_idx], scaler_dict[qubit_idx]\n",
    "            if bit == '0':\n",
    "                sample = scaler.inverse_transform(kde0.sample(1))\n",
    "                IQ_memory[shot_idx, qubit_idx] = complex(sample[0][0], sample[0][1])\n",
    "            elif bit == '1':\n",
    "                sample = scaler.inverse_transform(kde1.sample(1))\n",
    "                IQ_memory[shot_idx, qubit_idx] = complex(sample[0][0], sample[0][1])\n",
    "        shot_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.array(IQ_memory).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified job execution date: 2023-11-21 19:54:05.610765+01:00\n",
      "Found jobs for backend ibmq_mumbai with closest execution date 2023-11-21 18:54:05.610765+00:00.\n",
      "Searching for ibmq_mumbai and 23.11.21_10h17_300pts_2std\n"
     ]
    }
   ],
   "source": [
    "from Scratch import create_or_load_kde_grid\n",
    "\n",
    "grid_dict, processed_scaler_dict = create_or_load_kde_grid(provider, mumbai_calib_job, 300, 2, other_date=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_avgs_from_dict(noise_dict):\n",
    "    '''\n",
    "    Takes noise dictionary as an argument then returns length 5\n",
    "    array defining average noise levels: [init, idle, RO, single-, two-qubit gate]\n",
    "    '''\n",
    "    init_avg = np.average([noise_dict[qubit]['init'] for qubit in noise_dict])\n",
    "    idle_avg = np.average([noise_dict[qubit]['idle'] for qubit in noise_dict])\n",
    "    RO_avg = np.average([noise_dict[qubit]['RO'] for qubit in noise_dict])\n",
    "    single_avg = 1e-4#np.average([noise_dict[qubit]['init'] for qubit in noise_dict])\n",
    "    two_gate_avg = np.average([noise_dict[qubit]['2-gate'][connection]\n",
    "                        for qubit in noise_dict\n",
    "                        for connection in noise_dict[qubit]['2-gate']\n",
    "                        if connection != 'default'])\n",
    "    return [init_avg, idle_avg, RO_avg, single_avg, two_gate_avg]\n",
    "# End get_avgs_from_dict\n",
    "\n",
    "\n",
    "def get_noise_dict_from_backend(backend, layout, date=None):\n",
    "    '''\n",
    "    Takes a given backend and a mapping object and returns a noise dictionary\n",
    "    to pass to a new Cross_Platform_Code/Hex_Code to have accurate backend\n",
    "    specific noise information based on calibration data.\n",
    "    '''\n",
    "    # Pre-reqs\n",
    "    noise_dict = {}\n",
    "    round_time = 1000e-9\n",
    "    if date is None:\n",
    "        t = None\n",
    "    else:\n",
    "        t = datetime(day=int(date[-2:]), month=int(date[-4:-2]), year=int(date[:4]))\n",
    "    properties = backend.properties(datetime=t)\n",
    "    # Initializing each qubit with single qubit noise\n",
    "    for qubit in layout:\n",
    "        # Defining ROI error\n",
    "        ROI_error = properties.readout_error(qubit)\n",
    "        # Defining idle error\n",
    "        t1 = properties.t1(qubit)\n",
    "        t2 = properties.t2(qubit)\n",
    "        t_time = min(t1, t2)\n",
    "        idle_error = 1 - np.exp(-round_time / t_time)\n",
    "        # Updating dictionary\n",
    "        noise_dict[qubit] = {}\n",
    "        noise_dict[qubit]['init'] = ROI_error\n",
    "        noise_dict[qubit]['idle'] = idle_error\n",
    "        noise_dict[qubit]['RO'] = ROI_error\n",
    "        noise_dict[qubit]['gate'] = 1e-4\n",
    "        noise_dict[qubit]['2-gate'] = {'default': 1e-2}\n",
    "    # Two qubit gate noise\n",
    "    all_qiskit_indexes = layout \n",
    "    for pair in backend.coupling_map:\n",
    "        # Making sure connection is in circuit\n",
    "        if pair[0] in all_qiskit_indexes and pair[1] in all_qiskit_indexes:\n",
    "            # Getting two qubit gate error\n",
    "            two_gate_error = properties.gate_error('cx', pair)\n",
    "            if two_gate_error > .5:\n",
    "                two_gate_error = .5\n",
    "            # # Updating dictionary\n",
    "            # stim_index_0 = map.get_stim_index(qiskit_index=pair[0])\n",
    "            # stim_index_1 = map.get_stim_index(qiskit_index=pair[1])\n",
    "            noise_dict[pair[0]]['2-gate'][pair[1]] = two_gate_error\n",
    "            noise_dict[pair[1]]['2-gate'][pair[0]] = two_gate_error\n",
    "    return noise_dict\n",
    "# End get_noise_dict_from_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_dict: {1: {'init': 0.030000000000000027, 'idle': 0.007897557855443993, 'RO': 0.030000000000000027, 'gate': 0.0001, '2-gate': {'default': 0.01, 0: 0.005455353871420404, 2: 0.010170945774381879}}, 3: {'init': 0.021100000000000008, 'idle': 0.008996902186028333, 'RO': 0.021100000000000008, 'gate': 0.0001, '2-gate': {'default': 0.01, 2: 0.008544514649166696, 5: 0.021703370620595658}}, 0: {'init': 0.47, 'idle': 0.0121859535428267, 'RO': 0.47, 'gate': 0.0001, '2-gate': {'default': 0.01, 1: 0.005455353871420404}}, 2: {'init': 0.012699999999999934, 'idle': 0.008960615196325294, 'RO': 0.012699999999999934, 'gate': 0.0001, '2-gate': {'default': 0.01, 1: 0.010170945774381879, 3: 0.008544514649166696}}, 5: {'init': 0.01870000000000005, 'idle': 0.022334153450303096, 'RO': 0.01870000000000005, 'gate': 0.0001, '2-gate': {'default': 0.01, 3: 0.021703370620595658}}}\n",
      "avgs_noise [init_avg, idle_avg, RO_avg, single_avg, two_gate_avg]: [0.1105, 0.012075036446185483, 0.1105, 0.0001, 0.011468546228891159]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date = \"2023-10-30 09:45:17.340386+01:00\" #md.creation_date[0] # md[0] for log 1\n",
    "noise_dict = get_noise_dict_from_backend(provider.get_backend(DEVICE), layout, date=None) # takes noise closest to today\n",
    "print(\"noise_dict:\", noise_dict)\n",
    "avgs_noise = get_avgs_from_dict(noise_dict)\n",
    "print(\"avgs_noise [init_avg, idle_avg, RO_avg, single_avg, two_gate_avg]:\", avgs_noise)\n",
    "\n",
    "# takes 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatching\n",
    "import stim\n",
    "\n",
    "\n",
    "circuit = stim.Circuit.generated(\"repetition_code:memory\",\n",
    "                                distance=DISTANCE,\n",
    "                                rounds=ROUNDS,\n",
    "                                after_clifford_depolarization= avgs_noise[4], #two-qubit-fidelity,\n",
    "                                after_reset_flip_probability= 0, #reset error,\n",
    "                                before_measure_flip_probability= avgs_noise[2], #measurement error,\n",
    "                                before_round_data_depolarization= avgs_noise[1]) #idle error)\n",
    "# print(circuit)\n",
    "\n",
    "model = circuit.detector_error_model(decompose_errors=True)\n",
    "matching = pymatching.Matching.from_detector_error_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 274 out of 10000 shots\n"
     ]
    }
   ],
   "source": [
    "import cpp_soft_info\n",
    "\n",
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "# cpp_soft_info.reweight_edges_based_on_error_probs(matching._matching_graph, counts, False, \"spitz\")\n",
    "\n",
    "p_data = 6.869e-3 # mean sherbrooke noise\n",
    "num_errors = cpp_soft_info.decode_IQ_shots(matching._matching_graph, IQ_memory,\n",
    "                                           ROUNDS, 0, IQ_map, grid_dict,\n",
    "                                           processed_scaler_dict, p_data=p_data, p_mixed=p_data/1000, #p_mixed=1e-80, for d=30\n",
    "                                           common_measure=-1, _bimodal=False, merge_strategy = \"replace\")\n",
    "print(\"num_errors:\", num_errors, \"out of\", len(IQ_memory), \"shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 1564 out of 10000 shots\n"
     ]
    }
   ],
   "source": [
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "num_errors = cpp_soft_info.decode_IQ_shots_flat(matching._matching_graph, IQ_memory,\n",
    "                                           ROUNDS, 0, IQ_map, grid_dict,\n",
    "                                           processed_scaler_dict)\n",
    "print(\"num_errors:\", num_errors, \"out of\", len(IQ_memory), \"shots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_errors: 1843 out of 10000 shots\n"
     ]
    }
   ],
   "source": [
    "matching = pymatching.Matching.from_detector_error_model(model)\n",
    "\n",
    "def weight_to_prob(weight):\n",
    "    return 1/(1+np.exp(weight))\n",
    "\n",
    "p_data = 6.869e-3 # mean sherbrooke ECR error\n",
    "p_mixed = p_data/1 # Same as weighted\n",
    "# p_meas = 1e-3\n",
    "p_meas = 15.900e-2 # random found number\n",
    "\n",
    "\n",
    "# p_data = -1\n",
    "# p_mixed = -1\n",
    "# p_meas = -1\n",
    "\n",
    "num_errors = cpp_soft_info.decode_IQ_shots_flat_informed(matching._matching_graph, IQ_memory, \n",
    "                                           ROUNDS, 0, IQ_map, grid_dict, processed_scaler_dict,\n",
    "                                           p_data, p_mixed, p_meas, common_measure=-1)\n",
    "\n",
    "print(\"num_errors:\", num_errors, \"out of\", len(IQ_memory), \"shots\")\n",
    "         \n",
    "# takes 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Soft-Info-fMUpUe5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
